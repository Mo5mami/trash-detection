{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wEymMceED94",
    "papermill": {
     "duration": 0.03357,
     "end_time": "2021-04-29T16:31:42.369849",
     "exception": false,
     "start_time": "2021-04-29T16:31:42.336279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:31:42.439234Z",
     "iopub.status.busy": "2021-04-29T16:31:42.438431Z",
     "iopub.status.idle": "2021-04-29T16:31:42.441213Z",
     "shell.execute_reply": "2021-04-29T16:31:42.440781Z"
    },
    "id": "eTJ6aqypED-G",
    "outputId": "b651123e-ef7a-4b76-94e3-bb5bd7edee37",
    "papermill": {
     "duration": 0.039411,
     "end_time": "2021-04-29T16:31:42.441309",
     "exception": false,
     "start_time": "2021-04-29T16:31:42.401898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python -m pip install detectron2==0.4 -f \\\n",
    "#  https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:31:42.511783Z",
     "iopub.status.busy": "2021-04-29T16:31:42.510878Z",
     "iopub.status.idle": "2021-04-29T16:32:10.356314Z",
     "shell.execute_reply": "2021-04-29T16:32:10.354591Z"
    },
    "papermill": {
     "duration": 27.883139,
     "end_time": "2021-04-29T16:32:10.356500",
     "exception": false,
     "start_time": "2021-04-29T16:31:42.473361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html\r\n",
      "Collecting detectron2==0.4\r\n",
      "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/detectron2-0.4%2Bcu102-cp37-cp37m-linux_x86_64.whl (5.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 773 kB/s \r\n",
      "\u001b[?25hCollecting fvcore<0.1.4,>=0.1.3\r\n",
      "  Downloading fvcore-0.1.3.post20210317.tar.gz (47 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 47 kB 407 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (2.3.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (3.2.1)\r\n",
      "Collecting iopath>=0.1.2\r\n",
      "  Downloading iopath-0.1.8-py3-none-any.whl (19 kB)\r\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (8.0.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (0.18.2)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (1.1.0)\r\n",
      "Collecting yacs>=0.1.6\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (4.45.0)\r\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (1.4.1)\r\n",
      "Collecting omegaconf>=2\r\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\r\n",
      "Collecting pycocotools>=2.0.2\r\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (1.3.0)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (0.8.7)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore<0.1.4,>=0.1.3->detectron2==0.4) (1.18.5)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore<0.1.4,>=0.1.3->detectron2==0.4) (5.3.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.14.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (3.2.1)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.33.2)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.7.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (3.13.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.14.0)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (0.34.2)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.0.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (2.23.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (0.4.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (0.11.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.4) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.4) (1.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.4) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.4) (2.8.1)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath>=0.1.2->detectron2==0.4) (2.0.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf>=2->detectron2==0.4) (3.7.4.1)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2==0.4) (0.29.21)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (4.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (3.1.1)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (1.25.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2020.6.20)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (3.0.4)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (3.0.1)\r\n",
      "Building wheels for collected packages: fvcore, pycocotools\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.3.post20210317-py3-none-any.whl size=58540 sha256=696aa4cfe640c65f3add16e8daef6f901be645fd21b4a9644255c90ec5111289\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a6/02/09/10e3a0150eb92e5ecbee3677a813bffc32a8ec6f876bfe4adf\r\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=273761 sha256=45264c39fc8afc162aef2ecc62c4c5b0b3754c2d91d1f2bd3889e28fa877147c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\r\n",
      "Successfully built fvcore pycocotools\r\n",
      "Installing collected packages: yacs, iopath, fvcore, omegaconf, pycocotools, detectron2\r\n",
      "Successfully installed detectron2-0.4+cu102 fvcore-0.1.3.post20210317 iopath-0.1.8 omegaconf-2.0.6 pycocotools-2.0.2 yacs-0.1.8\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install detectron2==0.4 -f \\\n",
    "  https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:10.549640Z",
     "iopub.status.busy": "2021-04-29T16:32:10.548171Z",
     "iopub.status.idle": "2021-04-29T16:32:12.627224Z",
     "shell.execute_reply": "2021-04-29T16:32:12.627820Z"
    },
    "papermill": {
     "duration": 2.174004,
     "end_time": "2021-04-29T16:32:12.627990",
     "exception": false,
     "start_time": "2021-04-29T16:32:10.453986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-ignite==0.4.2\r\n",
      "pytorch-lightning==1.0.4\r\n",
      "torch==1.6.0\r\n",
      "torchaudio==0.6.0a0+f17ae39\r\n",
      "torchtext==0.8.0a0+c851c3e\r\n",
      "torchvision==0.7.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:12.730097Z",
     "iopub.status.busy": "2021-04-29T16:32:12.729274Z",
     "iopub.status.idle": "2021-04-29T16:32:13.362265Z",
     "shell.execute_reply": "2021-04-29T16:32:13.361244Z"
    },
    "id": "wK4MocOFED-O",
    "papermill": {
     "duration": 0.685945,
     "end_time": "2021-04-29T16:32:13.362385",
     "exception": false,
     "start_time": "2021-04-29T16:32:12.676440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p models logs configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:13.468340Z",
     "iopub.status.busy": "2021-04-29T16:32:13.465629Z",
     "iopub.status.idle": "2021-04-29T16:32:14.785991Z",
     "shell.execute_reply": "2021-04-29T16:32:14.784988Z"
    },
    "id": "ij6R7KtAED-P",
    "outputId": "691fa7cd-93e1-4182-bbad-d38da4171805",
    "papermill": {
     "duration": 1.373941,
     "end_time": "2021-04-29T16:32:14.786117",
     "exception": false,
     "start_time": "2021-04-29T16:32:13.412176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 29 16:32:14 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQP0yElOED-Q",
    "papermill": {
     "duration": 0.04865,
     "end_time": "2021-04-29T16:32:14.883543",
     "exception": false,
     "start_time": "2021-04-29T16:32:14.834893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:14.994362Z",
     "iopub.status.busy": "2021-04-29T16:32:14.993086Z",
     "iopub.status.idle": "2021-04-29T16:32:18.160847Z",
     "shell.execute_reply": "2021-04-29T16:32:18.159441Z"
    },
    "id": "4u5GjrIPED-R",
    "papermill": {
     "duration": 3.228087,
     "end_time": "2021-04-29T16:32:18.160966",
     "exception": false,
     "start_time": "2021-04-29T16:32:14.932879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "\n",
    "import detectron2\n",
    "from detectron2.data.transforms import Transform as T\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper, build_detection_test_loader , build_detection_train_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.config import configurable\n",
    "from detectron2.engine.hooks import EvalHook\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,StratifiedShuffleSplit,GroupKFold\n",
    "from sklearn.utils import check_random_state\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from IPython.display import FileLink, FileLinks\n",
    "import yaml\n",
    "from abc import ABC,ABCMeta, abstractmethod\n",
    "from yacs.config import CfgNode as CN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR0PbMOBED-T",
    "papermill": {
     "duration": 0.048564,
     "end_time": "2021-04-29T16:32:18.259113",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.210549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:18.360560Z",
     "iopub.status.busy": "2021-04-29T16:32:18.359823Z",
     "iopub.status.idle": "2021-04-29T16:32:18.362734Z",
     "shell.execute_reply": "2021-04-29T16:32:18.362307Z"
    },
    "id": "RsqnTOaRR-5C",
    "papermill": {
     "duration": 0.055473,
     "end_time": "2021-04-29T16:32:18.362830",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.307357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../input/tacotrashdataset\"\n",
    "LOGS_PATH = \"logs\"\n",
    "MODELS_PATH = \"models\"\n",
    "CONFIG_PATH = \"configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:18.470095Z",
     "iopub.status.busy": "2021-04-29T16:32:18.469282Z",
     "iopub.status.idle": "2021-04-29T16:32:18.472240Z",
     "shell.execute_reply": "2021-04-29T16:32:18.471823Z"
    },
    "id": "9mL5TQiXSFEm",
    "papermill": {
     "duration": 0.060935,
     "end_time": "2021-04-29T16:32:18.472337",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.411402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_C = CN()\n",
    "_C.general=CN()\n",
    "_C.general.seed = 42\n",
    "_C.general.n_folds = 5\n",
    "_C.general.tool = \"detectron2\"\n",
    "_C.general.experiment_id = \"26-04-2021\"\n",
    "_C.general.category = \"super_category\"\n",
    "_C.general.augmentations = True\n",
    "_C.general.TTA = False\n",
    "\n",
    "_C.preprocess=CN()\n",
    "_C.preprocess.height = 1500\n",
    "_C.preprocess.width = 1500\n",
    "_C.preprocess.longest_max_size = 1500\n",
    "_C.preprocess.smallest_max_size = 1000\n",
    "\n",
    "_C.model=CN()\n",
    "_C.model.base_lr = 0.001\n",
    "_C.model.num_classes = 29 #29 if super category 60 if normal category \n",
    "_C.model.model_name = \"faster_rcnn_R_101_FPN_3x\"\n",
    "_C.model.batchsize_per_image = 1024\n",
    "#_C.model.images_per_batch = 4\n",
    "_C.model.images_per_batch = 4\n",
    "_C.model.epochs = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:18.579127Z",
     "iopub.status.busy": "2021-04-29T16:32:18.578365Z",
     "iopub.status.idle": "2021-04-29T16:32:18.580723Z",
     "shell.execute_reply": "2021-04-29T16:32:18.581240Z"
    },
    "id": "0QQlNoxsED-U",
    "papermill": {
     "duration": 0.059712,
     "end_time": "2021-04-29T16:32:18.581354",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.521642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cfg_defaults():\n",
    "    \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
    "    # Return a clone so that the defaults will not be altered\n",
    "    # This is for the \"local variable\" use pattern\n",
    "    #return _C.clone()\n",
    "    return _C\n",
    "\n",
    "def dump_cfg(config = get_cfg_defaults() , path = \"experiment.yaml\"):\n",
    "    \"\"\"Save a yacs CfgNode object in a yaml file in path.\"\"\"\n",
    "    stream = open(path, 'w')\n",
    "    stream.write(config.dump())\n",
    "    stream.close()\n",
    "\n",
    "def inject_config(funct):\n",
    "    \"\"\"Inject a yacs CfgNode object in a function as first arg.\"\"\"\n",
    "    def function_wrapper(*args,**kwargs):\n",
    "        return funct(_C,*args,**kwargs)  \n",
    "    return function_wrapper\n",
    "\n",
    "def dump_dict(config,path=\"config.yaml\"):\n",
    "        stream = open(path, 'w')\n",
    "        yaml.dump(config,stream)\n",
    "        stream.close()\n",
    "\n",
    "c=get_cfg_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:18.684615Z",
     "iopub.status.busy": "2021-04-29T16:32:18.683760Z",
     "iopub.status.idle": "2021-04-29T16:32:18.689167Z",
     "shell.execute_reply": "2021-04-29T16:32:18.688596Z"
    },
    "id": "NWhZpAG8ED-W",
    "papermill": {
     "duration": 0.057986,
     "end_time": "2021-04-29T16:32:18.689260",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.631274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dump_cfg(path = os.path.join(LOGS_PATH , \"experiment.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM4UyIkMED-X",
    "papermill": {
     "duration": 0.048304,
     "end_time": "2021-04-29T16:32:18.786396",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.738092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:18.892006Z",
     "iopub.status.busy": "2021-04-29T16:32:18.891244Z",
     "iopub.status.idle": "2021-04-29T16:32:18.894108Z",
     "shell.execute_reply": "2021-04-29T16:32:18.893694Z"
    },
    "id": "jJdQmFwbED-Z",
    "papermill": {
     "duration": 0.058711,
     "end_time": "2021-04-29T16:32:18.894212",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.835501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def seed_all(config):\n",
    "    \"\"\"\n",
    "    seed my experiments to be able to reproduce\n",
    "    \"\"\"\n",
    "    seed_value=config.general[\"seed\"]\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDqBVC89ED-a",
    "papermill": {
     "duration": 0.048975,
     "end_time": "2021-04-29T16:32:18.992262",
     "exception": false,
     "start_time": "2021-04-29T16:32:18.943287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FIX annotation duplicated ids and negative bboxes\n",
    "\n",
    "repeated annotations idx \n",
    "\n",
    "308 => 0\n",
    "\n",
    "4039  =>2197\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:19.095797Z",
     "iopub.status.busy": "2021-04-29T16:32:19.095151Z",
     "iopub.status.idle": "2021-04-29T16:32:19.315866Z",
     "shell.execute_reply": "2021-04-29T16:32:19.314746Z"
    },
    "id": "ANn9_6WsED-a",
    "papermill": {
     "duration": 0.27463,
     "end_time": "2021-04-29T16:32:19.315987",
     "exception": false,
     "start_time": "2021-04-29T16:32:19.041357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot=json.load(open(os.path.join(DATASET_PATH,\"data/annotations.json\")))\n",
    "annot[\"annotations\"][308][\"id\"]=0\n",
    "annot[\"annotations\"][4039][\"id\"]=2197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xFUGtpxED-a",
    "papermill": {
     "duration": 0.049558,
     "end_time": "2021-04-29T16:32:19.415186",
     "exception": false,
     "start_time": "2021-04-29T16:32:19.365628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## delete negative BBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:19.525365Z",
     "iopub.status.busy": "2021-04-29T16:32:19.524483Z",
     "iopub.status.idle": "2021-04-29T16:32:19.527362Z",
     "shell.execute_reply": "2021-04-29T16:32:19.526929Z"
    },
    "id": "-VlzvW8JED-b",
    "papermill": {
     "duration": 0.063123,
     "end_time": "2021-04-29T16:32:19.527452",
     "exception": false,
     "start_time": "2021-04-29T16:32:19.464329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_to_delete=[]\n",
    "for idx,annotation in enumerate(annot[\"annotations\"]):\n",
    "    if (annotation[\"bbox\"][0]<0 or annotation[\"bbox\"][1]<0 or\n",
    "        annotation[\"bbox\"][2]<0 or annotation[\"bbox\"][3]<0):\n",
    "        annot_to_delete.append(idx)\n",
    "for pos,idx in enumerate(annot_to_delete):\n",
    "    del annot[\"annotations\"][idx-pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:19.631734Z",
     "iopub.status.busy": "2021-04-29T16:32:19.630586Z",
     "iopub.status.idle": "2021-04-29T16:32:20.139803Z",
     "shell.execute_reply": "2021-04-29T16:32:20.138341Z"
    },
    "id": "kZcq7GCDED-b",
    "papermill": {
     "duration": 0.563348,
     "end_time": "2021-04-29T16:32:20.139921",
     "exception": false,
     "start_time": "2021-04-29T16:32:19.576573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(annot,open(\"new_annotations.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptphgt97ED-c",
    "papermill": {
     "duration": 0.057861,
     "end_time": "2021-04-29T16:32:20.249477",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.191616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Annotation Preprocess and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sR-XOdvED-c",
    "papermill": {
     "duration": 0.051412,
     "end_time": "2021-04-29T16:32:20.352814",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.301402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Categories and Super categories dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:20.462537Z",
     "iopub.status.busy": "2021-04-29T16:32:20.460716Z",
     "iopub.status.idle": "2021-04-29T16:32:20.463122Z",
     "shell.execute_reply": "2021-04-29T16:32:20.463532Z"
    },
    "id": "afefHsVYED-d",
    "papermill": {
     "duration": 0.058276,
     "end_time": "2021-04-29T16:32:20.463644",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.405368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories={ annotation[\"id\"] : annotation[\"name\"] for annotation in annot[\"categories\"]}\n",
    "super_categories={ annotation[\"id\"] : annotation[\"supercategory\"] for annotation in annot[\"categories\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IA_JHKt0ED-f",
    "papermill": {
     "duration": 0.049547,
     "end_time": "2021-04-29T16:32:20.563068",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.513521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:20.691663Z",
     "iopub.status.busy": "2021-04-29T16:32:20.690867Z",
     "iopub.status.idle": "2021-04-29T16:32:20.693997Z",
     "shell.execute_reply": "2021-04-29T16:32:20.693558Z"
    },
    "id": "2VFDgjvVED-f",
    "papermill": {
     "duration": 0.081358,
     "end_time": "2021-04-29T16:32:20.694099",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.612741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_df=pd.DataFrame(annot[\"annotations\"])\n",
    "images_df=pd.DataFrame(annot[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:20.806889Z",
     "iopub.status.busy": "2021-04-29T16:32:20.805824Z",
     "iopub.status.idle": "2021-04-29T16:32:20.825389Z",
     "shell.execute_reply": "2021-04-29T16:32:20.824837Z"
    },
    "id": "axg8vADJED-f",
    "outputId": "5add80ef-22f9-4d09-9b39-f4d465d58eb3",
    "papermill": {
     "duration": 0.080968,
     "end_time": "2021-04-29T16:32:20.825489",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.744521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>749.500000</td>\n",
       "      <td>2824.88400</td>\n",
       "      <td>3222.825333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>433.157015</td>\n",
       "      <td>758.65017</td>\n",
       "      <td>802.357852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>842.00000</td>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>374.750000</td>\n",
       "      <td>2448.00000</td>\n",
       "      <td>2448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>749.500000</td>\n",
       "      <td>2448.00000</td>\n",
       "      <td>3264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1124.250000</td>\n",
       "      <td>3264.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1499.000000</td>\n",
       "      <td>6000.00000</td>\n",
       "      <td>5312.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       width       height\n",
       "count  1500.000000  1500.00000  1500.000000\n",
       "mean    749.500000  2824.88400  3222.825333\n",
       "std     433.157015   758.65017   802.357852\n",
       "min       0.000000   842.00000   474.000000\n",
       "25%     374.750000  2448.00000  2448.000000\n",
       "50%     749.500000  2448.00000  3264.000000\n",
       "75%    1124.250000  3264.00000  4000.000000\n",
       "max    1499.000000  6000.00000  5312.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUiH0qtEXj58",
    "papermill": {
     "duration": 0.05324,
     "end_time": "2021-04-29T16:32:20.931591",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.878351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Choose between normal categories or super categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:21.051792Z",
     "iopub.status.busy": "2021-04-29T16:32:21.050892Z",
     "iopub.status.idle": "2021-04-29T16:32:21.069685Z",
     "shell.execute_reply": "2021-04-29T16:32:21.069241Z"
    },
    "id": "nY1UmdtiED-g",
    "papermill": {
     "duration": 0.085287,
     "end_time": "2021-04-29T16:32:21.069792",
     "exception": false,
     "start_time": "2021-04-29T16:32:20.984505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_df[\"category\"]=annot_df[\"category_id\"].apply(lambda value : categories[value])\n",
    "annot_df[\"super_category\"]=annot_df[\"category_id\"].apply(lambda value : super_categories[value])\n",
    "super_category_to_index={value : key for key,value in enumerate(annot_df[\"super_category\"].unique())}\n",
    "annot_df[\"super_category_id\"]=annot_df[\"super_category\"].apply(lambda value : super_category_to_index[value])\n",
    "annot_df[\"normal_category_id\"]=annot_df[\"category_id\"]\n",
    "annot_df[\"normal_category\"]=annot_df[\"category\"]\n",
    "if c.general[\"category\"] != \"normal_category\":\n",
    "    annot_df[\"category_id\"]=annot_df[\"super_category_id\"]\n",
    "    annot_df[\"category\"]=annot_df[\"super_category\"]\n",
    "    annot_cat=annot_df.groupby(\"category_id\")[[\"category_id\",\"category\",\"super_category\"]].first()\n",
    "    annot_cat.columns=[\"id\",\"name\",\"supercategory\"]\n",
    "    annot[\"categories\"]=annot_cat.to_dict(\"records\")\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:21.178193Z",
     "iopub.status.busy": "2021-04-29T16:32:21.177415Z",
     "iopub.status.idle": "2021-04-29T16:32:21.180293Z",
     "shell.execute_reply": "2021-04-29T16:32:21.179872Z"
    },
    "id": "kbeKt9MKED-h",
    "papermill": {
     "duration": 0.05976,
     "end_time": "2021-04-29T16:32:21.180386",
     "exception": false,
     "start_time": "2021-04-29T16:32:21.120626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for id , name in zip(annot_df[\"category_id\"],annot_df[\"category\"]):\n",
    "    categories[id]=name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:21.348152Z",
     "iopub.status.busy": "2021-04-29T16:32:21.346913Z",
     "iopub.status.idle": "2021-04-29T16:32:21.351039Z",
     "shell.execute_reply": "2021-04-29T16:32:21.352123Z"
    },
    "id": "KKi6DDiZED-h",
    "outputId": "d6afa885-1ba2-4a7a-eab6-f1a3a12bf555",
    "papermill": {
     "duration": 0.094769,
     "end_time": "2021-04-29T16:32:21.352393",
     "exception": false,
     "start_time": "2021-04-29T16:32:21.257624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bottle',\n",
       " 1: 'Carton',\n",
       " 2: 'Bottle cap',\n",
       " 3: 'Can',\n",
       " 4: 'Pop tab',\n",
       " 5: 'Cup',\n",
       " 6: 'Plastic bag & wrapper',\n",
       " 7: 'Styrofoam piece',\n",
       " 8: 'Other plastic',\n",
       " 9: 'Plastic container',\n",
       " 10: 'Paper',\n",
       " 11: 'Lid',\n",
       " 12: 'Straw',\n",
       " 13: 'Paper bag',\n",
       " 14: 'Broken glass',\n",
       " 15: 'Plastic utensils',\n",
       " 16: 'Glass jar',\n",
       " 17: 'Food waste',\n",
       " 18: 'Squeezable tube',\n",
       " 19: 'Shoe',\n",
       " 20: 'Aluminium foil',\n",
       " 21: 'Unlabeled litter',\n",
       " 22: 'Blister pack',\n",
       " 23: 'Battery',\n",
       " 24: 'Rope & strings',\n",
       " 25: 'Cigarette',\n",
       " 26: 'Scrap metal',\n",
       " 27: 'Plastic glooves'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcJOY-OPED-i",
    "papermill": {
     "duration": 0.093284,
     "end_time": "2021-04-29T16:32:21.552096",
     "exception": false,
     "start_time": "2021-04-29T16:32:21.458812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:21.739063Z",
     "iopub.status.busy": "2021-04-29T16:32:21.738062Z",
     "iopub.status.idle": "2021-04-29T16:32:21.785772Z",
     "shell.execute_reply": "2021-04-29T16:32:21.787008Z"
    },
    "id": "NxqT7Z8fED-i",
    "outputId": "5cc8cf94-2fc3-4492-8876-a629141aa0de",
    "papermill": {
     "duration": 0.146488,
     "end_time": "2021-04-29T16:32:21.787230",
     "exception": false,
     "start_time": "2021-04-29T16:32:21.640742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>category</th>\n",
       "      <th>super_category</th>\n",
       "      <th>super_category_id</th>\n",
       "      <th>normal_category_id</th>\n",
       "      <th>normal_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[561.0, 1238.0, 568.0, 1201.0, 567.0, 1175.0,...</td>\n",
       "      <td>403954.0</td>\n",
       "      <td>[517.0, 127.0, 447.0, 1322.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Glass bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[928.0, 1876.0, 938.0, 1856.0, 968.0, 1826.0,...</td>\n",
       "      <td>1071259.5</td>\n",
       "      <td>[1.0, 457.0, 1429.0, 1519.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Carton</td>\n",
       "      <td>Carton</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Meal carton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[617.0, 383.0, 703.0, 437.0, 713.0, 456.0, 72...</td>\n",
       "      <td>99583.5</td>\n",
       "      <td>[531.0, 292.0, 1006.0, 672.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Carton</td>\n",
       "      <td>Carton</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Other carton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[670.0, 993.0, 679.0, 998.0, 684.0, 1001.0, 6...</td>\n",
       "      <td>73832.5</td>\n",
       "      <td>[632.0, 987.0, 500.0, 374.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Clear plastic bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[647.0, 1028.0, 650.0, 1022.0, 653.0, 1016.0,...</td>\n",
       "      <td>915.0</td>\n",
       "      <td>[632.0, 989.0, 44.0, 51.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottle cap</td>\n",
       "      <td>Bottle cap</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>Plastic bottle cap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  image_id  category_id  \\\n",
       "0   1         0            0   \n",
       "1   2         1            1   \n",
       "2   3         1            1   \n",
       "3   4         2            0   \n",
       "4   5         2            2   \n",
       "\n",
       "                                        segmentation       area  \\\n",
       "0  [[561.0, 1238.0, 568.0, 1201.0, 567.0, 1175.0,...   403954.0   \n",
       "1  [[928.0, 1876.0, 938.0, 1856.0, 968.0, 1826.0,...  1071259.5   \n",
       "2  [[617.0, 383.0, 703.0, 437.0, 713.0, 456.0, 72...    99583.5   \n",
       "3  [[670.0, 993.0, 679.0, 998.0, 684.0, 1001.0, 6...    73832.5   \n",
       "4  [[647.0, 1028.0, 650.0, 1022.0, 653.0, 1016.0,...      915.0   \n",
       "\n",
       "                            bbox  iscrowd    category super_category  \\\n",
       "0  [517.0, 127.0, 447.0, 1322.0]        0      Bottle         Bottle   \n",
       "1   [1.0, 457.0, 1429.0, 1519.0]        0      Carton         Carton   \n",
       "2  [531.0, 292.0, 1006.0, 672.0]        0      Carton         Carton   \n",
       "3   [632.0, 987.0, 500.0, 374.0]        0      Bottle         Bottle   \n",
       "4     [632.0, 989.0, 44.0, 51.0]        0  Bottle cap     Bottle cap   \n",
       "\n",
       "   super_category_id  normal_category_id       normal_category  \n",
       "0                  0                   6          Glass bottle  \n",
       "1                  1                  18           Meal carton  \n",
       "2                  1                  14          Other carton  \n",
       "3                  0                   5  Clear plastic bottle  \n",
       "4                  2                   7    Plastic bottle cap  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:21.959920Z",
     "iopub.status.busy": "2021-04-29T16:32:21.959141Z",
     "iopub.status.idle": "2021-04-29T16:32:22.712732Z",
     "shell.execute_reply": "2021-04-29T16:32:22.711700Z"
    },
    "id": "WbXgBm4tED-i",
    "outputId": "5b6df7e0-802c-4739-c7df-06d6487cba68",
    "papermill": {
     "duration": 0.839719,
     "end_time": "2021-04-29T16:32:22.712884",
     "exception": false,
     "start_time": "2021-04-29T16:32:21.873165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd950daf890>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFsCAYAAAA30fmmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7xcVXn/8c83QcJdEgkISSAoEUlUQAMiijdoAbEEqkgsakAUqVFRf1Wh1aJgKmq9lTa2UdGoCAYFidIqGAFB5RLuBIgEAyEkkICgCBpJeH5/rDVkZzLnnElyZu+Zfb7v1+u8Zvbae2Y9Z86ZZ9asvfZaigjMzKxehlUdgJmZDT4ndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycrdBJWmBpNdWHUedSRovKSRtlrf/T9K0QXrugyQtLGzfK+mQwXju/Hz+/yiJk7s9Y0PfyJK+JenTxbKImBQRVwx6cINM0vGSrq46jsEQEYdHxOyBjssfCHsM8FxXRcSegxFXL/9/1IGTu1nJGi3ubtOtcdlGigj/dNkPcCpwD/A4cAdwdGHf8cDVwL8DjwKLgcML+68AzgR+lR9/KbBDYf+RwALgsXzsXrn8O8DTwJ+BPwEfzeUXAA8CfwB+CUzK5ScBTwF/zcf/OJffCxyS748Avgwsyz9fBkbkfa8FlgL/D1gBLAdOKMT5hvy7Pw48APxTP6/Xu4E7C6/XS/t7HYG9gL8Aa3LsjxXi/XdgCfAQ8N/AloV6PprjXAa8Cwhgj7zv2cC3gZXAfcDHgWGFv9mvgC8Bvwc+k29fXHjuHfNrP7rF7zc8x/Uw8Dtgeq57s8Lf/F35/h7Alfnv9TDw/Vz+y/yYJ/LvfGzhb/Cx/Df+TqOsUPe9wGn59XsU+CawRfF/sSnWyDF09P/DP23kkaoD8E+LPwocA+xC+mZ1bH5D7pz3HZ/fNO/Ob/p/zG8M5f1XkBLaC4At8/ZZed8L8nP9DfCsnKwWAZvn/c+88QqxvBPYtvBGvLmw71vAp5uOL755zwCuISWu0cCvgTPzvtcCq/MxzyIl8yeBkXn/cuCgfH8kOWH38Vo9AOwHKCeW3dp8HZsT05eBucCo/Dv/GPhM3ncYKQFOArYiJcJicv82cHF+3Hjgt8CJhbpWA+8HNst/l5nAZwt1n0JOgC1+x5OBu4BxObbL6Tu5nwf8S/6dtwBeVXieZ+Jt+ht8Nv99t6R1cr+9UPevGn/zPl7D4mvyLTr0/+GfNvJI1QH4p40/EtwMTMn3jwcWFfZtld9Qz83bVwAfL+x/L/DTfP8TwJzCvmGkxPjavP3MG6+POLbPdT07bw/05r0HeENh36HAvfn+a0kt1c0K+1cAB+T7S4D3ANsN8Nr8DDhlI1/Hqwv7REr+zy+UvQJYnO+fQ070eXsP1rZShwOrgImF/e8BrijUtaQplpcD97O2dT8feEsfcf8COLmw/bf0ndy/DcwCxrZ4nlbJ/a/klnihrDm5F+t+A3BPq9ewuY5O/n/4Z+Af97l3IUnvkHSzpMckPQa8CNihcMiDjTsR8WS+u02r/aTWTmPfLqQug8ZjnyYlmDF9xDFc0lmS7pH0R9Ibk6ZY+rNOffn+LoXtRyJidR+xvomUSO6TdKWkV/RRxzhSkmgV/0CvY9Fo0gflDYXjf5rLG7/L/YXji/d3ADZn/d91TB/HExHXkj5MXiPphaQPibl9xNZc9319HAfp25iA6/LIlHf2cyzAyoj4ywDHNNe9S18HbqBN+f+wATi5dxlJuwFfA94HPCcitid9LdYgPP0yYLdCXSIlxwdyUfMUof8ATAEOIfUpj288tI/j+60P2DWXDSgiro+IKaSv7D8C5vRx6P3A85sL23gdm2N/mNRSnBQR2+efZ0dEI5ksB8YWjh/X9NinWP93faCw3eq1mg28DXg78IN+kuzypvp27eM4IuLBiHh3ROxC+vYwc4ARMgP9DWlRd+Nv+ATpAxEASc/dwOfe6P8PG5iTe/fZmvSmWAkg6QRSi3MwzAGOkHSwpGeRTlatIvV1QjqJ+LzC8dvm/Y+Q3sT/1vR8zcc3Ow/4uKTRknYA/hX47kBBStpc0nGSnh0RTwF/JJ38bOXrwD9JepmSPXJiH+h1fAgYK2lzeOZbzNeAL0naMT9mjKRD8/FzgBMk7SVpq/y7kB+7Ju+fIWnbXP+H2/hdvwMcTUrw3+7nuDnABySNlTSSdKK4JUnHSGp8CD2aX4PGazfQ36sv03Pdo4B/Br6fy28BJknaR9IWwCebHteR/w9rj5N7l4mIO4AvAL8hvTleTDqJNRjPvZCUSM4mtTb/Dvi7iPhrPuQzpDfbY5L+iZRw7iO1QO8gnfwq+gYwMR//oxZVfprUl3wrcBtwYy5rx9uBe3N30Mk57la/0wXADOB7pFExPwJGtfE6/oI0auhBSQ/nso+RTjBfk+v9ObBnruf/gP8gncxclJ8X0ocfpJOlT5BGs1yd4zmnv18wIpaSXpMArurn0K+Rzi3cko+/sJ9j9wOulfQnUjfPKRGxOO/7JDA7/73e0l9sTb5HGnX1u/zz6Rz/b0knPH8O3E36vYs6+f9hA2iMsDCzDSBpL1I3z4imfuENfZ5zgGUR8fFBC84MJ3eztkk6GriE1OUzG3g6Io7ahOcbTxrBs2+hdW02KNwtY9a+95D68O8h9WP/48Y+kaQzSS3/zzuxWye45W5mVkNuuZuZ1ZCTu5lZDXXFLHA77LBDjB8/vuowzMx6yg033PBwRIxuta8rkvv48eOZP39+1WGYmfUUSX1OReFuGTOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOroa64iKkd40+9ZJMef+9ZRwxSJGZm3c8tdzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGmoruUv6kKQFkm6XdJ6kLSSNknSZpLvz7cjC8adJWiRpoaRDOxe+mZm1MmBylzQG+AAwOSJeBAwHpgKnAvMiYgIwL28jaWLePwk4DJgpaXhnwjczs1ba7ZbZDNhS0mbAVsAyYAowO++fDRyV708Bzo+IVRGxGFgE7D94IZuZ2UAGTO4R8QDw78ASYDnwh4i4FNgpIpbnY5YDO+aHjAHuLzzF0lxmZmYlaadbZiSpNb47sAuwtaS39feQFmXR4nlPkjRf0vyVK1e2G6+ZmbWhnW6ZQ4DFEbEyIp4CLgQOBB6StDNAvl2Rj18KjCs8fiypG2cdETErIiZHxOTRo0dvyu9gZmZN2knuS4ADJG0lScDBwJ3AXGBaPmYacHG+PxeYKmmEpN2BCcB1gxu2mZn1Z8ApfyPiWkk/AG4EVgM3AbOAbYA5kk4kfQAck49fIGkOcEc+fnpErOlQ/GZm1kJb87lHxOnA6U3Fq0it+FbHzwBmbFpoZma2sXyFqplZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdVQOwtk7ynp5sLPHyV9UNIoSZdJujvfjiw85jRJiyQtlHRoZ38FMzNrNmByj4iFEbFPROwDvAx4ErgIOBWYFxETgHl5G0kTganAJOAwYKak4R2K38zMWtjQbpmDgXsi4j5gCjA7l88Gjsr3pwDnR8SqiFgMLAL2H4xgzcysPRua3KcC5+X7O0XEcoB8u2MuHwPcX3jM0ly2DkknSZovaf7KlSs3MAwzM+tP28ld0ubAkcAFAx3aoizWK4iYFRGTI2Ly6NGj2w3DzMzasCEt98OBGyPiobz9kKSdAfLtily+FBhXeNxYYNmmBmpmZu3bkOT+VtZ2yQDMBabl+9OAiwvlUyWNkLQ7MAG4blMDNTOz9m3WzkGStgL+BnhPofgsYI6kE4ElwDEAEbFA0hzgDmA1MD0i1gxq1GZm1q+2kntEPAk8p6nsEdLomVbHzwBmbHJ0Zma2UXyFqplZDTm5m5nVUFvdMpaMP/WSTX6Oe886YhAiMTPrn1vuZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ20ld0nbS/qBpLsk3SnpFZJGSbpM0t35dmTh+NMkLZK0UNKhnQvfzMxaabfl/hXgpxHxQmBv4E7gVGBeREwA5uVtJE0EpgKTgMOAmZKGD3bgZmbWtwGTu6TtgFcD3wCIiL9GxGPAFGB2Pmw2cFS+PwU4PyJWRcRiYBGw/2AHbmZmfWun5f48YCXwTUk3Sfq6pK2BnSJiOUC+3TEfPwa4v/D4pbnMzMxK0k5y3wx4KfDViNgXeILcBdMHtSiL9Q6STpI0X9L8lStXthWsmZm1p53kvhRYGhHX5u0fkJL9Q5J2Bsi3KwrHjys8fiywrPlJI2JWREyOiMmjR4/e2PjNzKyFAZN7RDwI3C9pz1x0MHAHMBeYlsumARfn+3OBqZJGSNodmABcN6hRm5lZv9pdQ/X9wLmSNgd+B5xA+mCYI+lEYAlwDEBELJA0h/QBsBqYHhFrBj1yMzPrU1vJPSJuBia32HVwH8fPAGZsQlxmZrYJfIWqmVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ21u1iHdZHxp16ySY+/96wjBikSM+tWbbXcJd0r6TZJN0uan8tGSbpM0t35dmTh+NMkLZK0UNKhnQrezMxa25BumddFxD4R0ViR6VRgXkRMAOblbSRNBKYCk4DDgJmShg9izGZmNoBN6XOfAszO92cDRxXKz4+IVRGxGFgE7L8J9ZiZ2QZqN7kHcKmkGySdlMt2iojlAPl2x1w+Bri/8NiluWwdkk6SNF/S/JUrV25c9GZm1lK7J1RfGRHLJO0IXCbprn6OVYuyWK8gYhYwC2Dy5Mnr7Tczs43XVss9Ipbl2xXARaRulock7QyQb1fkw5cC4woPHwssG6yAzcxsYAMmd0lbS9q2cR/4W+B2YC4wLR82Dbg4358LTJU0QtLuwATgusEO3MzM+tZOt8xOwEWSGsd/LyJ+Kul6YI6kE4ElwDEAEbFA0hzgDmA1MD0i1nQkejMza2nA5B4RvwP2blH+CHBwH4+ZAczY5OjMzGyjePoBM7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxryMnu2UTZ1qT/wcn9mneSWu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ21ndwlDZd0k6Sf5O1Rki6TdHe+HVk49jRJiyQtlHRoJwI3M7O+bUjL/RTgzsL2qcC8iJgAzMvbSJoITAUmAYcBMyUNH5xwzcysHW0ld0ljgSOArxeKpwCz8/3ZwFGF8vMjYlVELAYWkRbUNjOzkrTbcv8y8FHg6ULZThGxHCDf7pjLxwD3F45bmsvWIekkSfMlzV+5cuUGB25mZn0bMLlLeiOwIiJuaPM51aIs1iuImBURkyNi8ujRo9t8ajMza0c70w+8EjhS0huALYDtJH0XeEjSzhGxXNLOwIp8/FJgXOHxY4Flgxm0mZn1b8CWe0ScFhFjI2I86UTpLyLibcBcYFo+bBpwcb4/F5gqaYSk3YEJwHWDHrmZmfVpUyYOOwuYI+lEYAlwDEBELJA0B7gDWA1Mj4g1mxypmZm1bYOSe0RcAVyR7z8CHNzHcTOAGZsYm5mZbSRfoWpmVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ+2sobqFpOsk3SJpgaRP5fJRki6TdHe+HVl4zGmSFklaKOnQTv4CZma2vnZa7quA10fE3sA+wGGSDgBOBeZFxARgXt5G0kTScnyTgMOAmZKGdyJ4MzNrrZ01VCMi/pQ3n5V/ApgCzM7ls4Gj8v0pwPkRsSoiFgOLgP0HNWozM+tXW33ukoZLuhlYAVwWEdcCO0XEcoB8u2M+fAxwf+HhS3OZmZmVpK3kHhFrImIfYCywv6QX9XO4Wj3FegdJJ0maL2n+ypUr24vWzMzaskGjZSLiMdIC2YcBD0naGSDfrsiHLQXGFR42FljW4rlmRcTkiJg8evTojQjdzMz60s5omdGSts/3twQOAe4C5gLT8mHTgIvz/bnAVEkjJO0OTACuG+zAzcysb5u1cczOwOw84mUYMCcifiLpN8AcSScCS4BjACJigaQ5wB3AamB6RKzpTPg21I0/9ZJNevy9Zx0xSJGYdZcBk3tE3Ars26L8EeDgPh4zA5ixydGZmdlG8RWqZmY15ORuZlZD7fS5m1k/NrXfHwan79/nH6zILXczsxpycjczqyEndzOzGnJyNzOrIZ9QNbNB0y0nl80tdzOzWnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOroXaW2Rsn6XJJd0paIOmUXD5K0mWS7s63IwuPOU3SIkkLJR3ayV/AzMzW107LfTXw/yJiL+AAYLqkicCpwLyImADMy9vkfVOBSaSFtGfmJfrMzKwkAyb3iFgeETfm+48DdwJjgCnA7HzYbOCofH8KcH5ErIqIxcAiYP/BDtzMzPq2QX3uksaT1lO9FtgpIpZD+gAAdsyHjQHuLzxsaS5rfq6TJM2XNH/lypUbHrmZmfWp7eQuaRvgh8AHI+KP/R3aoizWK4iYFRGTI2Ly6NGj2w3DzMza0NaskJKeRUrs50bEhbn4IUk7R8RySTsDK3L5UmBc4eFjgWWDFbCZ2UC85GB7o2UEfAO4MyK+WNg1F5iW708DLi6UT5U0QtLuwATgusEL2czMBtJOy/2VwNuB2yTdnMv+GTgLmCPpRGAJcAxARCyQNAe4gzTSZnpErBn0yM3MrE8DJveIuJrW/egAB/fxmBnAjE2Iy8zMNoGvUDUzqyEndzOzGnJyNzOrISd3M7Maamucu5mZbZhNHWsPmzbe3i13M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczq6F2VmI6R9IKSbcXykZJukzS3fl2ZGHfaZIWSVoo6dBOBW5mZn1rp+X+LeCwprJTgXkRMQGYl7eRNBGYCkzKj5kpafigRWtmZm0ZMLlHxC+B3zcVTwFm5/uzgaMK5edHxKqIWAwsAvYfpFjNzKxNG9vnvlNELAfItzvm8jHA/YXjluYyMzMr0WCfUG211mq0PFA6SdJ8SfNXrlw5yGGYmQ1tG5vcH5K0M0C+XZHLlwLjCseNBZa1eoKImBURkyNi8ujRozcyDDMza2Vjk/tcYFq+Pw24uFA+VdIISbsDE4DrNi1EMzPbUAOuxCTpPOC1wA6SlgKnA2cBcySdCCwBjgGIiAWS5gB3AKuB6RGxpkOxm5lZHwZM7hHx1j52HdzH8TOAGZsSlJmZbRpfoWpmVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY11LHkLukwSQslLZJ0aqfqMTOz9XUkuUsaDvwXcDgwEXirpImdqMvMzNbXqZb7/sCiiPhdRPwVOB+Y0qG6zMysiSJi8J9UejNwWES8K2+/HXh5RLyvcMxJwEl5c09g4SZWuwPw8CY+x2Dohji6IQbojjgcw1rdEEc3xADdEcdgxLBbRIxutWPABbI3klqUrfMpEhGzgFmDVqE0PyImD9bz9XIc3RBDt8ThGLorjm6IoVvi6HQMneqWWQqMK2yPBZZ1qC4zM2vSqeR+PTBB0u6SNgemAnM7VJeZmTXpSLdMRKyW9D7gZ8Bw4JyIWNCJugoGrYtnE3VDHN0QA3RHHI5hrW6IoxtigO6Io6MxdOSEqpmZVctXqJqZ1ZCTu5lZDfVkcpc0XNLnq46jG0gaJuktVcfRbSRtJ2nbquMwq0pPJveIWAO8TFKr8fRDSkQ8DbxvwANLJmnriuqdLOk24Fbgdkm3SHpZyTEcLenZhe3tJR1VZgzWnSRtUVpdvXpCVdIXgAnABcATjfKIuLDkOAQcBzwvIs6QtCvw3Ii4rsQYPgH8Gfg+674Wvy8rhkIsBwJfB7aJiF0l7Q28JyLeW1L9twLTI+KqvP0qYGZEvKSM+nOdN0fEPk1lN0XEvmXFkOscAbwJGE9hZFxEnDHU4pD0POArwCuAp4HfAB+KiN+VFUOOYxHwEHAV8EvgVxHxh07U1akrVMswCngEeH2hLIBSkzswk/TP8nrgDOBx4IfAfiXG8M58O71QFsDzSoyh4UvAoeTrGiLiFkmvLrH+xxuJPdd/taTHS6wfWn8jruK9djHwB+AGYFUF9XdTHN8jTWZ4dN6eCpwHvLzMICJij9wAPAh4IzBT0mPNjYHB0LPJPSJOqDqG7OUR8VJJNwFExKP5wq3SRMTuZdY3kIi4v6nHbE2J1V8n6X9Ib9wAjgWukPTSHNuNJcQwX9IXSckkgPeTElvZxkbEYRXU26wb4lBEfKew/d18LU65QUhjgVeSkvvewALg6k7U1bPJXdILgK8CO0XEiyS9BDgyIj5dcihP5SmOI8c1mtSSL42krYAPA7tGxEmSJgB7RsRPyowjuz93zUT+kPsAcGeJ9TdaQKc3lR9I+hu9ns57P/AJUjeZgEtZ91tVWX4t6cURcVsFdXdbHJfndSXOZ+2H/iWSRkGpXZhLSFfw/1tEnNzJinq5z/1K4CPA/zT6MiXdHhEvKjmO40j/KC8FZgNvBj4REXNKjOH7pJbhO/IH3ZbAbzrxVa+NWHYg9W0ewtrEdkpEPFJ2LEOdpDuAPYDFpO4QAVHm+YduiUPS4n52R0SU0oWZz0G9Cng1sCtwN3BlRHxj0Ovq4eR+fUTsVzxR1epEVkmxvBA4mPRPOy8iymypPjO7XNNrcUtE7F1mHN1C0hHAJOCZkQllnLyT9OWI+KCkH9M0C2qO4chOx9AUz26tyiPivqEYR7eQtA0pwR8EvI304TJ+sOvp2W4Z4GFJz2dtd8ibgeVlByHpOxHxduCuFmVl+WturTdei+dT8okrSWfTIqE1RMQHSorjv4GtgNeRRu28GShr5FKjT/ffS6qvX43kKWlHCh90VcSRW6wH5aKrIuKWMmOQ9I5W5RHx7ZLjmA+MAH5N6mt/dac+5Ho5uU8nTbzzQkkPkL7yHVdBHJOKG7n/vdRx1cAngZ8C4ySdSzphU/YJ5/kl19eXAyPiJZJujYhP5SGzpYygiojGSdN9IuIrxX2STgGuLCOOQp1HAl8AdgFWALuRzn9M6u9xHYjjFODdrP07fFfSrIg4u8QwiqPXtiB9074RKDW5A4dHxMoyKurZbpmGfLHMsIgodbibpNOAfwa2BJ5sFAN/Bb4WEaUuCi7pOcABOYZrIqKSVWYkHRMRFwxU1sH6r42Il0u6Bvh70nDZ2yNiQhn15xhujIiXNpVVMc79FtIJ5J9HxL6SXge8NSJOGuChgx3HrcArIuKJvL016ZxQqX3/TTE9G/hO2V1lue5Sug178gpVSMlM0n+QLga4QtJXcoIrRUR8JiK2BT4fEdvln20j4jkVJPZ5EfFIRFwSET+JiIclzSszhoLT2izrlJ9I2h74PKlldi9phETHSXpr7m/fXdLcws8VpA+Zsj2VT2QPkzQsIi5n7WiiMol1h8OuofVqbWV6knQRZKlyt+GxpBFVAo4hfaMadL3cLXM+6QqvN+Xt40hDzw4pOY79mwtysj240xXnS5m3AnaQNJK1b5jtSF/FSyPpcOANwJj8oduwHbC6rDgi4sx894eSfgJs0akrAFv4Nem8zw6k7pCGx0nTIZTtsXzy7pfAuZJWUOLfouCbwLWSLsrbRwHnlBlA00nuYcBEoLQRbQWldRv2cnIfVXgjA3xaJc7fkRPr1lSbWN8DfDDXd0Mhhj+SLqAp0zJSv/uRrHvBzuPAh8oKQtJ04NyIeCwiVknaStJ7I2Jmp+vOJ8buk3QI8OeIeDpfj/FCoLQx3pL2AHYCppCmpfgQqfGzG6nFWKqI+GL+9vIq0v/oCRFxUxl1F16L4knu1aRFhB4oI4Ymf8m3T0rahfSNrjMXIUZET/6Q/lhTSZ/Cw4C3AJ8qsf5TWDtud3Hh5xbgfSW/Fh9oUTaior/LR1u9ViXWf3OLsptKfg1uIH2jGgPcD1xE+sApq/6fAC9pUT4Z+HEF/xPfaadsiLwWnwC2J/U4PEj6pndGJ+rq2ROqeb6QrVl7Negw1k6aFRGxXUlxvD/KPevfKoZWJ/DWK6swltJOJuaTd3tH/sfOo5dujYjSRog0XgNJ7we2jIjPlfwa9Hkxn6TbIuLFZcRRqHOd/4n8N7ktIiaWUHfXvBaShgEHRMSv8/YIOtht2LPdMpFOZnaDcyR9nAou/Zf0XFLrcEtJ+7Ju19BWna6/KZa3Av9APplY2LUt5Z5M/BkwJ5+4CuBk0jDRMknSK0hdISfmsjLfa/2Nad+yrCCKI8ok/bFRTBpRVtYapl3xWkCanjv3sb8ib6+ig9ej9GxyB5D096R+vCBdGPGjCsI4h/Q1/MC8vZQ0DXEZ87ocChwPjAW+WCh/nPSmKlO3nEz8GHAS8I+snf7g6yXWD6nL7jTgoohYoDTd7OUl1n+9pHdHxNeKhZJOpMQJzCLiM5I+C3w9It454AM6oytei4JLJb0JuLDx7bJTerlbZiZpvorzctGxwD0RUeoETeqCS/8lvSkiflhWfQORtBNrLxq5LiJWVBnPUJNf/4tILeRGApsMbA4cHREPlhzPDRFR9oV9jbq77bVodCevJp1cbcyzM+jdyL3ccn8N8KJC3+psShyRUFDZpf+S3hYR3wXGS/pw8/6I+GKLh3U6pmNIJ7uvIP3jni3pIxHxg7JjqYrSzKAfZf0LVcqYkZKIeAg4MF+01OhvviQiflFG/S1cI2m/iLi+7Iq77bUos+t79vsAAA8fSURBVDu5l5P7QtKsao15GcZRzVji01n/0v/jS6q7sZTdNiXV146PA/s1Wus50f0cGDLJHTiXdM3FG0l9/tOAUi45L4p00VKZ3UF9eR3wHkn3kQY9lD4rZLe8Fq2ugenUdTG93C1zJemrf2NSqP1IS2c9CeXMwJfPfr8ZmEcXXPrfDZpHIOTX6JYKRmhsHfly97I1uiHyhSovyWVXRsRrqoinavKskMULDi8HXsu6gx/+LyL2Guw6e7nl/q9VB5DPfr8v0tztl5Rdf9OVoOuJkmZibPJTST9j3XMh/1tW5Sqs4QqUvoZr9lS+XZ7nEVlGOuk9JEWXzE5ZseYLDhsep0MXHPZsy71bqMLFqSVN629/RMzudAytFEYxCfhlRFw0wEMGs+5rSd+m5kZFi7hIeiNpzqNxwNmk1tmnImJuvw+sKfUxO2WZ1x5UTdJ+pJF0b46Is/N7902kuY8+2Yl80bPJXdIBpDfOXqQz38OBJ8q6eKkQR6sVXiJKWtmlmymtyvRIp4d8NdXZmBXSC5d0CXXJ7JRVknQjcEhE/F5pwfjzSVNB7APsFRFvHuw6e7lb5j9J0w9cQBra9A4qmOUtumxx6qrkD9uzgN8DZ5IWrtiBNCPhOyKirAuJKlvDVV2yYEkXeioiHpH0zOyUefz7UDK80Do/FpiVhy//UNLNnaiwl5M7EbFI0vCIWAN8U9Kvq4hD0otIs8wVh72VvQhA1f6TdOHUs4FfkBYluEZpCcLzKO8q0ZNJa7iOIX0NLnNx6m5ZsKTbdMvslFUaLmmziFhNWiik+K2lI3m4l5P7k7lldrOkz5Gujtx6gMcMOkmnk85+TySdODyctHzWUEvum0XEpQCSzoiIawAi4i6pvKm780ilKlbkWu8ch6TtUnG5C8l0C3XZ7JQVOw+4UtLDpNfiKnjmNerI3DK93Oe+G/AQqb/9Q6QW48yIWFRyHLcBe5NmHtw7XxH39Yj4uxLq7ppugOLkUC0miur4JGZd9lpMJs1hvi3ppPJjwDtj7TJ8Q4LSfPr/HBG3NpVPBk4v4z3STXLX5c7ApbF2VaoXANtExI2DXV9PttzzrHIzIuJtpEt4P1VhOI15u1fnltoKoKyTqY1ugFeSvjl8P28fQ/nzZuydJ4cS608UVcbwt27qEjkHeG9ENFpnryIl+8qWlavI+ObEDhAR8yWNLz+cajW+zTaV/bZT9fVkco+INZJGS9o8Iv5acTjzlZZ1+xopof6JtRdWdVSjG0DS8cDrIuKpvP3fpL7m0kTE8DLra1F/47VouYZryeE83kjsObar85wiQ03XzMg4FPVyt8z/AC8F5rLu+PLS51MpxDQe2K5Va6XD9S4kLUD8+7w9knSl7J5lxtENWnUBldEt1FTfl0hXI55H6io6FngU+CFAJ76CdyNJ5wG/iNYzMv5tRBxbTWRDQ0+23LNl+WcYqW+zEpLWSxp58rD78pnxMpwF3CSpMXfGa4BPllR3V1CXrOGaNRahPr2p/EBSsi9lArEu8EHgIknH0WJGxsqiGiJ6ueX+vIj4XRfEcQ3pG8StpP7lF+X7zwFObowgKSGO5wIvz5vXlj2VadXyNAP7AGew7tQUjwOXR8SjlQRmNM3IuKDC2SmHlF5O7r8kjWW+njR+9qqIKH3KX0nnA2dGxIK8PRH4COlCngsjYp/+Hj9IMYg0xOx5EXGGpF2B50ZEKX3/3UTSRyPic01lp0TEV6qKyawKw6oOYGNFxKtJUw+cDYwELpHU8flcWnhhI7HnuO4A9i35W8VM0tJdb83bHZuMqAdMbVF2fNlBmFWtZ/vc8/Cyg/LP9qRl7a7q90GdsVDSV0lzRUA6efZbpcVvn+r7YYPq5ZEWZL4JICIezRd4DRnqkjVc1bQIsllVeja5A1eSxjZ/BvjfCodEHg+8l3TySKSrU/+JlNhfV1IMT+Wx/43VoEYDT5dUd7foijVco2kRZLOq9HKf+/aki3deTVqo42ngNxHxiUoDq0AejXAs6cTubNKUtx9vHu89VKjiNVwlfYr0gdLxRZDN+tKzyR1A0l6kYX8HkYaZLSlrtRtJcyLiLXn6gfVexChxCbEczwtJExIJmBcRpcyE2G20/hquBwGlruGqtYsgryHNI9KxRZDN+tKzyV3SPaR1VK8idYVcW2bXjKSDSN8Wljbt2g1YVsYcN5JG9be/jAVDuk2eO/xvomkNV8/nbkNNL/e5T4iIKvuVP0aaFGmddSBzMvkSUMakSDeQvjUUp11sbAflzXHTTYY1dcM8QsmjwgpDU3ePiDMljQN2HopDU606Pdtyr5r6WbpNTYtEW3kkfZ40QVdxDddbI+JjJcbwVdK3utdHxF55OohLI2K/AR5qNmh6ueVeta6ZFKlFS3HIXsQUER/Rumu4zooS13DNhvzQVKuek/vGu17Su/uYFKns6XZnkluKpCtjHydNUjUkW4oRcSFwofIarhWE4KGpVrmevUK1QdJnJb0s3/9SiVV/EDhB0hWSvpB/rgTeBZxSYhyQWorTSXPbk+dRGVItRUkH5L/FhZL2lXQ7cDvwkKTDSg7nP4CLgB0lzSCd8P+3kmOwIa4OLff5wEckTSLNM1OKiHgIOLBpUqRLKpoUyS3F7lnDlYg4V9INrB2aetRQHZpq1em5E6qSTiZdkbokb28JXEC6zPynEfGZKuOrQuEippcB32IIXsQk6ebGJG2S7oyIvQr7boqIfUuOZzhp/dBnGlCN/1mzMvRiy316RPw3PLMoxY+BC0nDD68lTUcwpDS1FGFothSL31T+3LSv1BaMpPeT5nJ/iHQhU2No6lBbZs8q1IvJ/VmStibNIfIj4AsR8V0ASVtVGlm1tgIaXTNDcQmzqtdwLToF2DMiqjiZawb0ZnL/AvA7UiK7jZTsdwWmka5YHXIk/StpUewfkpLZNyVdEBGfrjay8lS9hmuT+4E/VB2EDW091+cOz/RnQvpw+gxwKHAj8KGIeLiywCoi6U7SHPJ/ydtbAjcW+52t8yR9ON+dBOwJXAKsauyvcn1fG3p6seVORKzJd9cAH+7v2CHiXlLXw1/y9gjgnsqiGboaa/kuyT+bs3ZIau+1oqyn9WRyt0TS2aSksQpYIOmyvP03pLHVVqKI+BSkmSmbRyrl2SrNStOT3TKWSJrW3/6ImF1WLLaWpBsj4qUDlZl1klvuPczJu7tIOhx4AzBG0n8Udm0HrK4mKhuqeja5F05eFf0BuCEibi47nipJmkA6sTyRwrC/iBiKU/5WaRlpXqEjWXd+oceBD1USkQ1ZPdstI+l7wGTSRUwAR5CmH3ghcEFEfK6q2Mom6WrSRTONeeRPIP1tT680sCFK0jbAeNL5j3sao5jMytTLyf1nwJsi4k95exvgB8DRpNb7xCrjK5OkGyLiZcV55CVdFREHVR3bUCJpM9IEYSeQRssMA8YC3wT+JSKeqjA8G2J6eVbIXYHisnpPAbtFxJ8pjC0eIv4iaRhwt6T3SToa2LHqoIagzwOjgOdFxMvyfDbPB7YnretqVppebrl/gtRKvzgX/R0wl3QF66yIOK6q2MomaT/gTlISOZM0M+LnIuKaSgMbYiTdDbwgmt5U+aK7uyJiQjWR2VDUs8kdQNJk4JWkS+6vjoj5FYdkQ5ik30bECzZ0n1kn9OxoGYCImC9pCXmEiKRdh9K0qpJ+TD9XPkbEkSWGY3CHpHdExLeLhZLeBtxVUUw2RPVsy13SkaQumF2AFaQ++LsiYlKlgZVI0mv62x8RV5YVi4GkMaTpp/9MGgoZpKUOtwSOjogHKgzPhpheTu63kNYM/XlE7JtXRHprRJxUcWg2xEl6PWnyMAELImJexSHZENTLyX1+REzOSX7fiHha0nURsX/VsZVN0iuBTwK7kbraBIQvYjIbunq5z/2xPLb9KuBcSSsYupd4f4N0BeQNpJkyzWyI6+WW+9akKW4FHEca/nfuUFz9RtK1EfHyquMws+7Rs8kdQNJzgf1JJ66uj4gHKw6pEpLOIq1MdSHrLg5xY2VBmVmleja5S3oX8K/AL0it99cAZ0TEOZUGVgFJl7cojoh4fenBmFlX6OXkvhA4sNENI+k5wK8jYs9qIzMzq14vn1BdSppKteFx0sLEQ0aLaY8DeJh0te7iCkIysy7Rc8m9kNAeAK6VdDEpqU0BrqsssGps26JsPPAvkj4ZEeeXHI+ZdYme65aR1O8c5Y11LIcySaNIF3d5WTezIarnkru1R9JNecpZMxuCenk+d+tDvvz90arjMLPq9Fyfu60l6TbWnxVyFGktz3eUH5GZdQt3y/QwSbs1FQXwSEQ8UUU8ZtY9erZbRtJsSdsXtkdKGlIXMEXEfU0/S5zYzQx6OLkDL4mIxxobEfEo4BOIZmb0dnIfJmlkYyMP//M5BDMzejsZfgH4taQf5O1jgBkVxmNm1jV6+oSqpImk1ZgEzIuIOyoOycysK/Rccpe0XUT8MXfDrCcifl92TGZm3aYXk/tPIuKNkhaz7hhvLy1nZpb1XHI3M7OB9exoGUnrrSjfqszMbCjqudEykrYAtgJ2yEMhlXdtB+xSWWBmZl2k55I78B7gg6REfgNrk/sfgf+qKigzs27Ss33ukt4fEWdXHYeZWTfq2T534EFJ2wJI+rikCyV5cQozM3o7uX8iIh6X9CrgUGA28NWKYzIz6wq9nNzX5NsjgK9GxMXA5hXGY2bWNXo5uT8g6X+AtwD/K2kEvf37mJkNml4+oboVcBhwW0TcLWln4MURcWnFoZmZVa5nk3uDpB2BLRrbEbGkwnDMzLpCz3ZjSDpS0t3AYuDKfPt/1UZlZtYdeja5A2cCBwC/jYjdgUOAX1UbkplZd+jl5P5URDxCWpFpWERcDuxTdVBmZt2gF6cfaHhM0jbAL4FzJa0AVlcck5lZV+jZE6qStgb+Qppb5jjg2cC5uTVvZjak9WxyNzOzvvVct4ykx0krMDVmg2x8OjVWYtquksDMzLqIW+5mZjXUiy33LYCTgT2AW4FzIsInUs3MCnqu5S7p+8BTwFXA4cB9EXFKtVGZmXWXXkzut0XEi/P9zYDrIsLzuJuZFfTiRUxPNe64O8bMrLVebLmvAZ5obAJbAk/i0TJmZs/oueRuZmYD68VuGTMzG4CTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ39fwXg0K34QHa1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[\"category\"].value_counts().head(10).plot(kind=\"bar\",title=\"annotations category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:22.928826Z",
     "iopub.status.busy": "2021-04-29T16:32:22.925770Z",
     "iopub.status.idle": "2021-04-29T16:32:23.176249Z",
     "shell.execute_reply": "2021-04-29T16:32:23.177291Z"
    },
    "id": "UxvCar9RED-j",
    "outputId": "f74b7df2-293c-485c-da10-d6b9deba255e",
    "papermill": {
     "duration": 0.359842,
     "end_time": "2021-04-29T16:32:23.177460",
     "exception": false,
     "start_time": "2021-04-29T16:32:22.817618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd950cec690>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[\"super_category\"].value_counts().head(10).plot(kind=\"bar\",title=\"annotations super category distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ut0e6sLmED-k",
    "papermill": {
     "duration": 0.112914,
     "end_time": "2021-04-29T16:32:23.396134",
     "exception": false,
     "start_time": "2021-04-29T16:32:23.283220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:23.581971Z",
     "iopub.status.busy": "2021-04-29T16:32:23.570914Z",
     "iopub.status.idle": "2021-04-29T16:32:23.584604Z",
     "shell.execute_reply": "2021-04-29T16:32:23.584035Z"
    },
    "id": "8ABEczYtTURi",
    "papermill": {
     "duration": 0.126881,
     "end_time": "2021-04-29T16:32:23.584730",
     "exception": false,
     "start_time": "2021-04-29T16:32:23.457849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RepeatedStratifiedGroupKFold():\n",
    "\n",
    "    def __init__(self, n_splits=5, n_repeats=1, random_state=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_repeats = n_repeats\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        k = self.n_splits\n",
    "        def eval_y_counts_per_fold(y_counts, fold):\n",
    "            y_counts_per_fold[fold] += y_counts\n",
    "            std_per_label = []\n",
    "            for label in range(labels_num):\n",
    "                label_std = np.std(\n",
    "                    [y_counts_per_fold[i][label] / y_distr[label] for i in range(k)]\n",
    "                )\n",
    "                std_per_label.append(label_std)\n",
    "            y_counts_per_fold[fold] -= y_counts\n",
    "            return np.mean(std_per_label)\n",
    "            \n",
    "        rnd = check_random_state(self.random_state)\n",
    "        for repeat in range(self.n_repeats):\n",
    "            #print(np.max(y))\n",
    "            labels_num = np.max(y) + 1\n",
    "            y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "            y_distr = Counter()\n",
    "            for label, g in zip(y, groups):\n",
    "                y_counts_per_group[g][label] += 1\n",
    "                y_distr[label] += 1\n",
    "\n",
    "            y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "            groups_per_fold = defaultdict(set)\n",
    "        \n",
    "            groups_and_y_counts = list(y_counts_per_group.items())\n",
    "            rnd.shuffle(groups_and_y_counts)\n",
    "\n",
    "            for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "                best_fold = None\n",
    "                min_eval = None\n",
    "                for i in range(k):\n",
    "                    fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "                    if min_eval is None or fold_eval < min_eval:\n",
    "                        min_eval = fold_eval\n",
    "                        best_fold = i\n",
    "                y_counts_per_fold[best_fold] += y_counts\n",
    "                groups_per_fold[best_fold].add(g)\n",
    "            \n",
    "            all_groups = set(groups)\n",
    "            for i in range(k):\n",
    "                train_groups = all_groups - groups_per_fold[i]\n",
    "                test_groups = groups_per_fold[i]\n",
    "\n",
    "                train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "                test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "                yield train_indices, test_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:23.707335Z",
     "iopub.status.busy": "2021-04-29T16:32:23.706758Z",
     "iopub.status.idle": "2021-04-29T16:32:23.710849Z",
     "shell.execute_reply": "2021-04-29T16:32:23.710382Z"
    },
    "id": "3brGgIm0ED-l",
    "papermill": {
     "duration": 0.068728,
     "end_time": "2021-04-29T16:32:23.710960",
     "exception": false,
     "start_time": "2021-04-29T16:32:23.642232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def kfold_split(config,df):\n",
    "    seed_all()\n",
    "    df[\"folds\"]=-1\n",
    "    #kf = GroupKFold(n_splits=config.general[\"n_folds\"])\n",
    "    kf = RepeatedStratifiedGroupKFold(n_splits=config.general[\"n_folds\"], random_state=config.general[\"seed\"])\n",
    "    #for fold, (_, val_index) in enumerate(kf.split(df,groups=df[\"image_id\"])):\n",
    "    for fold, (_, val_index) in enumerate(kf.split(df,df.category_id, df.image_id)):\n",
    "            df.loc[val_index, \"folds\"] = fold\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:23.831947Z",
     "iopub.status.busy": "2021-04-29T16:32:23.831273Z",
     "iopub.status.idle": "2021-04-29T16:32:31.796160Z",
     "shell.execute_reply": "2021-04-29T16:32:31.794805Z"
    },
    "id": "J3HS1q84ED-l",
    "papermill": {
     "duration": 8.026423,
     "end_time": "2021-04-29T16:32:31.796273",
     "exception": false,
     "start_time": "2021-04-29T16:32:23.769850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_df=kfold_split(annot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:31.911405Z",
     "iopub.status.busy": "2021-04-29T16:32:31.910481Z",
     "iopub.status.idle": "2021-04-29T16:32:32.081079Z",
     "shell.execute_reply": "2021-04-29T16:32:32.080560Z"
    },
    "id": "iP7jcmIKED-l",
    "outputId": "4e027238-31e5-4832-97c8-e83c6c9bcebe",
    "papermill": {
     "duration": 0.229846,
     "end_time": "2021-04-29T16:32:32.081194",
     "exception": false,
     "start_time": "2021-04-29T16:32:31.851348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd950b87190>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]==0][\"category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Test annotations category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:32.211714Z",
     "iopub.status.busy": "2021-04-29T16:32:32.210792Z",
     "iopub.status.idle": "2021-04-29T16:32:32.464022Z",
     "shell.execute_reply": "2021-04-29T16:32:32.465199Z"
    },
    "id": "4_wUBaCAED-n",
    "outputId": "ffcf435d-e0da-4ed1-9a71-91b28db0b7ef",
    "papermill": {
     "duration": 0.327889,
     "end_time": "2021-04-29T16:32:32.465378",
     "exception": false,
     "start_time": "2021-04-29T16:32:32.137489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd950c1c210>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]!=0][\"category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Train annotations category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:32.697885Z",
     "iopub.status.busy": "2021-04-29T16:32:32.696944Z",
     "iopub.status.idle": "2021-04-29T16:32:32.895823Z",
     "shell.execute_reply": "2021-04-29T16:32:32.894891Z"
    },
    "id": "9-jU6eJQED-n",
    "outputId": "be0a3412-e3f6-41b0-f83c-2f6626145584",
    "papermill": {
     "duration": 0.314919,
     "end_time": "2021-04-29T16:32:32.895934",
     "exception": false,
     "start_time": "2021-04-29T16:32:32.581015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd94808ec90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]==0][\"super_category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Test annotations super category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:33.029105Z",
     "iopub.status.busy": "2021-04-29T16:32:33.023483Z",
     "iopub.status.idle": "2021-04-29T16:32:33.178999Z",
     "shell.execute_reply": "2021-04-29T16:32:33.179429Z"
    },
    "id": "3sM5GkMeED-n",
    "outputId": "dd9794d1-b555-4316-d4c0-c6173157f18e",
    "papermill": {
     "duration": 0.222457,
     "end_time": "2021-04-29T16:32:33.179550",
     "exception": false,
     "start_time": "2021-04-29T16:32:32.957093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd948022790>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]==0][\"super_category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Train annotations super category distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C1dlvNlED-n",
    "papermill": {
     "duration": 0.06293,
     "end_time": "2021-04-29T16:32:33.307874",
     "exception": false,
     "start_time": "2021-04-29T16:32:33.244944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:33.459969Z",
     "iopub.status.busy": "2021-04-29T16:32:33.459132Z",
     "iopub.status.idle": "2021-04-29T16:32:33.462776Z",
     "shell.execute_reply": "2021-04-29T16:32:33.462234Z"
    },
    "id": "I1wuP7ZpED-o",
    "papermill": {
     "duration": 0.088141,
     "end_time": "2021-04-29T16:32:33.462879",
     "exception": false,
     "start_time": "2021-04-29T16:32:33.374738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def register_dataset(config,fold):\n",
    "    train_dataset_name=f\"my_dataset_train_{fold}\"\n",
    "    test_dataset_name=f\"my_dataset_test_{fold}\"\n",
    "    train_dataset_file=f\"my_dataset_train_{fold}.json\"\n",
    "    test_dataset_file=f\"my_dataset_test_{fold}.json\"\n",
    "    \n",
    "    train_annot_df=annot_df[annot_df[\"folds\"]!=fold]\n",
    "    test_annot_df=annot_df[annot_df[\"folds\"]==fold]\n",
    "    train_annot_df=train_annot_df.drop([\"normal_category\",\"normal_category_id\"],axis=1)\n",
    "    test_annot_df=test_annot_df.drop([\"normal_category\",\"normal_category_id\"],axis=1)\n",
    "\n",
    "    train_images_df=images_df[images_df[\"id\"].apply(lambda i:True if i in list(train_annot_df[\"image_id\"].unique()) else False)]\n",
    "    test_images_df=images_df[images_df[\"id\"].apply(lambda i:True if i in list(test_annot_df[\"image_id\"].unique()) else False)]\n",
    "    \n",
    "    train_annot=annot.copy()\n",
    "    test_annot=annot.copy()\n",
    "    \n",
    "    train_annot[\"annotations\"]=train_annot_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    train_annot[\"images\"]=train_images_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    test_annot[\"annotations\"]=test_annot_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    test_annot[\"images\"]=test_images_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    \n",
    "    json.dump(train_annot,open(train_dataset_file,\"w\"))\n",
    "    json.dump(test_annot,open(test_dataset_file,\"w\"))\n",
    "    \n",
    "    if train_dataset_name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(train_dataset_name)\n",
    "        MetadataCatalog.remove(train_dataset_name)\n",
    "    if test_dataset_name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(test_dataset_name)\n",
    "        MetadataCatalog.remove(test_dataset_name)\n",
    "        \n",
    "    register_coco_instances(train_dataset_name, {}, train_dataset_file, os.path.join(DATASET_PATH,\"data\"))\n",
    "    register_coco_instances(test_dataset_name, {}, test_dataset_file, os.path.join(DATASET_PATH,\"data\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3AeKe2eED-o",
    "papermill": {
     "duration": 0.06364,
     "end_time": "2021-04-29T16:32:33.592274",
     "exception": false,
     "start_time": "2021-04-29T16:32:33.528634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess and augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:33.739401Z",
     "iopub.status.busy": "2021-04-29T16:32:33.738670Z",
     "iopub.status.idle": "2021-04-29T16:32:33.741577Z",
     "shell.execute_reply": "2021-04-29T16:32:33.741968Z"
    },
    "id": "tFNeqTcXED-p",
    "papermill": {
     "duration": 0.08528,
     "end_time": "2021-04-29T16:32:33.742091",
     "exception": false,
     "start_time": "2021-04-29T16:32:33.656811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def get_train_transforms(config):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.1, sat_shift_limit= 0.1, \n",
    "                                     val_shift_limit=0.1, p=0.8),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.3, \n",
    "                                           contrast_limit=0.2, p=0.8),\n",
    "            ],p=0.7),\n",
    "            A.Rotate (limit=15, interpolation=1, border_mode=4, value=None, mask_value=None, p=0.8),\n",
    "            \n",
    "            \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomResizedCrop (config.preprocess.height, config.preprocess.width, scale=(0.8, 0.8), ratio=(0.75, 1.3333333333333333), interpolation=1, always_apply=False, p=0.1),\n",
    "            A.OneOf([\n",
    "            A.Resize(height=config.preprocess.height, width=config.preprocess.width, p=0.2),\n",
    "            A.LongestMaxSize(max_size=config.preprocess.longest_max_size, p=0.2),\n",
    "            A.SmallestMaxSize(max_size=config.preprocess.smallest_max_size, p=0.2),\n",
    "                \n",
    "            ], p=1),\n",
    "            A.CLAHE(clip_limit=[1,4],p=1),\n",
    "            \n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='coco',\n",
    "            min_area=0.5, \n",
    "            min_visibility=0.5,\n",
    "            label_fields=['category_id']\n",
    "        )\n",
    "    )\n",
    "\n",
    "@inject_config\n",
    "def get_valid_transforms(config):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.SmallestMaxSize(max_size=config.preprocess.smallest_max_size, p=1.0),\n",
    "            A.CLAHE(clip_limit=[3,3],p=1),   \n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='coco',\n",
    "            min_area=0.5, \n",
    "            min_visibility=0.5,\n",
    "            label_fields=['category_id']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_transforms(train=True):\n",
    "    if (train):\n",
    "        return get_train_transforms()\n",
    "    return get_valid_transforms()\n",
    "albu_transformations=get_transforms(train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHP92WtLGeOG",
    "papermill": {
     "duration": 0.062073,
     "end_time": "2021-04-29T16:32:33.868539",
     "exception": false,
     "start_time": "2021-04-29T16:32:33.806466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Personal mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:34.015631Z",
     "iopub.status.busy": "2021-04-29T16:32:33.995181Z",
     "iopub.status.idle": "2021-04-29T16:32:34.017814Z",
     "shell.execute_reply": "2021-04-29T16:32:34.018304Z"
    },
    "id": "MbnJvmRmED-r",
    "papermill": {
     "duration": 0.087587,
     "end_time": "2021-04-29T16:32:34.018437",
     "exception": false,
     "start_time": "2021-04-29T16:32:33.930850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PersonalMapper (detectron2.data.DatasetMapper):\n",
    "    \"\"\"\n",
    "    Define a detectron2 personal mapper in order to be able to use albumentation augmentations\n",
    "    \"\"\"\n",
    "    def __call__(self, dataset_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.\n",
    "\n",
    "        Returns:\n",
    "            dict: a format that builtin models in detectron2 accept\n",
    "        \"\"\"\n",
    "        dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "        # USER: Write your own image loading if it's not from a file\n",
    "        image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n",
    "        #utils.check_image_size(dataset_dict, image)\n",
    "\n",
    "        \n",
    "        \n",
    "        ##### ADDED PART\n",
    "\n",
    "        #print(\"dataset dict : \",dataset_dict)\n",
    "\n",
    "        annos = [\n",
    "            obj for obj in dataset_dict[\"annotations\"]\n",
    "        ]\n",
    "        annos_bbox = [\n",
    "            obj[\"bbox\"] for obj in dataset_dict[\"annotations\"]\n",
    "        ]\n",
    "        annos_categroy_id = [\n",
    "            obj[\"category_id\"] for obj in dataset_dict.pop(\"annotations\")\n",
    "        ]\n",
    "        \n",
    "        if albu_transformations is not None:\n",
    "            transform_list=get_transforms(self.is_train)\n",
    "            image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            transform_result=transform_list(image=image,bboxes=annos_bbox,category_id=annos_categroy_id)\n",
    "            image=cv2.cvtColor(transform_result[\"image\"], cv2.COLOR_RGB2BGR)\n",
    "            annos=[annos[i] for i in range(len(transform_result[\"bboxes\"]))]\n",
    "            for i in range(len(annos)):\n",
    "                annos[i][\"bbox\"]=list(transform_result[\"bboxes\"][i])\n",
    "                annos[i][\"category_id\"]=transform_result[\"category_id\"][i]\n",
    "        \n",
    "        dataset_dict[\"annotations\"]=annos\n",
    "        \n",
    "        \n",
    "        ##### ADDED PART\n",
    "        \n",
    "        # USER: Remove if you don't do semantic/panoptic segmentation.\n",
    "        if \"sem_seg_file_name\" in dataset_dict:\n",
    "            sem_seg_gt = utils.read_image(dataset_dict.pop(\"sem_seg_file_name\"), \"L\").squeeze(2)\n",
    "        else:\n",
    "            sem_seg_gt = None\n",
    "\n",
    "        aug_input = T.AugInput(image, sem_seg=sem_seg_gt)\n",
    "        transforms = self.augmentations(aug_input)\n",
    "        image, sem_seg_gt = aug_input.image, aug_input.sem_seg\n",
    "\n",
    "        image_shape = image.shape[:2]  # h, w\n",
    "        # Pytorch's dataloader is efficient on torch.Tensor due to shared-memory,\n",
    "        # but not efficient on large generic data structures due to the use of pickle & mp.Queue.\n",
    "        # Therefore it's important to use torch.Tensor.\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))\n",
    "        if sem_seg_gt is not None:\n",
    "            dataset_dict[\"sem_seg\"] = torch.as_tensor(sem_seg_gt.astype(\"long\"))\n",
    "\n",
    "        # USER: Remove if you don't use pre-computed proposals.\n",
    "        # Most users would not need this feature.\n",
    "        if self.proposal_topk is not None:\n",
    "            utils.transform_proposals(\n",
    "                dataset_dict, image_shape, transforms, proposal_topk=self.proposal_topk\n",
    "            )\n",
    "\n",
    "        if not self.is_train:\n",
    "            # USER: Modify this if you want to keep them for some reason.\n",
    "            dataset_dict.pop(\"annotations\", None)\n",
    "            dataset_dict.pop(\"sem_seg_file_name\", None)\n",
    "            return dataset_dict\n",
    "\n",
    "        if \"annotations\" in dataset_dict:\n",
    "            # USER: Modify this if you want to keep them for some reason.\n",
    "            for anno in dataset_dict[\"annotations\"]:\n",
    "                if not self.use_instance_mask:\n",
    "                    anno.pop(\"segmentation\", None)\n",
    "                if not self.use_keypoint:\n",
    "                    anno.pop(\"keypoints\", None)\n",
    "\n",
    "            # USER: Implement additional transformations if you have other types of data\n",
    "            annos = [\n",
    "                utils.transform_instance_annotations(\n",
    "                    obj, transforms, image_shape, keypoint_hflip_indices=self.keypoint_hflip_indices\n",
    "                )\n",
    "                for obj in dataset_dict.pop(\"annotations\")\n",
    "                if obj.get(\"iscrowd\", 0) == 0\n",
    "            ]\n",
    "            instances = utils.annotations_to_instances(\n",
    "                annos, image_shape, mask_format=self.instance_mask_format\n",
    "            )\n",
    "\n",
    "            # After transforms such as cropping are applied, the bounding box may no longer\n",
    "            # tightly bound the object. As an example, imagine a triangle object\n",
    "            # [(0,0), (2,0), (0,2)] cropped by a box [(1,0),(2,2)] (XYXY format). The tight\n",
    "            # bounding box of the cropped triangle should be [(1,0),(2,1)], which is not equal to\n",
    "            # the intersection of original bounding box and the cropping box.\n",
    "            if self.recompute_boxes:\n",
    "                instances.gt_boxes = instances.gt_masks.get_bounding_boxes()\n",
    "            dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "        return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uguNAheFED-v",
    "papermill": {
     "duration": 0.060795,
     "end_time": "2021-04-29T16:32:34.141075",
     "exception": false,
     "start_time": "2021-04-29T16:32:34.080280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:34.278953Z",
     "iopub.status.busy": "2021-04-29T16:32:34.277059Z",
     "iopub.status.idle": "2021-04-29T16:32:34.279521Z",
     "shell.execute_reply": "2021-04-29T16:32:34.279940Z"
    },
    "id": "ENHtg1FBED-v",
    "papermill": {
     "duration": 0.077709,
     "end_time": "2021-04-29T16:32:34.280057",
     "exception": false,
     "start_time": "2021-04-29T16:32:34.202348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PersonalTrainer (detectron2.engine.defaults.DefaultTrainer):\n",
    "    \"\"\"\n",
    "    Personal trainer based on detectron2 DefaultTrainer to add some hooks and change data loaders\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg , config=c):\n",
    "        super().__init__(cfg)\n",
    "        self.metric=0\n",
    "        self.checkpointer.save_dir=MODELS_PATH\n",
    "\n",
    "        \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        def save_best_model():\n",
    "            \n",
    "            metric=self.test(self.cfg, self.model)[\"bbox\"][\"AP50\"]\n",
    "            if(metric>self.metric):\n",
    "                self.metric=metric\n",
    "                self.checkpointer.save(\"best_model\") # it will add .pth alone\n",
    "                \n",
    "        steps_per_epoch=annot_df.shape[0]//c.model[\"images_per_batch\"]\n",
    "        model_checkpointer=EvalHook(steps_per_epoch, save_best_model)\n",
    "        hooks.insert(-1,model_checkpointer)\n",
    "        return hooks\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        \n",
    "        #return build_detection_train_loader(cfg,mapper=DatasetMapper(cfg,is_train=True,))\n",
    "        return build_detection_train_loader(cfg,mapper=PersonalMapper(cfg,is_train=True,augmentations=[]))\n",
    "    @classmethod\n",
    "    def build_test_loader(cls, cfg, dataset_name):\n",
    "        \n",
    "        #return build_detection_test_loader( cfg,dataset_name,mapper=DatasetMapper(cfg,is_train=False,))\n",
    "        return build_detection_test_loader( cfg,dataset_name,mapper=PersonalMapper(cfg,is_train=False,augmentations=[]))\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        return COCOEvaluator(dataset_name, (\"bbox\",), False, output_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rBP7049ED-w",
    "papermill": {
     "duration": 0.061871,
     "end_time": "2021-04-29T16:32:34.403498",
     "exception": false,
     "start_time": "2021-04-29T16:32:34.341627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare config params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:34.544052Z",
     "iopub.status.busy": "2021-04-29T16:32:34.542318Z",
     "iopub.status.idle": "2021-04-29T16:32:34.544765Z",
     "shell.execute_reply": "2021-04-29T16:32:34.545177Z"
    },
    "id": "9ytbXLftED-w",
    "papermill": {
     "duration": 0.079362,
     "end_time": "2021-04-29T16:32:34.545290",
     "exception": false,
     "start_time": "2021-04-29T16:32:34.465928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def get_config(config,fold=0):\n",
    "    \"\"\"\n",
    "    Detectron2 config\n",
    "    \"\"\"\n",
    "    steps_per_epoch=annot_df.shape[0]//config.model[\"images_per_batch\"]\n",
    "    train_dataset_name=f\"my_dataset_train_{fold}\"\n",
    "    test_dataset_name=f\"my_dataset_test_{fold}\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.MODEL.DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{config.model['model_name']}.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
    "    cfg.DATASETS.TEST = (test_dataset_name,)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{config.model['model_name']}.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = config.model[\"images_per_batch\"]\n",
    "    cfg.SOLVER.BASE_LR = config.model[\"base_lr\"]  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = steps_per_epoch*config.model[\"epochs\"]  # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "    cfg.SOLVER.STEPS = (steps_per_epoch*8,)\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = config.model[\"batchsize_per_image\"]   # faster, and good enough for this toy dataset (default: 512)\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = config.model[\"num_classes\"]  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "    cfg.TEST.EVAL_PERIOD=0\n",
    "    cfg.OUTPUT_DIR = LOGS_PATH\n",
    "    cfg.OUTPUT_DIR_BEST = LOGS_PATH\n",
    "    cfg.SOLVER.AMP.ENABLED = True\n",
    "    #cfg.MODEL.WEIGHTS = \"../input/trash-taco-heavy-augs/models/best_model.pth\"\n",
    "\n",
    "    cfg.SEED = config.general[\"seed\"]\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(cfg.OUTPUT_DIR_BEST, exist_ok=True)\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:34.675789Z",
     "iopub.status.busy": "2021-04-29T16:32:34.674923Z",
     "iopub.status.idle": "2021-04-29T16:32:34.693322Z",
     "shell.execute_reply": "2021-04-29T16:32:34.692831Z"
    },
    "id": "QTymd5RxED-w",
    "papermill": {
     "duration": 0.086489,
     "end_time": "2021-04-29T16:32:34.693443",
     "exception": false,
     "start_time": "2021-04-29T16:32:34.606954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg=get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqG_5mO6ED-w",
    "papermill": {
     "duration": 0.062295,
     "end_time": "2021-04-29T16:32:34.818327",
     "exception": false,
     "start_time": "2021-04-29T16:32:34.756032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:34.951676Z",
     "iopub.status.busy": "2021-04-29T16:32:34.949752Z",
     "iopub.status.idle": "2021-04-29T16:32:34.952367Z",
     "shell.execute_reply": "2021-04-29T16:32:34.952808Z"
    },
    "id": "t-dS-_KiED-w",
    "papermill": {
     "duration": 0.072597,
     "end_time": "2021-04-29T16:32:34.952924",
     "exception": false,
     "start_time": "2021-04-29T16:32:34.880327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    \"\"\"\n",
    "    train function that help train on the dataset and validate on a certain fold\n",
    "    \"\"\"\n",
    "    seed_all()\n",
    "    register_dataset(fold)\n",
    "    cfg=get_config(fold)\n",
    "    #trainer = DefaultTrainer(cfg)\n",
    "    trainer = PersonalTrainer(cfg) \n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.evaluator = COCOEvaluator(f\"my_dataset_test_{fold}\", (\"bbox\",), False, output_dir=None)\n",
    "    trainer.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T16:32:35.085433Z",
     "iopub.status.busy": "2021-04-29T16:32:35.084152Z",
     "iopub.status.idle": "2021-04-30T00:38:03.879387Z",
     "shell.execute_reply": "2021-04-30T00:38:03.878889Z"
    },
    "id": "9UNwptwrED-x",
    "outputId": "c6dddf10-ec92-4a7a-ff1d-5f456666468b",
    "papermill": {
     "duration": 29128.86501,
     "end_time": "2021-04-30T00:38:03.879521",
     "exception": false,
     "start_time": "2021-04-29T16:32:35.014511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/29 16:32:42 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=30, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=116, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/29 16:32:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 16:32:42 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 16:32:42 d2.data.datasets.coco]: \u001b[0mLoaded 1190 images in COCO format from my_dataset_train_0.json\n",
      "\u001b[32m[04/29 16:32:42 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1190 images left.\n",
      "\u001b[32m[04/29 16:32:42 d2.data.build]: \u001b[0mDistribution of instances among all 28 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|    Bottle     | 350          |    Carton     | 200          |  Bottle cap   | 231          |\n",
      "|      Can      | 218          |    Pop tab    | 79           |      Cup      | 153          |\n",
      "| Plastic bag.. | 678          | Styrofoam p.. | 88           | Other plastic | 218          |\n",
      "| Plastic con.. | 57           |     Paper     | 117          |      Lid      | 69           |\n",
      "|     Straw     | 128          |   Paper bag   | 20           | Broken glass  | 111          |\n",
      "| Plastic ute.. | 29           |   Glass jar   | 4            |  Food waste   | 6            |\n",
      "| Squeezable .. | 5            |     Shoe      | 5            | Aluminium f.. | 49           |\n",
      "| Unlabeled l.. | 412          | Blister pack  | 5            |    Battery    | 1            |\n",
      "| Rope & stri.. | 23           |   Cigarette   | 533          |  Scrap metal  | 14           |\n",
      "| Plastic glo.. | 3            |               |              |               |              |\n",
      "|     total     | 3806         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[04/29 16:32:42 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/29 16:32:42 d2.data.common]: \u001b[0mSerializing 1190 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 16:32:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.80 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f6e8b1.pkl: 243MB [00:39, 6.13MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/29 16:33:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/29 16:34:25 d2.utils.events]: \u001b[0m eta: 7:50:01  iter: 19  total_loss: 3.657  loss_cls: 3.423  loss_box_reg: 0.0665  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.02516  time: 2.6491  data_time: 0.1686  lr: 1.9981e-05  max_mem: 9677M\n",
      "\u001b[32m[04/29 16:35:20 d2.utils.events]: \u001b[0m eta: 7:46:53  iter: 39  total_loss: 2.938  loss_cls: 2.686  loss_box_reg: 0.06362  loss_rpn_cls: 0.07668  loss_rpn_loc: 0.04147  time: 2.6824  data_time: 0.0132  lr: 3.9961e-05  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:36:13 d2.utils.events]: \u001b[0m eta: 7:43:44  iter: 59  total_loss: 1.289  loss_cls: 0.8702  loss_box_reg: 0.06598  loss_rpn_cls: 0.1518  loss_rpn_loc: 0.0309  time: 2.6812  data_time: 0.0161  lr: 5.9941e-05  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:37:06 d2.utils.events]: \u001b[0m eta: 7:42:16  iter: 79  total_loss: 0.4463  loss_cls: 0.1933  loss_box_reg: 0.07843  loss_rpn_cls: 0.06827  loss_rpn_loc: 0.05585  time: 2.6675  data_time: 0.0148  lr: 7.9921e-05  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:37:57 d2.utils.events]: \u001b[0m eta: 7:39:34  iter: 99  total_loss: 0.2049  loss_cls: 0.1038  loss_box_reg: 0.03582  loss_rpn_cls: 0.05235  loss_rpn_loc: 0.01448  time: 2.6471  data_time: 0.0146  lr: 9.9901e-05  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:38:50 d2.utils.events]: \u001b[0m eta: 7:38:04  iter: 119  total_loss: 0.2235  loss_cls: 0.1051  loss_box_reg: 0.04498  loss_rpn_cls: 0.05826  loss_rpn_loc: 0.02514  time: 2.6462  data_time: 0.0133  lr: 0.00011988  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:39:42 d2.utils.events]: \u001b[0m eta: 7:36:13  iter: 139  total_loss: 0.2874  loss_cls: 0.1064  loss_box_reg: 0.0425  loss_rpn_cls: 0.04544  loss_rpn_loc: 0.03157  time: 2.6407  data_time: 0.0168  lr: 0.00013986  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:40:38 d2.utils.events]: \u001b[0m eta: 7:36:59  iter: 159  total_loss: 0.2181  loss_cls: 0.1113  loss_box_reg: 0.05036  loss_rpn_cls: 0.03646  loss_rpn_loc: 0.02491  time: 2.6595  data_time: 0.0145  lr: 0.00015984  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:41:28 d2.utils.events]: \u001b[0m eta: 7:35:59  iter: 179  total_loss: 0.2724  loss_cls: 0.128  loss_box_reg: 0.05948  loss_rpn_cls: 0.03523  loss_rpn_loc: 0.03177  time: 2.6414  data_time: 0.0173  lr: 0.00017982  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:42:19 d2.utils.events]: \u001b[0m eta: 7:34:26  iter: 199  total_loss: 0.2342  loss_cls: 0.132  loss_box_reg: 0.05696  loss_rpn_cls: 0.02752  loss_rpn_loc: 0.0185  time: 2.6339  data_time: 0.0146  lr: 0.0001998  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:43:11 d2.utils.events]: \u001b[0m eta: 7:32:47  iter: 219  total_loss: 0.2342  loss_cls: 0.1213  loss_box_reg: 0.05953  loss_rpn_cls: 0.0318  loss_rpn_loc: 0.02508  time: 2.6278  data_time: 0.0138  lr: 0.00021978  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:44:03 d2.utils.events]: \u001b[0m eta: 7:31:12  iter: 239  total_loss: 0.2288  loss_cls: 0.1249  loss_box_reg: 0.06581  loss_rpn_cls: 0.02996  loss_rpn_loc: 0.01728  time: 2.6251  data_time: 0.0144  lr: 0.00023976  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:44:55 d2.utils.events]: \u001b[0m eta: 7:29:57  iter: 259  total_loss: 0.3226  loss_cls: 0.1514  loss_box_reg: 0.06839  loss_rpn_cls: 0.05283  loss_rpn_loc: 0.02576  time: 2.6226  data_time: 0.0138  lr: 0.00025974  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:45:47 d2.utils.events]: \u001b[0m eta: 7:28:46  iter: 279  total_loss: 0.3003  loss_cls: 0.1377  loss_box_reg: 0.0761  loss_rpn_cls: 0.03216  loss_rpn_loc: 0.02329  time: 2.6213  data_time: 0.0147  lr: 0.00027972  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:46:38 d2.utils.events]: \u001b[0m eta: 7:27:18  iter: 299  total_loss: 0.2793  loss_cls: 0.1335  loss_box_reg: 0.06976  loss_rpn_cls: 0.03828  loss_rpn_loc: 0.0215  time: 2.6172  data_time: 0.0209  lr: 0.0002997  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:47:29 d2.utils.events]: \u001b[0m eta: 7:26:27  iter: 319  total_loss: 0.2838  loss_cls: 0.128  loss_box_reg: 0.07341  loss_rpn_cls: 0.02414  loss_rpn_loc: 0.0176  time: 2.6143  data_time: 0.0308  lr: 0.00031968  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:48:26 d2.utils.events]: \u001b[0m eta: 7:26:31  iter: 339  total_loss: 0.3086  loss_cls: 0.1481  loss_box_reg: 0.08338  loss_rpn_cls: 0.03636  loss_rpn_loc: 0.03129  time: 2.6259  data_time: 0.0317  lr: 0.00033966  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:49:20 d2.utils.events]: \u001b[0m eta: 7:26:18  iter: 359  total_loss: 0.2555  loss_cls: 0.1236  loss_box_reg: 0.07325  loss_rpn_cls: 0.027  loss_rpn_loc: 0.02415  time: 2.6322  data_time: 0.0304  lr: 0.00035964  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:50:11 d2.utils.events]: \u001b[0m eta: 7:25:18  iter: 379  total_loss: 0.3331  loss_cls: 0.1472  loss_box_reg: 0.08642  loss_rpn_cls: 0.03125  loss_rpn_loc: 0.03173  time: 2.6272  data_time: 0.0295  lr: 0.00037962  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:51:03 d2.utils.events]: \u001b[0m eta: 7:24:45  iter: 399  total_loss: 0.3312  loss_cls: 0.1609  loss_box_reg: 0.09975  loss_rpn_cls: 0.02365  loss_rpn_loc: 0.02951  time: 2.6263  data_time: 0.0280  lr: 0.0003996  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:51:55 d2.utils.events]: \u001b[0m eta: 7:23:45  iter: 419  total_loss: 0.2546  loss_cls: 0.1239  loss_box_reg: 0.06795  loss_rpn_cls: 0.03092  loss_rpn_loc: 0.01633  time: 2.6232  data_time: 0.0284  lr: 0.00041958  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:52:50 d2.utils.events]: \u001b[0m eta: 7:23:43  iter: 439  total_loss: 0.2753  loss_cls: 0.1326  loss_box_reg: 0.07927  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.01356  time: 2.6291  data_time: 0.0311  lr: 0.00043956  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:53:47 d2.utils.events]: \u001b[0m eta: 7:23:50  iter: 459  total_loss: 0.282  loss_cls: 0.1537  loss_box_reg: 0.09947  loss_rpn_cls: 0.02366  loss_rpn_loc: 0.02198  time: 2.6389  data_time: 0.0267  lr: 0.00045954  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:54:39 d2.utils.events]: \u001b[0m eta: 7:22:58  iter: 479  total_loss: 0.2683  loss_cls: 0.1252  loss_box_reg: 0.07578  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.02226  time: 2.6382  data_time: 0.0376  lr: 0.00047952  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:55:32 d2.utils.events]: \u001b[0m eta: 7:21:50  iter: 499  total_loss: 0.2441  loss_cls: 0.1279  loss_box_reg: 0.08522  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.01636  time: 2.6388  data_time: 0.0270  lr: 0.0004995  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:56:27 d2.utils.events]: \u001b[0m eta: 7:21:19  iter: 519  total_loss: 0.2578  loss_cls: 0.1189  loss_box_reg: 0.07562  loss_rpn_cls: 0.03098  loss_rpn_loc: 0.02653  time: 2.6429  data_time: 0.0277  lr: 0.00051948  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:57:21 d2.utils.events]: \u001b[0m eta: 7:20:42  iter: 539  total_loss: 0.2493  loss_cls: 0.1196  loss_box_reg: 0.083  loss_rpn_cls: 0.03138  loss_rpn_loc: 0.01569  time: 2.6448  data_time: 0.0305  lr: 0.00053946  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:58:14 d2.utils.events]: \u001b[0m eta: 7:19:49  iter: 559  total_loss: 0.2394  loss_cls: 0.1228  loss_box_reg: 0.07975  loss_rpn_cls: 0.02495  loss_rpn_loc: 0.01644  time: 2.6444  data_time: 0.0299  lr: 0.00055944  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:59:04 d2.utils.events]: \u001b[0m eta: 7:18:57  iter: 579  total_loss: 0.352  loss_cls: 0.1715  loss_box_reg: 0.1166  loss_rpn_cls: 0.03172  loss_rpn_loc: 0.02731  time: 2.6394  data_time: 0.0393  lr: 0.00057942  max_mem: 9678M\n",
      "\u001b[32m[04/29 16:59:55 d2.utils.events]: \u001b[0m eta: 7:18:05  iter: 599  total_loss: 0.266  loss_cls: 0.1358  loss_box_reg: 0.07727  loss_rpn_cls: 0.02856  loss_rpn_loc: 0.02327  time: 2.6368  data_time: 0.0296  lr: 0.0005994  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:00:48 d2.utils.events]: \u001b[0m eta: 7:17:15  iter: 619  total_loss: 0.27  loss_cls: 0.1453  loss_box_reg: 0.08763  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.01537  time: 2.6373  data_time: 0.0267  lr: 0.00061938  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:01:41 d2.utils.events]: \u001b[0m eta: 7:16:51  iter: 639  total_loss: 0.2619  loss_cls: 0.1241  loss_box_reg: 0.08135  loss_rpn_cls: 0.02364  loss_rpn_loc: 0.01408  time: 2.6370  data_time: 0.0323  lr: 0.00063936  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:02:34 d2.utils.events]: \u001b[0m eta: 7:16:00  iter: 659  total_loss: 0.3173  loss_cls: 0.1366  loss_box_reg: 0.08905  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.03041  time: 2.6371  data_time: 0.0287  lr: 0.00065934  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:03:27 d2.utils.events]: \u001b[0m eta: 7:15:07  iter: 679  total_loss: 0.3042  loss_cls: 0.142  loss_box_reg: 0.09331  loss_rpn_cls: 0.02612  loss_rpn_loc: 0.02602  time: 2.6379  data_time: 0.0396  lr: 0.00067932  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:04:19 d2.utils.events]: \u001b[0m eta: 7:14:17  iter: 699  total_loss: 0.2943  loss_cls: 0.1291  loss_box_reg: 0.09252  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.02369  time: 2.6370  data_time: 0.0288  lr: 0.0006993  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:05:13 d2.utils.events]: \u001b[0m eta: 7:13:32  iter: 719  total_loss: 0.3342  loss_cls: 0.143  loss_box_reg: 0.08374  loss_rpn_cls: 0.03316  loss_rpn_loc: 0.03148  time: 2.6384  data_time: 0.0329  lr: 0.00071928  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:06:02 d2.utils.events]: \u001b[0m eta: 7:12:31  iter: 739  total_loss: 0.2905  loss_cls: 0.1443  loss_box_reg: 0.0928  loss_rpn_cls: 0.02406  loss_rpn_loc: 0.02787  time: 2.6339  data_time: 0.0296  lr: 0.00073926  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:06:52 d2.utils.events]: \u001b[0m eta: 7:11:12  iter: 759  total_loss: 0.2542  loss_cls: 0.1207  loss_box_reg: 0.08297  loss_rpn_cls: 0.02181  loss_rpn_loc: 0.03261  time: 2.6301  data_time: 0.0378  lr: 0.00075924  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:07:45 d2.utils.events]: \u001b[0m eta: 7:10:20  iter: 779  total_loss: 0.3251  loss_cls: 0.1177  loss_box_reg: 0.08048  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.02482  time: 2.6309  data_time: 0.0296  lr: 0.00077922  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:08:40 d2.utils.events]: \u001b[0m eta: 7:09:56  iter: 799  total_loss: 0.2842  loss_cls: 0.1308  loss_box_reg: 0.08548  loss_rpn_cls: 0.02807  loss_rpn_loc: 0.03091  time: 2.6331  data_time: 0.0281  lr: 0.0007992  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:09:32 d2.utils.events]: \u001b[0m eta: 7:09:04  iter: 819  total_loss: 0.2566  loss_cls: 0.1246  loss_box_reg: 0.08122  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.01351  time: 2.6325  data_time: 0.0263  lr: 0.00081918  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:10:23 d2.utils.events]: \u001b[0m eta: 7:08:13  iter: 839  total_loss: 0.3169  loss_cls: 0.1381  loss_box_reg: 0.08342  loss_rpn_cls: 0.03367  loss_rpn_loc: 0.02861  time: 2.6307  data_time: 0.0303  lr: 0.00083916  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:11:15 d2.utils.events]: \u001b[0m eta: 7:07:17  iter: 859  total_loss: 0.2135  loss_cls: 0.1013  loss_box_reg: 0.06548  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.01739  time: 2.6295  data_time: 0.0288  lr: 0.00085914  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:12:06 d2.utils.events]: \u001b[0m eta: 7:06:16  iter: 879  total_loss: 0.2659  loss_cls: 0.1197  loss_box_reg: 0.07449  loss_rpn_cls: 0.032  loss_rpn_loc: 0.02026  time: 2.6280  data_time: 0.0261  lr: 0.00087912  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:12:58 d2.utils.events]: \u001b[0m eta: 7:05:10  iter: 899  total_loss: 0.2785  loss_cls: 0.1401  loss_box_reg: 0.0868  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.02241  time: 2.6268  data_time: 0.0275  lr: 0.0008991  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:13:50 d2.utils.events]: \u001b[0m eta: 7:04:32  iter: 919  total_loss: 0.3246  loss_cls: 0.136  loss_box_reg: 0.0927  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.0193  time: 2.6266  data_time: 0.0323  lr: 0.00091908  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:14:41 d2.utils.events]: \u001b[0m eta: 7:03:24  iter: 939  total_loss: 0.2411  loss_cls: 0.1144  loss_box_reg: 0.07427  loss_rpn_cls: 0.02183  loss_rpn_loc: 0.0226  time: 2.6256  data_time: 0.0313  lr: 0.00093906  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:15:33 d2.utils.events]: \u001b[0m eta: 7:02:33  iter: 959  total_loss: 0.2653  loss_cls: 0.1163  loss_box_reg: 0.07789  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.01661  time: 2.6248  data_time: 0.0282  lr: 0.00095904  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:16:25 d2.utils.events]: \u001b[0m eta: 7:01:42  iter: 979  total_loss: 0.2058  loss_cls: 0.1023  loss_box_reg: 0.0676  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.01805  time: 2.6245  data_time: 0.0337  lr: 0.00097902  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:17:18 d2.utils.events]: \u001b[0m eta: 7:00:49  iter: 999  total_loss: 0.2833  loss_cls: 0.1346  loss_box_reg: 0.08428  loss_rpn_cls: 0.02139  loss_rpn_loc: 0.02867  time: 2.6244  data_time: 0.0284  lr: 0.000999  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:18:12 d2.utils.events]: \u001b[0m eta: 6:59:50  iter: 1019  total_loss: 0.318  loss_cls: 0.1301  loss_box_reg: 0.0759  loss_rpn_cls: 0.02581  loss_rpn_loc: 0.03659  time: 2.6258  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:19:04 d2.utils.events]: \u001b[0m eta: 6:58:59  iter: 1039  total_loss: 0.2456  loss_cls: 0.1187  loss_box_reg: 0.06978  loss_rpn_cls: 0.02023  loss_rpn_loc: 0.01765  time: 2.6250  data_time: 0.0299  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:19:55 d2.utils.events]: \u001b[0m eta: 6:58:21  iter: 1059  total_loss: 0.2941  loss_cls: 0.1366  loss_box_reg: 0.09207  loss_rpn_cls: 0.01913  loss_rpn_loc: 0.01982  time: 2.6244  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:20:50 d2.utils.events]: \u001b[0m eta: 6:57:23  iter: 1079  total_loss: 0.2398  loss_cls: 0.1277  loss_box_reg: 0.08508  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.01391  time: 2.6264  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:21:42 d2.utils.events]: \u001b[0m eta: 6:56:50  iter: 1099  total_loss: 0.2676  loss_cls: 0.1189  loss_box_reg: 0.07195  loss_rpn_cls: 0.03056  loss_rpn_loc: 0.02036  time: 2.6256  data_time: 0.0288  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:22:34 d2.utils.events]: \u001b[0m eta: 6:56:09  iter: 1119  total_loss: 0.2264  loss_cls: 0.1021  loss_box_reg: 0.0578  loss_rpn_cls: 0.01962  loss_rpn_loc: 0.02282  time: 2.6252  data_time: 0.0315  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:23:26 d2.utils.events]: \u001b[0m eta: 6:55:29  iter: 1139  total_loss: 0.2915  loss_cls: 0.1254  loss_box_reg: 0.08026  loss_rpn_cls: 0.0315  loss_rpn_loc: 0.02873  time: 2.6251  data_time: 0.0285  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:24:19 d2.utils.events]: \u001b[0m eta: 6:54:14  iter: 1159  total_loss: 0.3325  loss_cls: 0.1419  loss_box_reg: 0.08142  loss_rpn_cls: 0.04608  loss_rpn_loc: 0.04297  time: 2.6249  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:25:10 d2.utils.events]: \u001b[0m eta: 6:53:30  iter: 1179  total_loss: 0.2021  loss_cls: 0.1057  loss_box_reg: 0.06144  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.02574  time: 2.6241  data_time: 0.0392  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:25:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 17:25:47 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 17:25:47 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 17:25:47 d2.data.build]: \u001b[0mDistribution of instances among all 28 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|    Bottle     | 88           |    Carton     | 51           |  Bottle cap   | 58           |\n",
      "|      Can      | 55           |    Pop tab    | 20           |      Cup      | 39           |\n",
      "| Plastic bag.. | 170          | Styrofoam p.. | 23           | Other plastic | 55           |\n",
      "| Plastic con.. | 15           |     Paper     | 30           |      Lid      | 18           |\n",
      "|     Straw     | 33           |   Paper bag   | 6            | Broken glass  | 27           |\n",
      "| Plastic ute.. | 8            |   Glass jar   | 2            |  Food waste   | 2            |\n",
      "| Squeezable .. | 2            |     Shoe      | 2            | Aluminium f.. | 13           |\n",
      "| Unlabeled l.. | 104          | Blister pack  | 2            |    Battery    | 1            |\n",
      "| Rope & stri.. | 6            |   Cigarette   | 134          |  Scrap metal  | 6            |\n",
      "| Plastic glo.. | 1            |               |              |               |              |\n",
      "|     total     | 971          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[04/29 17:25:47 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 17:25:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 17:25:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 17:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1704 s / img. ETA=0:00:53\n",
      "\u001b[32m[04/29 17:25:56 d2.evaluation.evaluator]: \u001b[0mInference done 30/310. 0.2270 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/29 17:26:01 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2299 s / img. ETA=0:01:11\n",
      "\u001b[32m[04/29 17:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2226 s / img. ETA=0:01:14\n",
      "\u001b[32m[04/29 17:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 76/310. 0.2155 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/29 17:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 92/310. 0.2097 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/29 17:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 109/310. 0.2037 s / img. ETA=0:01:02\n",
      "\u001b[32m[04/29 17:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 124/310. 0.2002 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/29 17:26:32 d2.evaluation.evaluator]: \u001b[0mInference done 148/310. 0.1961 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/29 17:26:37 d2.evaluation.evaluator]: \u001b[0mInference done 172/310. 0.1942 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/29 17:26:42 d2.evaluation.evaluator]: \u001b[0mInference done 193/310. 0.1929 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/29 17:26:47 d2.evaluation.evaluator]: \u001b[0mInference done 218/310. 0.1911 s / img. ETA=0:00:24\n",
      "\u001b[32m[04/29 17:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1898 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/29 17:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 264/310. 0.1885 s / img. ETA=0:00:12\n",
      "\u001b[32m[04/29 17:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 285/310. 0.1878 s / img. ETA=0:00:06\n",
      "\u001b[32m[04/29 17:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 309/310. 0.1888 s / img. ETA=0:00:00\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:19.071683 (0.259251 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.188970 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.155\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.648 | 7.836  | 4.911  | 1.270 | 4.424 | 5.221 |\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 35.629 | Carton          | 18.750 | Bottle cap     | 16.377 |\n",
      "| Can                   | 16.287 | Pop tab         | 0.000  | Cup            | 8.103  |\n",
      "| Plastic bag & wrapper | 16.396 | Styrofoam piece | 0.000  | Other plastic  | 1.087  |\n",
      "| Plastic container     | 0.000  | Paper           | 2.578  | Lid            | 2.551  |\n",
      "| Straw                 | 4.766  | Paper bag       | 0.000  | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 0.000  | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 0.000  |\n",
      "| Unlabeled litter      | 2.098  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 0.000  | Cigarette       | 5.508  | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 17:27:09 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 17:27:09 d2.evaluation.testing]: \u001b[0mcopypaste: 4.6475,7.8363,4.9113,1.2703,4.4245,5.2213\n",
      "\u001b[32m[04/29 17:27:26 d2.utils.events]: \u001b[0m eta: 6:52:57  iter: 1199  total_loss: 0.2816  loss_cls: 0.1474  loss_box_reg: 0.09231  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.02646  time: 2.6247  data_time: 0.0329  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:28:19 d2.utils.events]: \u001b[0m eta: 6:52:08  iter: 1219  total_loss: 0.1991  loss_cls: 0.09761  loss_box_reg: 0.05833  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.01135  time: 2.6244  data_time: 0.0280  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:29:14 d2.utils.events]: \u001b[0m eta: 6:51:31  iter: 1239  total_loss: 0.2638  loss_cls: 0.1351  loss_box_reg: 0.08687  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01725  time: 2.6266  data_time: 0.0291  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:30:05 d2.utils.events]: \u001b[0m eta: 6:50:40  iter: 1259  total_loss: 0.3626  loss_cls: 0.1803  loss_box_reg: 0.09522  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.04347  time: 2.6259  data_time: 0.0375  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:30:59 d2.utils.events]: \u001b[0m eta: 6:49:59  iter: 1279  total_loss: 0.2245  loss_cls: 0.09921  loss_box_reg: 0.06617  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.02028  time: 2.6266  data_time: 0.0301  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:31:50 d2.utils.events]: \u001b[0m eta: 6:49:23  iter: 1299  total_loss: 0.2462  loss_cls: 0.118  loss_box_reg: 0.06737  loss_rpn_cls: 0.02051  loss_rpn_loc: 0.03098  time: 2.6254  data_time: 0.0340  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:32:43 d2.utils.events]: \u001b[0m eta: 6:48:31  iter: 1319  total_loss: 0.1898  loss_cls: 0.09356  loss_box_reg: 0.05232  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.02047  time: 2.6262  data_time: 0.0303  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:33:38 d2.utils.events]: \u001b[0m eta: 6:47:30  iter: 1339  total_loss: 0.2277  loss_cls: 0.09935  loss_box_reg: 0.05356  loss_rpn_cls: 0.02432  loss_rpn_loc: 0.0352  time: 2.6274  data_time: 0.0329  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:34:29 d2.utils.events]: \u001b[0m eta: 6:46:34  iter: 1359  total_loss: 0.2443  loss_cls: 0.1256  loss_box_reg: 0.07067  loss_rpn_cls: 0.01747  loss_rpn_loc: 0.01584  time: 2.6265  data_time: 0.0283  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:35:21 d2.utils.events]: \u001b[0m eta: 6:45:42  iter: 1379  total_loss: 0.2417  loss_cls: 0.1328  loss_box_reg: 0.07045  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.01908  time: 2.6258  data_time: 0.0263  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:36:13 d2.utils.events]: \u001b[0m eta: 6:44:36  iter: 1399  total_loss: 0.2248  loss_cls: 0.1251  loss_box_reg: 0.06607  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01526  time: 2.6259  data_time: 0.0315  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:37:05 d2.utils.events]: \u001b[0m eta: 6:43:44  iter: 1419  total_loss: 0.2489  loss_cls: 0.1108  loss_box_reg: 0.05695  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.02215  time: 2.6250  data_time: 0.0366  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:38:00 d2.utils.events]: \u001b[0m eta: 6:42:51  iter: 1439  total_loss: 0.2141  loss_cls: 0.1016  loss_box_reg: 0.05332  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.02218  time: 2.6268  data_time: 0.0303  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:38:55 d2.utils.events]: \u001b[0m eta: 6:41:53  iter: 1459  total_loss: 0.2241  loss_cls: 0.1197  loss_box_reg: 0.06458  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.01866  time: 2.6286  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:39:46 d2.utils.events]: \u001b[0m eta: 6:40:53  iter: 1479  total_loss: 0.2712  loss_cls: 0.1315  loss_box_reg: 0.07439  loss_rpn_cls: 0.02319  loss_rpn_loc: 0.03248  time: 2.6279  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:40:42 d2.utils.events]: \u001b[0m eta: 6:40:16  iter: 1499  total_loss: 0.2171  loss_cls: 0.1158  loss_box_reg: 0.06321  loss_rpn_cls: 0.02246  loss_rpn_loc: 0.01918  time: 2.6301  data_time: 0.0280  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:41:36 d2.utils.events]: \u001b[0m eta: 6:39:22  iter: 1519  total_loss: 0.2915  loss_cls: 0.1342  loss_box_reg: 0.07532  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.02134  time: 2.6308  data_time: 0.0362  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:42:30 d2.utils.events]: \u001b[0m eta: 6:38:30  iter: 1539  total_loss: 0.2668  loss_cls: 0.135  loss_box_reg: 0.07047  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.02524  time: 2.6318  data_time: 0.0298  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:43:21 d2.utils.events]: \u001b[0m eta: 6:37:46  iter: 1559  total_loss: 0.215  loss_cls: 0.119  loss_box_reg: 0.06198  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.01741  time: 2.6308  data_time: 0.0274  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:44:13 d2.utils.events]: \u001b[0m eta: 6:36:48  iter: 1579  total_loss: 0.2433  loss_cls: 0.1193  loss_box_reg: 0.07245  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.04205  time: 2.6300  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:45:03 d2.utils.events]: \u001b[0m eta: 6:35:51  iter: 1599  total_loss: 0.2113  loss_cls: 0.1048  loss_box_reg: 0.07311  loss_rpn_cls: 0.01963  loss_rpn_loc: 0.02077  time: 2.6286  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:45:54 d2.utils.events]: \u001b[0m eta: 6:34:21  iter: 1619  total_loss: 0.2543  loss_cls: 0.1346  loss_box_reg: 0.06989  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.02045  time: 2.6274  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:46:48 d2.utils.events]: \u001b[0m eta: 6:33:21  iter: 1639  total_loss: 0.2786  loss_cls: 0.1218  loss_box_reg: 0.0676  loss_rpn_cls: 0.03416  loss_rpn_loc: 0.02767  time: 2.6283  data_time: 0.0249  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:47:42 d2.utils.events]: \u001b[0m eta: 6:32:24  iter: 1659  total_loss: 0.2701  loss_cls: 0.1277  loss_box_reg: 0.07392  loss_rpn_cls: 0.02049  loss_rpn_loc: 0.03244  time: 2.6290  data_time: 0.0718  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:48:35 d2.utils.events]: \u001b[0m eta: 6:31:37  iter: 1679  total_loss: 0.2148  loss_cls: 0.1056  loss_box_reg: 0.05259  loss_rpn_cls: 0.02449  loss_rpn_loc: 0.01822  time: 2.6293  data_time: 0.0330  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:49:29 d2.utils.events]: \u001b[0m eta: 6:30:41  iter: 1699  total_loss: 0.2054  loss_cls: 0.1162  loss_box_reg: 0.05883  loss_rpn_cls: 0.01613  loss_rpn_loc: 0.02208  time: 2.6302  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:50:22 d2.utils.events]: \u001b[0m eta: 6:29:44  iter: 1719  total_loss: 0.2162  loss_cls: 0.09551  loss_box_reg: 0.05352  loss_rpn_cls: 0.02626  loss_rpn_loc: 0.0305  time: 2.6309  data_time: 0.0285  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:51:12 d2.utils.events]: \u001b[0m eta: 6:29:02  iter: 1739  total_loss: 0.2587  loss_cls: 0.1366  loss_box_reg: 0.07175  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.03035  time: 2.6290  data_time: 0.0256  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:52:04 d2.utils.events]: \u001b[0m eta: 6:28:18  iter: 1759  total_loss: 0.2107  loss_cls: 0.1119  loss_box_reg: 0.06513  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.02378  time: 2.6290  data_time: 0.0300  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:52:56 d2.utils.events]: \u001b[0m eta: 6:27:23  iter: 1779  total_loss: 0.2048  loss_cls: 0.1016  loss_box_reg: 0.05274  loss_rpn_cls: 0.009714  loss_rpn_loc: 0.01239  time: 2.6286  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:53:48 d2.utils.events]: \u001b[0m eta: 6:26:18  iter: 1799  total_loss: 0.1761  loss_cls: 0.08929  loss_box_reg: 0.04848  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.01606  time: 2.6283  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:54:40 d2.utils.events]: \u001b[0m eta: 6:25:20  iter: 1819  total_loss: 0.2175  loss_cls: 0.1075  loss_box_reg: 0.05286  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.02522  time: 2.6277  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:55:34 d2.utils.events]: \u001b[0m eta: 6:24:15  iter: 1839  total_loss: 0.2501  loss_cls: 0.0983  loss_box_reg: 0.05471  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.05096  time: 2.6282  data_time: 0.0548  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:56:25 d2.utils.events]: \u001b[0m eta: 6:23:31  iter: 1859  total_loss: 0.2284  loss_cls: 0.1047  loss_box_reg: 0.05183  loss_rpn_cls: 0.01976  loss_rpn_loc: 0.02089  time: 2.6277  data_time: 0.0656  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:57:19 d2.utils.events]: \u001b[0m eta: 6:22:56  iter: 1879  total_loss: 0.2188  loss_cls: 0.1106  loss_box_reg: 0.05966  loss_rpn_cls: 0.02275  loss_rpn_loc: 0.02096  time: 2.6282  data_time: 0.0217  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:58:12 d2.utils.events]: \u001b[0m eta: 6:22:07  iter: 1899  total_loss: 0.2125  loss_cls: 0.09991  loss_box_reg: 0.055  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.02521  time: 2.6284  data_time: 0.0251  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:59:05 d2.utils.events]: \u001b[0m eta: 6:21:15  iter: 1919  total_loss: 0.2156  loss_cls: 0.1099  loss_box_reg: 0.05321  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.01238  time: 2.6290  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 17:59:58 d2.utils.events]: \u001b[0m eta: 6:21:09  iter: 1939  total_loss: 0.2111  loss_cls: 0.1096  loss_box_reg: 0.06613  loss_rpn_cls: 0.009762  loss_rpn_loc: 0.01849  time: 2.6288  data_time: 0.0287  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:00:53 d2.utils.events]: \u001b[0m eta: 6:20:17  iter: 1959  total_loss: 0.2418  loss_cls: 0.1308  loss_box_reg: 0.07252  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.02032  time: 2.6301  data_time: 0.0287  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:01:45 d2.utils.events]: \u001b[0m eta: 6:19:20  iter: 1979  total_loss: 0.2933  loss_cls: 0.1675  loss_box_reg: 0.08779  loss_rpn_cls: 0.02597  loss_rpn_loc: 0.03698  time: 2.6300  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:02:35 d2.utils.events]: \u001b[0m eta: 6:18:28  iter: 1999  total_loss: 0.2354  loss_cls: 0.1096  loss_box_reg: 0.06101  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.0263  time: 2.6285  data_time: 0.0308  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:03:27 d2.utils.events]: \u001b[0m eta: 6:17:26  iter: 2019  total_loss: 0.2636  loss_cls: 0.131  loss_box_reg: 0.06143  loss_rpn_cls: 0.02026  loss_rpn_loc: 0.03482  time: 2.6285  data_time: 0.0254  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:04:21 d2.utils.events]: \u001b[0m eta: 6:16:52  iter: 2039  total_loss: 0.2521  loss_cls: 0.1206  loss_box_reg: 0.06498  loss_rpn_cls: 0.02638  loss_rpn_loc: 0.03817  time: 2.6292  data_time: 0.0278  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:05:14 d2.utils.events]: \u001b[0m eta: 6:15:54  iter: 2059  total_loss: 0.2636  loss_cls: 0.1369  loss_box_reg: 0.0703  loss_rpn_cls: 0.019  loss_rpn_loc: 0.02211  time: 2.6290  data_time: 0.0309  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:06:07 d2.utils.events]: \u001b[0m eta: 6:15:02  iter: 2079  total_loss: 0.2197  loss_cls: 0.1083  loss_box_reg: 0.0645  loss_rpn_cls: 0.01072  loss_rpn_loc: 0.02195  time: 2.6293  data_time: 0.0299  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:07:00 d2.utils.events]: \u001b[0m eta: 6:14:10  iter: 2099  total_loss: 0.2005  loss_cls: 0.09716  loss_box_reg: 0.05141  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.01303  time: 2.6297  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:07:52 d2.utils.events]: \u001b[0m eta: 6:13:18  iter: 2119  total_loss: 0.2049  loss_cls: 0.1133  loss_box_reg: 0.06521  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.01608  time: 2.6292  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:08:43 d2.utils.events]: \u001b[0m eta: 6:12:26  iter: 2139  total_loss: 0.2035  loss_cls: 0.1014  loss_box_reg: 0.06096  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.01727  time: 2.6285  data_time: 0.0261  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:09:36 d2.utils.events]: \u001b[0m eta: 6:11:40  iter: 2159  total_loss: 0.2705  loss_cls: 0.1131  loss_box_reg: 0.06389  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.02991  time: 2.6286  data_time: 0.0458  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:10:27 d2.utils.events]: \u001b[0m eta: 6:10:34  iter: 2179  total_loss: 0.2493  loss_cls: 0.1343  loss_box_reg: 0.07706  loss_rpn_cls: 0.01884  loss_rpn_loc: 0.02789  time: 2.6281  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:11:18 d2.utils.events]: \u001b[0m eta: 6:09:42  iter: 2199  total_loss: 0.29  loss_cls: 0.1305  loss_box_reg: 0.07576  loss_rpn_cls: 0.0228  loss_rpn_loc: 0.04917  time: 2.6274  data_time: 0.0257  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:12:09 d2.utils.events]: \u001b[0m eta: 6:08:54  iter: 2219  total_loss: 0.2485  loss_cls: 0.1186  loss_box_reg: 0.05615  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.02215  time: 2.6267  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:13:00 d2.utils.events]: \u001b[0m eta: 6:07:45  iter: 2239  total_loss: 0.1984  loss_cls: 0.0933  loss_box_reg: 0.05239  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.01182  time: 2.6261  data_time: 0.0269  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:13:54 d2.utils.events]: \u001b[0m eta: 6:07:06  iter: 2259  total_loss: 0.2557  loss_cls: 0.1244  loss_box_reg: 0.06281  loss_rpn_cls: 0.02041  loss_rpn_loc: 0.01981  time: 2.6267  data_time: 0.0337  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:14:45 d2.utils.events]: \u001b[0m eta: 6:06:14  iter: 2279  total_loss: 0.1845  loss_cls: 0.09794  loss_box_reg: 0.05039  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.01859  time: 2.6258  data_time: 0.0236  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:15:35 d2.utils.events]: \u001b[0m eta: 6:05:10  iter: 2299  total_loss: 0.2126  loss_cls: 0.1063  loss_box_reg: 0.05796  loss_rpn_cls: 0.0273  loss_rpn_loc: 0.02261  time: 2.6247  data_time: 0.0312  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:16:25 d2.utils.events]: \u001b[0m eta: 6:04:07  iter: 2319  total_loss: 0.2309  loss_cls: 0.1079  loss_box_reg: 0.05276  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.02064  time: 2.6239  data_time: 0.0413  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:17:19 d2.utils.events]: \u001b[0m eta: 6:03:26  iter: 2339  total_loss: 0.1965  loss_cls: 0.08988  loss_box_reg: 0.05204  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.02164  time: 2.6243  data_time: 0.0311  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:18:14 d2.utils.events]: \u001b[0m eta: 6:02:44  iter: 2359  total_loss: 0.2702  loss_cls: 0.1106  loss_box_reg: 0.05954  loss_rpn_cls: 0.0196  loss_rpn_loc: 0.04322  time: 2.6255  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:19:06 d2.utils.events]: \u001b[0m eta: 6:01:57  iter: 2379  total_loss: 0.1939  loss_cls: 0.09737  loss_box_reg: 0.05841  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.01952  time: 2.6253  data_time: 0.0237  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:19:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 18:19:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 18:19:25 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 18:19:25 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 18:19:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 18:19:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 18:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1795 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/29 18:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 31/310. 0.2266 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/29 18:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2285 s / img. ETA=0:01:11\n",
      "\u001b[32m[04/29 18:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 63/310. 0.2176 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/29 18:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 75/310. 0.2155 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/29 18:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 91/310. 0.2082 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/29 18:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 107/310. 0.2032 s / img. ETA=0:01:03\n",
      "\u001b[32m[04/29 18:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 123/310. 0.2001 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/29 18:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 147/310. 0.1966 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/29 18:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 171/310. 0.1936 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/29 18:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 195/310. 0.1935 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/29 18:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 219/310. 0.1923 s / img. ETA=0:00:24\n",
      "\u001b[32m[04/29 18:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1916 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/29 18:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 265/310. 0.1909 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/29 18:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 287/310. 0.1905 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:18.189614 (0.256359 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.191218 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 9.791 | 16.397 | 10.929 | 2.697 | 11.273 | 11.431 |\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.886 | Carton          | 30.912 | Bottle cap     | 25.353 |\n",
      "| Can                   | 29.384 | Pop tab         | 1.823  | Cup            | 17.812 |\n",
      "| Plastic bag & wrapper | 23.154 | Styrofoam piece | 9.320  | Other plastic  | 5.773  |\n",
      "| Plastic container     | 9.996  | Paper           | 4.083  | Lid            | 14.017 |\n",
      "| Straw                 | 10.537 | Paper bag       | 0.000  | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 19.439 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 15.842 |\n",
      "| Unlabeled litter      | 2.917  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 0.000  | Cigarette       | 12.895 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 18:20:46 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 18:20:46 d2.evaluation.testing]: \u001b[0mcopypaste: 9.7909,16.3975,10.9287,2.6974,11.2731,11.4311\n",
      "\u001b[32m[04/29 18:21:19 d2.utils.events]: \u001b[0m eta: 6:00:54  iter: 2399  total_loss: 0.2211  loss_cls: 0.09915  loss_box_reg: 0.05514  loss_rpn_cls: 0.01965  loss_rpn_loc: 0.0194  time: 2.6244  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:22:11 d2.utils.events]: \u001b[0m eta: 6:00:02  iter: 2419  total_loss: 0.235  loss_cls: 0.1154  loss_box_reg: 0.06328  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.01904  time: 2.6242  data_time: 0.0266  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:23:06 d2.utils.events]: \u001b[0m eta: 5:59:06  iter: 2439  total_loss: 0.1671  loss_cls: 0.07823  loss_box_reg: 0.04375  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.01978  time: 2.6250  data_time: 0.0299  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:24:00 d2.utils.events]: \u001b[0m eta: 5:58:19  iter: 2459  total_loss: 0.2033  loss_cls: 0.111  loss_box_reg: 0.05645  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.02108  time: 2.6257  data_time: 0.0335  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:24:51 d2.utils.events]: \u001b[0m eta: 5:57:23  iter: 2479  total_loss: 0.1979  loss_cls: 0.0975  loss_box_reg: 0.05093  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.01565  time: 2.6250  data_time: 0.1199  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:25:41 d2.utils.events]: \u001b[0m eta: 5:56:11  iter: 2499  total_loss: 0.2027  loss_cls: 0.08935  loss_box_reg: 0.04272  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.01312  time: 2.6241  data_time: 0.0330  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:26:36 d2.utils.events]: \u001b[0m eta: 5:55:19  iter: 2519  total_loss: 0.2454  loss_cls: 0.124  loss_box_reg: 0.06955  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.02963  time: 2.6250  data_time: 0.0276  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:27:28 d2.utils.events]: \u001b[0m eta: 5:54:27  iter: 2539  total_loss: 0.2504  loss_cls: 0.1162  loss_box_reg: 0.05933  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.03117  time: 2.6249  data_time: 0.0329  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:28:19 d2.utils.events]: \u001b[0m eta: 5:53:31  iter: 2559  total_loss: 0.203  loss_cls: 0.1015  loss_box_reg: 0.05072  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.0173  time: 2.6243  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:29:08 d2.utils.events]: \u001b[0m eta: 5:52:32  iter: 2579  total_loss: 0.1976  loss_cls: 0.1009  loss_box_reg: 0.04875  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.03229  time: 2.6227  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:29:57 d2.utils.events]: \u001b[0m eta: 5:51:44  iter: 2599  total_loss: 0.2127  loss_cls: 0.1158  loss_box_reg: 0.06395  loss_rpn_cls: 0.008354  loss_rpn_loc: 0.02129  time: 2.6215  data_time: 0.0306  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:30:46 d2.utils.events]: \u001b[0m eta: 5:50:52  iter: 2619  total_loss: 0.2614  loss_cls: 0.1024  loss_box_reg: 0.0611  loss_rpn_cls: 0.02156  loss_rpn_loc: 0.02328  time: 2.6201  data_time: 0.0313  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:31:38 d2.utils.events]: \u001b[0m eta: 5:49:58  iter: 2639  total_loss: 0.2316  loss_cls: 0.1312  loss_box_reg: 0.06598  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.02273  time: 2.6201  data_time: 0.0264  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:32:32 d2.utils.events]: \u001b[0m eta: 5:49:04  iter: 2659  total_loss: 0.2731  loss_cls: 0.134  loss_box_reg: 0.07735  loss_rpn_cls: 0.01766  loss_rpn_loc: 0.0436  time: 2.6205  data_time: 0.0294  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:33:27 d2.utils.events]: \u001b[0m eta: 5:48:17  iter: 2679  total_loss: 0.2468  loss_cls: 0.1273  loss_box_reg: 0.06486  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.0274  time: 2.6216  data_time: 0.0253  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:34:21 d2.utils.events]: \u001b[0m eta: 5:47:28  iter: 2699  total_loss: 0.2342  loss_cls: 0.1233  loss_box_reg: 0.06507  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.02198  time: 2.6221  data_time: 0.0300  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:35:14 d2.utils.events]: \u001b[0m eta: 5:46:29  iter: 2719  total_loss: 0.2035  loss_cls: 0.1047  loss_box_reg: 0.05988  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.01427  time: 2.6225  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:36:09 d2.utils.events]: \u001b[0m eta: 5:45:42  iter: 2739  total_loss: 0.3008  loss_cls: 0.1455  loss_box_reg: 0.08667  loss_rpn_cls: 0.01201  loss_rpn_loc: 0.02452  time: 2.6233  data_time: 0.0245  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:37:02 d2.utils.events]: \u001b[0m eta: 5:44:50  iter: 2759  total_loss: 0.1611  loss_cls: 0.07518  loss_box_reg: 0.04524  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.02197  time: 2.6235  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:37:54 d2.utils.events]: \u001b[0m eta: 5:44:11  iter: 2779  total_loss: 0.1761  loss_cls: 0.0935  loss_box_reg: 0.0551  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.01679  time: 2.6232  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:38:45 d2.utils.events]: \u001b[0m eta: 5:43:14  iter: 2799  total_loss: 0.1793  loss_cls: 0.09347  loss_box_reg: 0.05481  loss_rpn_cls: 0.009269  loss_rpn_loc: 0.01511  time: 2.6229  data_time: 0.0280  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:39:38 d2.utils.events]: \u001b[0m eta: 5:42:30  iter: 2819  total_loss: 0.2015  loss_cls: 0.0969  loss_box_reg: 0.05403  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.01813  time: 2.6228  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:40:30 d2.utils.events]: \u001b[0m eta: 5:41:35  iter: 2839  total_loss: 0.1962  loss_cls: 0.09296  loss_box_reg: 0.06101  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.01621  time: 2.6229  data_time: 0.0311  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:41:21 d2.utils.events]: \u001b[0m eta: 5:40:36  iter: 2859  total_loss: 0.2361  loss_cls: 0.09534  loss_box_reg: 0.05688  loss_rpn_cls: 0.01606  loss_rpn_loc: 0.03613  time: 2.6224  data_time: 0.0234  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:42:12 d2.utils.events]: \u001b[0m eta: 5:39:33  iter: 2879  total_loss: 0.221  loss_cls: 0.1137  loss_box_reg: 0.05998  loss_rpn_cls: 0.007922  loss_rpn_loc: 0.01927  time: 2.6216  data_time: 0.0283  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:43:03 d2.utils.events]: \u001b[0m eta: 5:38:43  iter: 2899  total_loss: 0.2408  loss_cls: 0.1128  loss_box_reg: 0.07334  loss_rpn_cls: 0.01581  loss_rpn_loc: 0.03474  time: 2.6213  data_time: 0.0237  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:43:56 d2.utils.events]: \u001b[0m eta: 5:37:47  iter: 2919  total_loss: 0.2907  loss_cls: 0.1351  loss_box_reg: 0.07065  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.04443  time: 2.6213  data_time: 0.0526  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:44:51 d2.utils.events]: \u001b[0m eta: 5:36:56  iter: 2939  total_loss: 0.2275  loss_cls: 0.1266  loss_box_reg: 0.07177  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.01938  time: 2.6221  data_time: 0.0313  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:45:43 d2.utils.events]: \u001b[0m eta: 5:36:04  iter: 2959  total_loss: 0.2055  loss_cls: 0.1038  loss_box_reg: 0.06276  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.02544  time: 2.6221  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:46:35 d2.utils.events]: \u001b[0m eta: 5:35:14  iter: 2979  total_loss: 0.2036  loss_cls: 0.1047  loss_box_reg: 0.06115  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.02395  time: 2.6219  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:47:28 d2.utils.events]: \u001b[0m eta: 5:34:22  iter: 2999  total_loss: 0.2159  loss_cls: 0.09596  loss_box_reg: 0.0586  loss_rpn_cls: 0.01863  loss_rpn_loc: 0.02255  time: 2.6222  data_time: 0.0269  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:48:20 d2.utils.events]: \u001b[0m eta: 5:33:30  iter: 3019  total_loss: 0.2338  loss_cls: 0.1108  loss_box_reg: 0.07127  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.02025  time: 2.6220  data_time: 0.0319  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:49:18 d2.utils.events]: \u001b[0m eta: 5:32:39  iter: 3039  total_loss: 0.2551  loss_cls: 0.1305  loss_box_reg: 0.07149  loss_rpn_cls: 0.013  loss_rpn_loc: 0.02099  time: 2.6239  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:50:10 d2.utils.events]: \u001b[0m eta: 5:31:38  iter: 3059  total_loss: 0.2083  loss_cls: 0.1051  loss_box_reg: 0.05786  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.01394  time: 2.6237  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:51:01 d2.utils.events]: \u001b[0m eta: 5:30:40  iter: 3079  total_loss: 0.249  loss_cls: 0.1117  loss_box_reg: 0.06319  loss_rpn_cls: 0.01352  loss_rpn_loc: 0.0284  time: 2.6231  data_time: 0.0275  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:51:53 d2.utils.events]: \u001b[0m eta: 5:29:45  iter: 3099  total_loss: 0.2156  loss_cls: 0.1012  loss_box_reg: 0.05661  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.02359  time: 2.6230  data_time: 0.0262  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:52:44 d2.utils.events]: \u001b[0m eta: 5:28:57  iter: 3119  total_loss: 0.2723  loss_cls: 0.1217  loss_box_reg: 0.0696  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.0405  time: 2.6225  data_time: 0.0302  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:53:34 d2.utils.events]: \u001b[0m eta: 5:27:55  iter: 3139  total_loss: 0.1772  loss_cls: 0.09345  loss_box_reg: 0.04993  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.01437  time: 2.6216  data_time: 0.0319  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:54:24 d2.utils.events]: \u001b[0m eta: 5:26:57  iter: 3159  total_loss: 0.2124  loss_cls: 0.1151  loss_box_reg: 0.06631  loss_rpn_cls: 0.007951  loss_rpn_loc: 0.01728  time: 2.6211  data_time: 0.0317  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:55:18 d2.utils.events]: \u001b[0m eta: 5:26:11  iter: 3179  total_loss: 0.2462  loss_cls: 0.1275  loss_box_reg: 0.0662  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.02259  time: 2.6214  data_time: 0.0469  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:56:11 d2.utils.events]: \u001b[0m eta: 5:25:19  iter: 3199  total_loss: 0.2231  loss_cls: 0.1101  loss_box_reg: 0.06384  loss_rpn_cls: 0.019  loss_rpn_loc: 0.01831  time: 2.6217  data_time: 0.0413  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:57:06 d2.utils.events]: \u001b[0m eta: 5:24:44  iter: 3219  total_loss: 0.2713  loss_cls: 0.1197  loss_box_reg: 0.06975  loss_rpn_cls: 0.01697  loss_rpn_loc: 0.0328  time: 2.6222  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:57:58 d2.utils.events]: \u001b[0m eta: 5:24:02  iter: 3239  total_loss: 0.2441  loss_cls: 0.1237  loss_box_reg: 0.06961  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.02836  time: 2.6222  data_time: 0.0299  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:58:50 d2.utils.events]: \u001b[0m eta: 5:22:51  iter: 3259  total_loss: 0.2164  loss_cls: 0.1111  loss_box_reg: 0.06096  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.01961  time: 2.6222  data_time: 0.0323  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 18:59:41 d2.utils.events]: \u001b[0m eta: 5:21:52  iter: 3279  total_loss: 0.1675  loss_cls: 0.08987  loss_box_reg: 0.05058  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.01943  time: 2.6216  data_time: 0.0356  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:00:33 d2.utils.events]: \u001b[0m eta: 5:21:07  iter: 3299  total_loss: 0.2446  loss_cls: 0.1114  loss_box_reg: 0.05872  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.01662  time: 2.6216  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:01:26 d2.utils.events]: \u001b[0m eta: 5:20:33  iter: 3319  total_loss: 0.206  loss_cls: 0.1145  loss_box_reg: 0.06026  loss_rpn_cls: 0.01868  loss_rpn_loc: 0.01268  time: 2.6216  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:02:17 d2.utils.events]: \u001b[0m eta: 5:19:24  iter: 3339  total_loss: 0.2019  loss_cls: 0.1026  loss_box_reg: 0.06186  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.01783  time: 2.6213  data_time: 0.0484  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:03:07 d2.utils.events]: \u001b[0m eta: 5:18:32  iter: 3359  total_loss: 0.2203  loss_cls: 0.1016  loss_box_reg: 0.05798  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.02399  time: 2.6206  data_time: 0.0310  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:04:00 d2.utils.events]: \u001b[0m eta: 5:17:57  iter: 3379  total_loss: 0.2025  loss_cls: 0.09805  loss_box_reg: 0.05957  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.01485  time: 2.6208  data_time: 0.0306  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:04:52 d2.utils.events]: \u001b[0m eta: 5:17:10  iter: 3399  total_loss: 0.2624  loss_cls: 0.1335  loss_box_reg: 0.08315  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.02938  time: 2.6206  data_time: 0.0248  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:05:45 d2.utils.events]: \u001b[0m eta: 5:16:27  iter: 3419  total_loss: 0.2139  loss_cls: 0.1088  loss_box_reg: 0.05845  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.01352  time: 2.6208  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:06:34 d2.utils.events]: \u001b[0m eta: 5:15:28  iter: 3439  total_loss: 0.2468  loss_cls: 0.108  loss_box_reg: 0.05445  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.0141  time: 2.6197  data_time: 0.0308  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:07:26 d2.utils.events]: \u001b[0m eta: 5:14:32  iter: 3459  total_loss: 0.1873  loss_cls: 0.09696  loss_box_reg: 0.05828  loss_rpn_cls: 0.01122  loss_rpn_loc: 0.01649  time: 2.6195  data_time: 0.0277  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:08:18 d2.utils.events]: \u001b[0m eta: 5:13:45  iter: 3479  total_loss: 0.2264  loss_cls: 0.1175  loss_box_reg: 0.0639  loss_rpn_cls: 0.009966  loss_rpn_loc: 0.01562  time: 2.6195  data_time: 0.0299  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:09:10 d2.utils.events]: \u001b[0m eta: 5:12:56  iter: 3499  total_loss: 0.2055  loss_cls: 0.09964  loss_box_reg: 0.05802  loss_rpn_cls: 0.008365  loss_rpn_loc: 0.02651  time: 2.6192  data_time: 0.0337  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:10:04 d2.utils.events]: \u001b[0m eta: 5:12:13  iter: 3519  total_loss: 0.1969  loss_cls: 0.1305  loss_box_reg: 0.0541  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.02145  time: 2.6198  data_time: 0.0243  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:10:58 d2.utils.events]: \u001b[0m eta: 5:11:12  iter: 3539  total_loss: 0.2151  loss_cls: 0.1044  loss_box_reg: 0.061  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.02024  time: 2.6204  data_time: 0.0268  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:11:49 d2.utils.events]: \u001b[0m eta: 5:10:16  iter: 3559  total_loss: 0.1853  loss_cls: 0.09664  loss_box_reg: 0.0526  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.01485  time: 2.6200  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:12:43 d2.utils.events]: \u001b[0m eta: 5:09:44  iter: 3579  total_loss: 0.1869  loss_cls: 0.08782  loss_box_reg: 0.05483  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.01612  time: 2.6204  data_time: 0.0263  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:12:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 19:12:49 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 19:12:49 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 19:12:49 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 19:12:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 19:12:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 19:12:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1852 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/29 19:12:57 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2293 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/29 19:13:02 d2.evaluation.evaluator]: \u001b[0mInference done 49/310. 0.2265 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/29 19:13:07 d2.evaluation.evaluator]: \u001b[0mInference done 63/310. 0.2162 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/29 19:13:12 d2.evaluation.evaluator]: \u001b[0mInference done 74/310. 0.2163 s / img. ETA=0:01:14\n",
      "\u001b[32m[04/29 19:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 91/310. 0.2091 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/29 19:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 106/310. 0.2048 s / img. ETA=0:01:04\n",
      "\u001b[32m[04/29 19:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 123/310. 0.2007 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/29 19:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 147/310. 0.1971 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/29 19:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 171/310. 0.1939 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/29 19:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 196/310. 0.1926 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/29 19:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 218/310. 0.1914 s / img. ETA=0:00:24\n",
      "\u001b[32m[04/29 19:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1902 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/29 19:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 265/310. 0.1890 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/29 19:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 287/310. 0.1885 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:17.953682 (0.255586 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.189290 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.328 | 18.297 | 14.676 | 1.420 | 14.704 | 15.419 |\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 39.974 | Carton          | 33.439 | Bottle cap     | 30.576 |\n",
      "| Can                   | 26.708 | Pop tab         | 3.522  | Cup            | 22.678 |\n",
      "| Plastic bag & wrapper | 29.750 | Styrofoam piece | 11.779 | Other plastic  | 7.241  |\n",
      "| Plastic container     | 20.719 | Paper           | 7.202  | Lid            | 14.856 |\n",
      "| Straw                 | 17.833 | Paper bag       | 0.000  | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 41.379 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 25.193 |\n",
      "| Unlabeled litter      | 1.762  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 0.000  | Cigarette       | 10.570 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 19:14:09 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 19:14:09 d2.evaluation.testing]: \u001b[0mcopypaste: 12.3279,18.2968,14.6756,1.4202,14.7035,15.4186\n",
      "\u001b[32m[04/29 19:14:56 d2.utils.events]: \u001b[0m eta: 5:08:54  iter: 3599  total_loss: 0.1689  loss_cls: 0.09132  loss_box_reg: 0.04712  loss_rpn_cls: 0.009627  loss_rpn_loc: 0.01725  time: 2.6198  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:15:47 d2.utils.events]: \u001b[0m eta: 5:08:06  iter: 3619  total_loss: 0.2122  loss_cls: 0.1086  loss_box_reg: 0.06058  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.02519  time: 2.6196  data_time: 0.0242  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:16:41 d2.utils.events]: \u001b[0m eta: 5:07:21  iter: 3639  total_loss: 0.2349  loss_cls: 0.1071  loss_box_reg: 0.05344  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.02097  time: 2.6200  data_time: 0.0314  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:17:34 d2.utils.events]: \u001b[0m eta: 5:06:36  iter: 3659  total_loss: 0.2784  loss_cls: 0.1448  loss_box_reg: 0.0801  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.02993  time: 2.6201  data_time: 0.0269  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:18:25 d2.utils.events]: \u001b[0m eta: 5:05:26  iter: 3679  total_loss: 0.2043  loss_cls: 0.1075  loss_box_reg: 0.06721  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.02185  time: 2.6198  data_time: 0.0278  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:19:19 d2.utils.events]: \u001b[0m eta: 5:04:34  iter: 3699  total_loss: 0.2266  loss_cls: 0.1079  loss_box_reg: 0.05384  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.029  time: 2.6201  data_time: 0.0313  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:20:12 d2.utils.events]: \u001b[0m eta: 5:03:45  iter: 3719  total_loss: 0.2056  loss_cls: 0.09892  loss_box_reg: 0.04922  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.02393  time: 2.6202  data_time: 0.0248  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:21:03 d2.utils.events]: \u001b[0m eta: 5:02:50  iter: 3739  total_loss: 0.1726  loss_cls: 0.08169  loss_box_reg: 0.05167  loss_rpn_cls: 0.00935  loss_rpn_loc: 0.02323  time: 2.6199  data_time: 0.0307  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:21:57 d2.utils.events]: \u001b[0m eta: 5:02:03  iter: 3759  total_loss: 0.2364  loss_cls: 0.1175  loss_box_reg: 0.07196  loss_rpn_cls: 0.01665  loss_rpn_loc: 0.02052  time: 2.6203  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:22:46 d2.utils.events]: \u001b[0m eta: 5:01:03  iter: 3779  total_loss: 0.1753  loss_cls: 0.08821  loss_box_reg: 0.0554  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.01822  time: 2.6195  data_time: 0.0399  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:23:40 d2.utils.events]: \u001b[0m eta: 5:00:17  iter: 3799  total_loss: 0.1961  loss_cls: 0.0923  loss_box_reg: 0.05266  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.01927  time: 2.6197  data_time: 0.0276  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:24:33 d2.utils.events]: \u001b[0m eta: 4:59:23  iter: 3819  total_loss: 0.2702  loss_cls: 0.1126  loss_box_reg: 0.06884  loss_rpn_cls: 0.01626  loss_rpn_loc: 0.02771  time: 2.6200  data_time: 0.0311  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:25:25 d2.utils.events]: \u001b[0m eta: 4:58:33  iter: 3839  total_loss: 0.1858  loss_cls: 0.1009  loss_box_reg: 0.04743  loss_rpn_cls: 0.02323  loss_rpn_loc: 0.02893  time: 2.6200  data_time: 0.0287  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:26:17 d2.utils.events]: \u001b[0m eta: 4:57:43  iter: 3859  total_loss: 0.1738  loss_cls: 0.09397  loss_box_reg: 0.05244  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.01636  time: 2.6197  data_time: 0.0332  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:27:08 d2.utils.events]: \u001b[0m eta: 4:56:50  iter: 3879  total_loss: 0.2067  loss_cls: 0.09285  loss_box_reg: 0.05726  loss_rpn_cls: 0.009883  loss_rpn_loc: 0.02013  time: 2.6195  data_time: 0.0306  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:28:01 d2.utils.events]: \u001b[0m eta: 4:56:07  iter: 3899  total_loss: 0.1975  loss_cls: 0.09777  loss_box_reg: 0.05417  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.02092  time: 2.6195  data_time: 0.0239  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:28:52 d2.utils.events]: \u001b[0m eta: 4:55:21  iter: 3919  total_loss: 0.1853  loss_cls: 0.08376  loss_box_reg: 0.05032  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.01765  time: 2.6193  data_time: 0.0287  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:29:47 d2.utils.events]: \u001b[0m eta: 4:54:29  iter: 3939  total_loss: 0.1865  loss_cls: 0.08492  loss_box_reg: 0.05113  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.01975  time: 2.6198  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:30:39 d2.utils.events]: \u001b[0m eta: 4:53:42  iter: 3959  total_loss: 0.2019  loss_cls: 0.1086  loss_box_reg: 0.06304  loss_rpn_cls: 0.006444  loss_rpn_loc: 0.01474  time: 2.6197  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:31:32 d2.utils.events]: \u001b[0m eta: 4:52:50  iter: 3979  total_loss: 0.2445  loss_cls: 0.1034  loss_box_reg: 0.06322  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.03102  time: 2.6200  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:32:26 d2.utils.events]: \u001b[0m eta: 4:52:00  iter: 3999  total_loss: 0.1352  loss_cls: 0.07695  loss_box_reg: 0.03717  loss_rpn_cls: 0.008847  loss_rpn_loc: 0.01038  time: 2.6203  data_time: 0.0272  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:33:18 d2.utils.events]: \u001b[0m eta: 4:50:56  iter: 4019  total_loss: 0.219  loss_cls: 0.116  loss_box_reg: 0.05607  loss_rpn_cls: 0.01879  loss_rpn_loc: 0.03444  time: 2.6203  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:34:09 d2.utils.events]: \u001b[0m eta: 4:49:43  iter: 4039  total_loss: 0.1923  loss_cls: 0.09928  loss_box_reg: 0.0503  loss_rpn_cls: 0.009603  loss_rpn_loc: 0.01671  time: 2.6198  data_time: 0.0316  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:35:02 d2.utils.events]: \u001b[0m eta: 4:49:03  iter: 4059  total_loss: 0.1491  loss_cls: 0.08646  loss_box_reg: 0.04912  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.01548  time: 2.6199  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:35:52 d2.utils.events]: \u001b[0m eta: 4:48:05  iter: 4079  total_loss: 0.2317  loss_cls: 0.109  loss_box_reg: 0.06676  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.02638  time: 2.6194  data_time: 0.0302  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:36:45 d2.utils.events]: \u001b[0m eta: 4:47:13  iter: 4099  total_loss: 0.2297  loss_cls: 0.1039  loss_box_reg: 0.07206  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.02461  time: 2.6196  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:37:35 d2.utils.events]: \u001b[0m eta: 4:46:08  iter: 4119  total_loss: 0.249  loss_cls: 0.1348  loss_box_reg: 0.06683  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.02331  time: 2.6189  data_time: 0.0332  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:38:26 d2.utils.events]: \u001b[0m eta: 4:45:17  iter: 4139  total_loss: 0.2146  loss_cls: 0.1165  loss_box_reg: 0.06093  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.02173  time: 2.6185  data_time: 0.0228  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:39:16 d2.utils.events]: \u001b[0m eta: 4:44:28  iter: 4159  total_loss: 0.1602  loss_cls: 0.08793  loss_box_reg: 0.05248  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.0268  time: 2.6181  data_time: 0.0345  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:40:07 d2.utils.events]: \u001b[0m eta: 4:43:29  iter: 4179  total_loss: 0.181  loss_cls: 0.0891  loss_box_reg: 0.05741  loss_rpn_cls: 0.009894  loss_rpn_loc: 0.01602  time: 2.6176  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:40:59 d2.utils.events]: \u001b[0m eta: 4:42:29  iter: 4199  total_loss: 0.1694  loss_cls: 0.09735  loss_box_reg: 0.05202  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.01183  time: 2.6176  data_time: 0.0274  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:41:51 d2.utils.events]: \u001b[0m eta: 4:41:16  iter: 4219  total_loss: 0.1326  loss_cls: 0.07395  loss_box_reg: 0.04379  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.0119  time: 2.6174  data_time: 0.0314  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:42:43 d2.utils.events]: \u001b[0m eta: 4:40:24  iter: 4239  total_loss: 0.2253  loss_cls: 0.1159  loss_box_reg: 0.0583  loss_rpn_cls: 0.01021  loss_rpn_loc: 0.01958  time: 2.6174  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:43:34 d2.utils.events]: \u001b[0m eta: 4:39:29  iter: 4259  total_loss: 0.1885  loss_cls: 0.08916  loss_box_reg: 0.04689  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.02384  time: 2.6171  data_time: 0.0357  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:44:27 d2.utils.events]: \u001b[0m eta: 4:38:40  iter: 4279  total_loss: 0.1705  loss_cls: 0.09467  loss_box_reg: 0.05365  loss_rpn_cls: 0.009224  loss_rpn_loc: 0.0185  time: 2.6172  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:45:23 d2.utils.events]: \u001b[0m eta: 4:38:09  iter: 4299  total_loss: 0.2683  loss_cls: 0.1208  loss_box_reg: 0.07121  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.03912  time: 2.6181  data_time: 0.0317  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:46:16 d2.utils.events]: \u001b[0m eta: 4:37:18  iter: 4319  total_loss: 0.1924  loss_cls: 0.08557  loss_box_reg: 0.05481  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.02212  time: 2.6183  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:47:07 d2.utils.events]: \u001b[0m eta: 4:36:29  iter: 4339  total_loss: 0.1931  loss_cls: 0.09745  loss_box_reg: 0.04932  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.01511  time: 2.6179  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:47:59 d2.utils.events]: \u001b[0m eta: 4:35:35  iter: 4359  total_loss: 0.2231  loss_cls: 0.1054  loss_box_reg: 0.06132  loss_rpn_cls: 0.017  loss_rpn_loc: 0.02619  time: 2.6179  data_time: 0.0406  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:48:50 d2.utils.events]: \u001b[0m eta: 4:34:16  iter: 4379  total_loss: 0.1872  loss_cls: 0.07848  loss_box_reg: 0.04783  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.01798  time: 2.6176  data_time: 0.0277  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:49:40 d2.utils.events]: \u001b[0m eta: 4:33:22  iter: 4399  total_loss: 0.1453  loss_cls: 0.07553  loss_box_reg: 0.03961  loss_rpn_cls: 0.009914  loss_rpn_loc: 0.01798  time: 2.6170  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:50:34 d2.utils.events]: \u001b[0m eta: 4:32:27  iter: 4419  total_loss: 0.2377  loss_cls: 0.1062  loss_box_reg: 0.06734  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.0255  time: 2.6174  data_time: 0.0262  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:51:28 d2.utils.events]: \u001b[0m eta: 4:31:41  iter: 4439  total_loss: 0.1788  loss_cls: 0.08515  loss_box_reg: 0.04694  loss_rpn_cls: 0.01015  loss_rpn_loc: 0.01205  time: 2.6176  data_time: 0.0243  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:52:21 d2.utils.events]: \u001b[0m eta: 4:30:48  iter: 4459  total_loss: 0.2438  loss_cls: 0.1108  loss_box_reg: 0.06648  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.04055  time: 2.6178  data_time: 0.0308  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:53:10 d2.utils.events]: \u001b[0m eta: 4:29:54  iter: 4479  total_loss: 0.186  loss_cls: 0.08935  loss_box_reg: 0.0437  loss_rpn_cls: 0.0145  loss_rpn_loc: 0.01274  time: 2.6172  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:54:04 d2.utils.events]: \u001b[0m eta: 4:29:05  iter: 4499  total_loss: 0.2402  loss_cls: 0.09041  loss_box_reg: 0.06364  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.02953  time: 2.6175  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:54:58 d2.utils.events]: \u001b[0m eta: 4:28:17  iter: 4519  total_loss: 0.2181  loss_cls: 0.09783  loss_box_reg: 0.06156  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.02505  time: 2.6179  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:55:53 d2.utils.events]: \u001b[0m eta: 4:27:25  iter: 4539  total_loss: 0.1595  loss_cls: 0.08006  loss_box_reg: 0.04724  loss_rpn_cls: 0.008937  loss_rpn_loc: 0.01467  time: 2.6184  data_time: 0.0285  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:56:45 d2.utils.events]: \u001b[0m eta: 4:26:47  iter: 4559  total_loss: 0.1745  loss_cls: 0.08833  loss_box_reg: 0.05355  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.02072  time: 2.6183  data_time: 0.0319  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:57:40 d2.utils.events]: \u001b[0m eta: 4:26:06  iter: 4579  total_loss: 0.1939  loss_cls: 0.1076  loss_box_reg: 0.05649  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.02468  time: 2.6189  data_time: 0.0298  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:58:33 d2.utils.events]: \u001b[0m eta: 4:25:19  iter: 4599  total_loss: 0.2257  loss_cls: 0.1064  loss_box_reg: 0.06341  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.02939  time: 2.6190  data_time: 0.0417  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 19:59:24 d2.utils.events]: \u001b[0m eta: 4:24:27  iter: 4619  total_loss: 0.2385  loss_cls: 0.1158  loss_box_reg: 0.06286  loss_rpn_cls: 0.013  loss_rpn_loc: 0.02047  time: 2.6187  data_time: 0.0302  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:00:15 d2.utils.events]: \u001b[0m eta: 4:23:39  iter: 4639  total_loss: 0.1967  loss_cls: 0.1018  loss_box_reg: 0.06195  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.0179  time: 2.6185  data_time: 0.0251  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:01:08 d2.utils.events]: \u001b[0m eta: 4:22:51  iter: 4659  total_loss: 0.164  loss_cls: 0.07439  loss_box_reg: 0.04317  loss_rpn_cls: 0.007488  loss_rpn_loc: 0.02027  time: 2.6184  data_time: 0.0263  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:01:58 d2.utils.events]: \u001b[0m eta: 4:22:01  iter: 4679  total_loss: 0.2139  loss_cls: 0.1092  loss_box_reg: 0.07292  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.02606  time: 2.6181  data_time: 0.0342  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:02:50 d2.utils.events]: \u001b[0m eta: 4:21:08  iter: 4699  total_loss: 0.2016  loss_cls: 0.1101  loss_box_reg: 0.06044  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01437  time: 2.6180  data_time: 0.0312  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:03:41 d2.utils.events]: \u001b[0m eta: 4:20:15  iter: 4719  total_loss: 0.1821  loss_cls: 0.1028  loss_box_reg: 0.05422  loss_rpn_cls: 0.007309  loss_rpn_loc: 0.01601  time: 2.6175  data_time: 0.0300  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:04:33 d2.utils.events]: \u001b[0m eta: 4:19:23  iter: 4739  total_loss: 0.1997  loss_cls: 0.1019  loss_box_reg: 0.05403  loss_rpn_cls: 0.008475  loss_rpn_loc: 0.01598  time: 2.6176  data_time: 0.0256  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:05:26 d2.utils.events]: \u001b[0m eta: 4:18:17  iter: 4759  total_loss: 0.18  loss_cls: 0.09414  loss_box_reg: 0.05986  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01754  time: 2.6176  data_time: 0.0281  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:06:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 20:06:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 20:06:09 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 20:06:09 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 20:06:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 20:06:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 20:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1716 s / img. ETA=0:00:53\n",
      "\u001b[32m[04/29 20:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 31/310. 0.2240 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/29 20:06:23 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2288 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/29 20:06:28 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2176 s / img. ETA=0:01:11\n",
      "\u001b[32m[04/29 20:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 73/310. 0.2177 s / img. ETA=0:01:15\n",
      "\u001b[32m[04/29 20:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 89/310. 0.2114 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/29 20:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 104/310. 0.2062 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/29 20:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 120/310. 0.2028 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/29 20:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 141/310. 0.1988 s / img. ETA=0:00:52\n",
      "\u001b[32m[04/29 20:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 166/310. 0.1964 s / img. ETA=0:00:42\n",
      "\u001b[32m[04/29 20:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 189/310. 0.1941 s / img. ETA=0:00:34\n",
      "\u001b[32m[04/29 20:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 211/310. 0.1940 s / img. ETA=0:00:27\n",
      "\u001b[32m[04/29 20:07:14 d2.evaluation.evaluator]: \u001b[0mInference done 237/310. 0.1928 s / img. ETA=0:00:19\n",
      "\u001b[32m[04/29 20:07:19 d2.evaluation.evaluator]: \u001b[0mInference done 257/310. 0.1915 s / img. ETA=0:00:14\n",
      "\u001b[32m[04/29 20:07:24 d2.evaluation.evaluator]: \u001b[0mInference done 279/310. 0.1908 s / img. ETA=0:00:08\n",
      "\u001b[32m[04/29 20:07:29 d2.evaluation.evaluator]: \u001b[0mInference done 305/310. 0.1907 s / img. ETA=0:00:01\n",
      "\u001b[32m[04/29 20:07:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:19.070576 (0.259248 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 20:07:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.191285 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 20:07:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 20:07:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 20:07:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.035 | 20.998 | 15.881 | 1.857 | 16.620 | 16.459 |\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 43.263 | Carton          | 30.721 | Bottle cap     | 29.329 |\n",
      "| Can                   | 31.108 | Pop tab         | 5.188  | Cup            | 23.962 |\n",
      "| Plastic bag & wrapper | 24.193 | Styrofoam piece | 11.338 | Other plastic  | 6.185  |\n",
      "| Plastic container     | 24.837 | Paper           | 8.885  | Lid            | 14.492 |\n",
      "| Straw                 | 21.412 | Paper bag       | 13.312 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 54.096 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 29.604 |\n",
      "| Unlabeled litter      | 2.202  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 3.366  | Cigarette       | 15.478 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 20:07:31 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 20:07:31 d2.evaluation.testing]: \u001b[0mcopypaste: 14.0347,20.9976,15.8810,1.8571,16.6204,16.4589\n",
      "\u001b[32m[04/29 20:07:43 d2.utils.events]: \u001b[0m eta: 4:17:32  iter: 4779  total_loss: 0.2008  loss_cls: 0.0989  loss_box_reg: 0.0652  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.02144  time: 2.6180  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:08:36 d2.utils.events]: \u001b[0m eta: 4:16:38  iter: 4799  total_loss: 0.212  loss_cls: 0.1022  loss_box_reg: 0.0605  loss_rpn_cls: 0.008286  loss_rpn_loc: 0.0194  time: 2.6180  data_time: 0.0530  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:09:29 d2.utils.events]: \u001b[0m eta: 4:15:56  iter: 4819  total_loss: 0.2236  loss_cls: 0.111  loss_box_reg: 0.05355  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.02437  time: 2.6183  data_time: 0.0308  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:10:22 d2.utils.events]: \u001b[0m eta: 4:15:01  iter: 4839  total_loss: 0.1724  loss_cls: 0.08539  loss_box_reg: 0.05175  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.01142  time: 2.6184  data_time: 0.0269  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:11:13 d2.utils.events]: \u001b[0m eta: 4:14:09  iter: 4859  total_loss: 0.2099  loss_cls: 0.1093  loss_box_reg: 0.06386  loss_rpn_cls: 0.008922  loss_rpn_loc: 0.02356  time: 2.6182  data_time: 0.0287  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:12:05 d2.utils.events]: \u001b[0m eta: 4:13:22  iter: 4879  total_loss: 0.2559  loss_cls: 0.1315  loss_box_reg: 0.07604  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.02646  time: 2.6179  data_time: 0.0322  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:12:58 d2.utils.events]: \u001b[0m eta: 4:12:35  iter: 4899  total_loss: 0.1935  loss_cls: 0.1072  loss_box_reg: 0.0601  loss_rpn_cls: 0.007011  loss_rpn_loc: 0.02175  time: 2.6181  data_time: 0.0270  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:13:50 d2.utils.events]: \u001b[0m eta: 4:11:43  iter: 4919  total_loss: 0.2002  loss_cls: 0.09962  loss_box_reg: 0.05804  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.02302  time: 2.6181  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:14:43 d2.utils.events]: \u001b[0m eta: 4:10:38  iter: 4939  total_loss: 0.2168  loss_cls: 0.1106  loss_box_reg: 0.06365  loss_rpn_cls: 0.007489  loss_rpn_loc: 0.02059  time: 2.6181  data_time: 0.0314  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:15:32 d2.utils.events]: \u001b[0m eta: 4:09:35  iter: 4959  total_loss: 0.1741  loss_cls: 0.09738  loss_box_reg: 0.04965  loss_rpn_cls: 0.008548  loss_rpn_loc: 0.0147  time: 2.6174  data_time: 0.0314  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:16:24 d2.utils.events]: \u001b[0m eta: 4:08:40  iter: 4979  total_loss: 0.1418  loss_cls: 0.08089  loss_box_reg: 0.05096  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.01606  time: 2.6174  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:17:16 d2.utils.events]: \u001b[0m eta: 4:07:33  iter: 4999  total_loss: 0.2082  loss_cls: 0.0885  loss_box_reg: 0.05447  loss_rpn_cls: 0.00743  loss_rpn_loc: 0.02525  time: 2.6172  data_time: 0.0276  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:18:09 d2.utils.events]: \u001b[0m eta: 4:07:11  iter: 5019  total_loss: 0.2208  loss_cls: 0.0996  loss_box_reg: 0.06962  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.02701  time: 2.6173  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:19:01 d2.utils.events]: \u001b[0m eta: 4:06:32  iter: 5039  total_loss: 0.1867  loss_cls: 0.1099  loss_box_reg: 0.05753  loss_rpn_cls: 0.008184  loss_rpn_loc: 0.02287  time: 2.6172  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:19:53 d2.utils.events]: \u001b[0m eta: 4:05:27  iter: 5059  total_loss: 0.208  loss_cls: 0.1072  loss_box_reg: 0.06098  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.02268  time: 2.6171  data_time: 0.0264  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:20:47 d2.utils.events]: \u001b[0m eta: 4:05:01  iter: 5079  total_loss: 0.1679  loss_cls: 0.08159  loss_box_reg: 0.04839  loss_rpn_cls: 0.008717  loss_rpn_loc: 0.01653  time: 2.6174  data_time: 0.0471  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:21:39 d2.utils.events]: \u001b[0m eta: 4:04:03  iter: 5099  total_loss: 0.2128  loss_cls: 0.1017  loss_box_reg: 0.05907  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.02028  time: 2.6173  data_time: 0.0280  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:22:32 d2.utils.events]: \u001b[0m eta: 4:03:17  iter: 5119  total_loss: 0.1961  loss_cls: 0.1045  loss_box_reg: 0.05911  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01346  time: 2.6174  data_time: 0.0312  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:23:23 d2.utils.events]: \u001b[0m eta: 4:02:25  iter: 5139  total_loss: 0.1564  loss_cls: 0.08358  loss_box_reg: 0.047  loss_rpn_cls: 0.009974  loss_rpn_loc: 0.01728  time: 2.6171  data_time: 0.0286  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:24:18 d2.utils.events]: \u001b[0m eta: 4:01:43  iter: 5159  total_loss: 0.2348  loss_cls: 0.1231  loss_box_reg: 0.0665  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.02353  time: 2.6177  data_time: 0.0316  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:25:09 d2.utils.events]: \u001b[0m eta: 4:00:53  iter: 5179  total_loss: 0.18  loss_cls: 0.09805  loss_box_reg: 0.05767  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.02226  time: 2.6175  data_time: 0.0324  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:25:59 d2.utils.events]: \u001b[0m eta: 4:00:04  iter: 5199  total_loss: 0.2199  loss_cls: 0.1143  loss_box_reg: 0.05741  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.02685  time: 2.6169  data_time: 0.0309  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:26:50 d2.utils.events]: \u001b[0m eta: 3:59:11  iter: 5219  total_loss: 0.2627  loss_cls: 0.1218  loss_box_reg: 0.08026  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.02288  time: 2.6168  data_time: 0.0298  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:27:42 d2.utils.events]: \u001b[0m eta: 3:58:21  iter: 5239  total_loss: 0.2668  loss_cls: 0.1275  loss_box_reg: 0.07327  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.0205  time: 2.6167  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:28:34 d2.utils.events]: \u001b[0m eta: 3:57:35  iter: 5259  total_loss: 0.1903  loss_cls: 0.08733  loss_box_reg: 0.05671  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.01856  time: 2.6167  data_time: 0.0316  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:29:27 d2.utils.events]: \u001b[0m eta: 3:56:42  iter: 5279  total_loss: 0.172  loss_cls: 0.08373  loss_box_reg: 0.05562  loss_rpn_cls: 0.009011  loss_rpn_loc: 0.01322  time: 2.6168  data_time: 0.0312  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:30:17 d2.utils.events]: \u001b[0m eta: 3:55:47  iter: 5299  total_loss: 0.2402  loss_cls: 0.1241  loss_box_reg: 0.06395  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.01632  time: 2.6163  data_time: 0.0290  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:31:09 d2.utils.events]: \u001b[0m eta: 3:54:55  iter: 5319  total_loss: 0.2172  loss_cls: 0.08926  loss_box_reg: 0.05034  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.02393  time: 2.6163  data_time: 0.0298  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:32:01 d2.utils.events]: \u001b[0m eta: 3:54:03  iter: 5339  total_loss: 0.2047  loss_cls: 0.1013  loss_box_reg: 0.06083  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.03142  time: 2.6161  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:32:56 d2.utils.events]: \u001b[0m eta: 3:53:11  iter: 5359  total_loss: 0.2154  loss_cls: 0.09538  loss_box_reg: 0.05339  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.0284  time: 2.6166  data_time: 0.0303  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:33:49 d2.utils.events]: \u001b[0m eta: 3:52:37  iter: 5379  total_loss: 0.1798  loss_cls: 0.08774  loss_box_reg: 0.05872  loss_rpn_cls: 0.008783  loss_rpn_loc: 0.01586  time: 2.6169  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:34:41 d2.utils.events]: \u001b[0m eta: 3:51:53  iter: 5399  total_loss: 0.257  loss_cls: 0.1228  loss_box_reg: 0.08249  loss_rpn_cls: 0.02067  loss_rpn_loc: 0.0464  time: 2.6167  data_time: 0.0295  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:35:32 d2.utils.events]: \u001b[0m eta: 3:51:00  iter: 5419  total_loss: 0.2031  loss_cls: 0.09983  loss_box_reg: 0.0713  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.01818  time: 2.6165  data_time: 0.0283  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:36:25 d2.utils.events]: \u001b[0m eta: 3:49:55  iter: 5439  total_loss: 0.2488  loss_cls: 0.1273  loss_box_reg: 0.07348  loss_rpn_cls: 0.01862  loss_rpn_loc: 0.03228  time: 2.6165  data_time: 0.0243  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:37:17 d2.utils.events]: \u001b[0m eta: 3:49:03  iter: 5459  total_loss: 0.1646  loss_cls: 0.093  loss_box_reg: 0.04856  loss_rpn_cls: 0.006083  loss_rpn_loc: 0.01386  time: 2.6166  data_time: 0.0318  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:38:08 d2.utils.events]: \u001b[0m eta: 3:48:17  iter: 5479  total_loss: 0.1791  loss_cls: 0.07794  loss_box_reg: 0.05086  loss_rpn_cls: 0.01081  loss_rpn_loc: 0.02747  time: 2.6163  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:38:58 d2.utils.events]: \u001b[0m eta: 3:47:14  iter: 5499  total_loss: 0.1512  loss_cls: 0.07557  loss_box_reg: 0.04393  loss_rpn_cls: 0.009496  loss_rpn_loc: 0.01205  time: 2.6158  data_time: 0.0275  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:39:50 d2.utils.events]: \u001b[0m eta: 3:46:15  iter: 5519  total_loss: 0.1486  loss_cls: 0.08334  loss_box_reg: 0.04523  loss_rpn_cls: 0.009759  loss_rpn_loc: 0.01505  time: 2.6158  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:40:42 d2.utils.events]: \u001b[0m eta: 3:45:21  iter: 5539  total_loss: 0.1828  loss_cls: 0.0938  loss_box_reg: 0.05419  loss_rpn_cls: 0.008311  loss_rpn_loc: 0.01217  time: 2.6156  data_time: 0.0266  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:41:36 d2.utils.events]: \u001b[0m eta: 3:44:31  iter: 5559  total_loss: 0.1903  loss_cls: 0.09807  loss_box_reg: 0.05479  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.01788  time: 2.6159  data_time: 0.0324  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:42:29 d2.utils.events]: \u001b[0m eta: 3:43:32  iter: 5579  total_loss: 0.2123  loss_cls: 0.09231  loss_box_reg: 0.06184  loss_rpn_cls: 0.008996  loss_rpn_loc: 0.0226  time: 2.6162  data_time: 0.0318  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:43:23 d2.utils.events]: \u001b[0m eta: 3:42:40  iter: 5599  total_loss: 0.1563  loss_cls: 0.09091  loss_box_reg: 0.05136  loss_rpn_cls: 0.009445  loss_rpn_loc: 0.01246  time: 2.6163  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:44:16 d2.utils.events]: \u001b[0m eta: 3:41:52  iter: 5619  total_loss: 0.191  loss_cls: 0.09564  loss_box_reg: 0.04503  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.01625  time: 2.6166  data_time: 0.0309  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:45:11 d2.utils.events]: \u001b[0m eta: 3:41:00  iter: 5639  total_loss: 0.2389  loss_cls: 0.1267  loss_box_reg: 0.07629  loss_rpn_cls: 0.008059  loss_rpn_loc: 0.02253  time: 2.6170  data_time: 0.0243  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:46:02 d2.utils.events]: \u001b[0m eta: 3:40:03  iter: 5659  total_loss: 0.2047  loss_cls: 0.08642  loss_box_reg: 0.06001  loss_rpn_cls: 0.008723  loss_rpn_loc: 0.02707  time: 2.6168  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:46:54 d2.utils.events]: \u001b[0m eta: 3:39:11  iter: 5679  total_loss: 0.1972  loss_cls: 0.08986  loss_box_reg: 0.07102  loss_rpn_cls: 0.009415  loss_rpn_loc: 0.02542  time: 2.6168  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:47:48 d2.utils.events]: \u001b[0m eta: 3:38:27  iter: 5699  total_loss: 0.2176  loss_cls: 0.09886  loss_box_reg: 0.05885  loss_rpn_cls: 0.008084  loss_rpn_loc: 0.01752  time: 2.6170  data_time: 0.0291  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:48:41 d2.utils.events]: \u001b[0m eta: 3:37:35  iter: 5719  total_loss: 0.1873  loss_cls: 0.08643  loss_box_reg: 0.06204  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.02444  time: 2.6171  data_time: 0.0349  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:49:32 d2.utils.events]: \u001b[0m eta: 3:36:39  iter: 5739  total_loss: 0.1836  loss_cls: 0.09447  loss_box_reg: 0.05661  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.01828  time: 2.6169  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:50:25 d2.utils.events]: \u001b[0m eta: 3:35:51  iter: 5759  total_loss: 0.169  loss_cls: 0.08529  loss_box_reg: 0.05409  loss_rpn_cls: 0.008712  loss_rpn_loc: 0.01317  time: 2.6170  data_time: 0.0280  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:51:18 d2.utils.events]: \u001b[0m eta: 3:34:59  iter: 5779  total_loss: 0.2621  loss_cls: 0.1078  loss_box_reg: 0.06042  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.03016  time: 2.6172  data_time: 0.0306  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:52:13 d2.utils.events]: \u001b[0m eta: 3:34:09  iter: 5799  total_loss: 0.1485  loss_cls: 0.07129  loss_box_reg: 0.04095  loss_rpn_cls: 0.008467  loss_rpn_loc: 0.009254  time: 2.6175  data_time: 0.0326  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:53:06 d2.utils.events]: \u001b[0m eta: 3:33:14  iter: 5819  total_loss: 0.214  loss_cls: 0.08097  loss_box_reg: 0.04808  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.01735  time: 2.6177  data_time: 0.0306  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:54:00 d2.utils.events]: \u001b[0m eta: 3:32:25  iter: 5839  total_loss: 0.1673  loss_cls: 0.08653  loss_box_reg: 0.04616  loss_rpn_cls: 0.008659  loss_rpn_loc: 0.01413  time: 2.6180  data_time: 0.0336  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:54:54 d2.utils.events]: \u001b[0m eta: 3:31:38  iter: 5859  total_loss: 0.254  loss_cls: 0.1212  loss_box_reg: 0.07771  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.02202  time: 2.6181  data_time: 0.0252  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:55:48 d2.utils.events]: \u001b[0m eta: 3:30:55  iter: 5879  total_loss: 0.2101  loss_cls: 0.1129  loss_box_reg: 0.06893  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.01435  time: 2.6184  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:56:42 d2.utils.events]: \u001b[0m eta: 3:30:02  iter: 5899  total_loss: 0.2156  loss_cls: 0.1025  loss_box_reg: 0.06505  loss_rpn_cls: 0.009994  loss_rpn_loc: 0.02479  time: 2.6187  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:57:34 d2.utils.events]: \u001b[0m eta: 3:29:02  iter: 5919  total_loss: 0.1762  loss_cls: 0.09628  loss_box_reg: 0.05365  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.01436  time: 2.6186  data_time: 0.0278  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:58:26 d2.utils.events]: \u001b[0m eta: 3:28:10  iter: 5939  total_loss: 0.1509  loss_cls: 0.07692  loss_box_reg: 0.04821  loss_rpn_cls: 0.004701  loss_rpn_loc: 0.01285  time: 2.6186  data_time: 0.0261  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:59:16 d2.utils.events]: \u001b[0m eta: 3:27:16  iter: 5959  total_loss: 0.1991  loss_cls: 0.09002  loss_box_reg: 0.0599  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.0276  time: 2.6182  data_time: 0.0243  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 20:59:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 20:59:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 20:59:41 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 20:59:41 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 20:59:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 20:59:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 20:59:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1867 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/29 20:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2279 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/29 20:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2362 s / img. ETA=0:01:15\n",
      "\u001b[32m[04/29 21:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2222 s / img. ETA=0:01:14\n",
      "\u001b[32m[04/29 21:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 75/310. 0.2177 s / img. ETA=0:01:14\n",
      "\u001b[32m[04/29 21:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 92/310. 0.2111 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/29 21:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 107/310. 0.2074 s / img. ETA=0:01:04\n",
      "\u001b[32m[04/29 21:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 124/310. 0.2028 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/29 21:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 146/310. 0.1996 s / img. ETA=0:00:49\n",
      "\u001b[32m[04/29 21:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 168/310. 0.1982 s / img. ETA=0:00:41\n",
      "\u001b[32m[04/29 21:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 192/310. 0.1967 s / img. ETA=0:00:33\n",
      "\u001b[32m[04/29 21:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 217/310. 0.1947 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/29 21:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1931 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/29 21:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 266/310. 0.1916 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/29 21:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 289/310. 0.1912 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/29 21:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 310/310. 0.1923 s / img. ETA=0:00:00\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:19.157795 (0.259534 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.192258 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.16 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.616 | 21.361 | 15.708 | 2.380 | 14.572 | 16.169 |\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 39.393 | Carton          | 33.411 | Bottle cap     | 21.842 |\n",
      "| Can                   | 33.838 | Pop tab         | 6.554  | Cup            | 27.140 |\n",
      "| Plastic bag & wrapper | 29.092 | Styrofoam piece | 16.940 | Other plastic  | 6.666  |\n",
      "| Plastic container     | 18.326 | Paper           | 9.599  | Lid            | 16.863 |\n",
      "| Straw                 | 19.717 | Paper bag       | 13.886 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 52.873 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 17.327 |\n",
      "| Unlabeled litter      | 2.315  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 4.208  | Cigarette       | 11.259 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 21:01:03 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 21:01:03 d2.evaluation.testing]: \u001b[0mcopypaste: 13.6161,21.3607,15.7081,2.3797,14.5723,16.1695\n",
      "\u001b[32m[04/29 21:01:29 d2.utils.events]: \u001b[0m eta: 3:26:23  iter: 5979  total_loss: 0.2043  loss_cls: 0.1091  loss_box_reg: 0.06481  loss_rpn_cls: 0.00896  loss_rpn_loc: 0.01509  time: 2.6178  data_time: 0.0335  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:02:22 d2.utils.events]: \u001b[0m eta: 3:25:40  iter: 5999  total_loss: 0.2094  loss_cls: 0.1068  loss_box_reg: 0.06024  loss_rpn_cls: 0.009471  loss_rpn_loc: 0.01891  time: 2.6178  data_time: 0.0311  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:03:17 d2.utils.events]: \u001b[0m eta: 3:24:43  iter: 6019  total_loss: 0.1825  loss_cls: 0.07927  loss_box_reg: 0.04509  loss_rpn_cls: 0.00898  loss_rpn_loc: 0.03492  time: 2.6183  data_time: 0.0799  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:04:09 d2.utils.events]: \u001b[0m eta: 3:23:48  iter: 6039  total_loss: 0.194  loss_cls: 0.08605  loss_box_reg: 0.05379  loss_rpn_cls: 0.009485  loss_rpn_loc: 0.01174  time: 2.6182  data_time: 0.0260  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:05:01 d2.utils.events]: \u001b[0m eta: 3:22:58  iter: 6059  total_loss: 0.2347  loss_cls: 0.1248  loss_box_reg: 0.06555  loss_rpn_cls: 0.008322  loss_rpn_loc: 0.0212  time: 2.6182  data_time: 0.0301  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:05:54 d2.utils.events]: \u001b[0m eta: 3:22:06  iter: 6079  total_loss: 0.2027  loss_cls: 0.1004  loss_box_reg: 0.06766  loss_rpn_cls: 0.007153  loss_rpn_loc: 0.01425  time: 2.6183  data_time: 0.0260  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:06:46 d2.utils.events]: \u001b[0m eta: 3:21:19  iter: 6099  total_loss: 0.2318  loss_cls: 0.1089  loss_box_reg: 0.07401  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.03427  time: 2.6181  data_time: 0.0309  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:07:40 d2.utils.events]: \u001b[0m eta: 3:20:38  iter: 6119  total_loss: 0.1563  loss_cls: 0.09126  loss_box_reg: 0.0474  loss_rpn_cls: 0.008608  loss_rpn_loc: 0.01508  time: 2.6185  data_time: 0.0255  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:08:34 d2.utils.events]: \u001b[0m eta: 3:19:48  iter: 6139  total_loss: 0.1949  loss_cls: 0.09345  loss_box_reg: 0.05796  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.02045  time: 2.6188  data_time: 0.0260  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:09:28 d2.utils.events]: \u001b[0m eta: 3:18:44  iter: 6159  total_loss: 0.1708  loss_cls: 0.09382  loss_box_reg: 0.05185  loss_rpn_cls: 0.008531  loss_rpn_loc: 0.01545  time: 2.6189  data_time: 0.0272  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:10:19 d2.utils.events]: \u001b[0m eta: 3:17:47  iter: 6179  total_loss: 0.167  loss_cls: 0.08715  loss_box_reg: 0.05314  loss_rpn_cls: 0.007657  loss_rpn_loc: 0.01213  time: 2.6187  data_time: 0.0320  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:11:08 d2.utils.events]: \u001b[0m eta: 3:16:54  iter: 6199  total_loss: 0.1816  loss_cls: 0.09316  loss_box_reg: 0.05507  loss_rpn_cls: 0.008079  loss_rpn_loc: 0.02046  time: 2.6182  data_time: 0.0270  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:12:01 d2.utils.events]: \u001b[0m eta: 3:16:05  iter: 6219  total_loss: 0.242  loss_cls: 0.08331  loss_box_reg: 0.05201  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.02284  time: 2.6182  data_time: 0.0244  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:12:54 d2.utils.events]: \u001b[0m eta: 3:15:15  iter: 6239  total_loss: 0.1993  loss_cls: 0.08835  loss_box_reg: 0.04815  loss_rpn_cls: 0.009441  loss_rpn_loc: 0.01836  time: 2.6183  data_time: 0.0336  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:13:45 d2.utils.events]: \u001b[0m eta: 3:14:20  iter: 6259  total_loss: 0.1826  loss_cls: 0.08756  loss_box_reg: 0.05188  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.01893  time: 2.6182  data_time: 0.0283  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:14:37 d2.utils.events]: \u001b[0m eta: 3:13:31  iter: 6279  total_loss: 0.2104  loss_cls: 0.1  loss_box_reg: 0.06354  loss_rpn_cls: 0.009635  loss_rpn_loc: 0.01571  time: 2.6182  data_time: 0.0367  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:15:30 d2.utils.events]: \u001b[0m eta: 3:12:40  iter: 6299  total_loss: 0.1853  loss_cls: 0.09009  loss_box_reg: 0.05479  loss_rpn_cls: 0.009814  loss_rpn_loc: 0.01432  time: 2.6182  data_time: 0.0229  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:16:23 d2.utils.events]: \u001b[0m eta: 3:11:48  iter: 6319  total_loss: 0.1876  loss_cls: 0.07633  loss_box_reg: 0.05281  loss_rpn_cls: 0.006832  loss_rpn_loc: 0.0209  time: 2.6183  data_time: 0.0342  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:17:13 d2.utils.events]: \u001b[0m eta: 3:10:55  iter: 6339  total_loss: 0.1763  loss_cls: 0.08919  loss_box_reg: 0.05192  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.009817  time: 2.6180  data_time: 0.0254  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:18:05 d2.utils.events]: \u001b[0m eta: 3:10:00  iter: 6359  total_loss: 0.1647  loss_cls: 0.09322  loss_box_reg: 0.04948  loss_rpn_cls: 0.009569  loss_rpn_loc: 0.03029  time: 2.6178  data_time: 0.0333  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:18:57 d2.utils.events]: \u001b[0m eta: 3:08:54  iter: 6379  total_loss: 0.2206  loss_cls: 0.1071  loss_box_reg: 0.06753  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.02874  time: 2.6178  data_time: 0.0321  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:19:50 d2.utils.events]: \u001b[0m eta: 3:08:02  iter: 6399  total_loss: 0.1765  loss_cls: 0.08984  loss_box_reg: 0.05582  loss_rpn_cls: 0.007318  loss_rpn_loc: 0.01641  time: 2.6180  data_time: 0.0308  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:20:42 d2.utils.events]: \u001b[0m eta: 3:07:10  iter: 6419  total_loss: 0.1941  loss_cls: 0.09658  loss_box_reg: 0.0574  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.0335  time: 2.6178  data_time: 0.0306  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:21:33 d2.utils.events]: \u001b[0m eta: 3:06:21  iter: 6439  total_loss: 0.1591  loss_cls: 0.07378  loss_box_reg: 0.0509  loss_rpn_cls: 0.007231  loss_rpn_loc: 0.02355  time: 2.6177  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:22:27 d2.utils.events]: \u001b[0m eta: 3:05:38  iter: 6459  total_loss: 0.1881  loss_cls: 0.08546  loss_box_reg: 0.04388  loss_rpn_cls: 0.007684  loss_rpn_loc: 0.0157  time: 2.6179  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:23:19 d2.utils.events]: \u001b[0m eta: 3:04:47  iter: 6479  total_loss: 0.2542  loss_cls: 0.1012  loss_box_reg: 0.07523  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.03574  time: 2.6178  data_time: 0.0307  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:24:11 d2.utils.events]: \u001b[0m eta: 3:03:57  iter: 6499  total_loss: 0.1739  loss_cls: 0.07887  loss_box_reg: 0.05446  loss_rpn_cls: 0.008421  loss_rpn_loc: 0.01454  time: 2.6178  data_time: 0.0270  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:25:03 d2.utils.events]: \u001b[0m eta: 3:03:04  iter: 6519  total_loss: 0.1796  loss_cls: 0.08662  loss_box_reg: 0.05936  loss_rpn_cls: 0.008832  loss_rpn_loc: 0.01551  time: 2.6177  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:25:57 d2.utils.events]: \u001b[0m eta: 3:02:12  iter: 6539  total_loss: 0.1981  loss_cls: 0.09994  loss_box_reg: 0.06262  loss_rpn_cls: 0.008977  loss_rpn_loc: 0.01519  time: 2.6180  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:26:54 d2.utils.events]: \u001b[0m eta: 3:01:20  iter: 6559  total_loss: 0.1908  loss_cls: 0.0951  loss_box_reg: 0.05877  loss_rpn_cls: 0.006048  loss_rpn_loc: 0.01687  time: 2.6187  data_time: 0.0276  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:27:46 d2.utils.events]: \u001b[0m eta: 3:00:18  iter: 6579  total_loss: 0.2097  loss_cls: 0.09802  loss_box_reg: 0.06879  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.02157  time: 2.6186  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:28:37 d2.utils.events]: \u001b[0m eta: 2:59:23  iter: 6599  total_loss: 0.2129  loss_cls: 0.09948  loss_box_reg: 0.06234  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.02239  time: 2.6184  data_time: 0.0277  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:29:30 d2.utils.events]: \u001b[0m eta: 2:58:29  iter: 6619  total_loss: 0.2061  loss_cls: 0.1125  loss_box_reg: 0.06512  loss_rpn_cls: 0.007929  loss_rpn_loc: 0.01898  time: 2.6184  data_time: 0.0294  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:30:20 d2.utils.events]: \u001b[0m eta: 2:57:31  iter: 6639  total_loss: 0.146  loss_cls: 0.06208  loss_box_reg: 0.0537  loss_rpn_cls: 0.009492  loss_rpn_loc: 0.01316  time: 2.6182  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:31:12 d2.utils.events]: \u001b[0m eta: 2:56:45  iter: 6659  total_loss: 0.1825  loss_cls: 0.0921  loss_box_reg: 0.05356  loss_rpn_cls: 0.008152  loss_rpn_loc: 0.01644  time: 2.6181  data_time: 0.0257  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:32:04 d2.utils.events]: \u001b[0m eta: 2:55:54  iter: 6679  total_loss: 0.2269  loss_cls: 0.1014  loss_box_reg: 0.06348  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.02256  time: 2.6181  data_time: 0.0311  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:32:57 d2.utils.events]: \u001b[0m eta: 2:55:01  iter: 6699  total_loss: 0.1517  loss_cls: 0.0749  loss_box_reg: 0.04954  loss_rpn_cls: 0.009915  loss_rpn_loc: 0.01136  time: 2.6181  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:33:49 d2.utils.events]: \u001b[0m eta: 2:54:09  iter: 6719  total_loss: 0.1556  loss_cls: 0.07887  loss_box_reg: 0.04604  loss_rpn_cls: 0.007424  loss_rpn_loc: 0.01518  time: 2.6180  data_time: 0.0274  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:34:41 d2.utils.events]: \u001b[0m eta: 2:53:25  iter: 6739  total_loss: 0.1832  loss_cls: 0.08482  loss_box_reg: 0.05461  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.01744  time: 2.6180  data_time: 0.0367  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:35:34 d2.utils.events]: \u001b[0m eta: 2:52:28  iter: 6759  total_loss: 0.1705  loss_cls: 0.09387  loss_box_reg: 0.04824  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.01301  time: 2.6181  data_time: 0.0270  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:36:24 d2.utils.events]: \u001b[0m eta: 2:51:33  iter: 6779  total_loss: 0.2427  loss_cls: 0.1108  loss_box_reg: 0.06935  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.0255  time: 2.6177  data_time: 0.0371  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:37:15 d2.utils.events]: \u001b[0m eta: 2:50:38  iter: 6799  total_loss: 0.2019  loss_cls: 0.09712  loss_box_reg: 0.05687  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.02226  time: 2.6175  data_time: 0.0561  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:38:07 d2.utils.events]: \u001b[0m eta: 2:49:44  iter: 6819  total_loss: 0.1981  loss_cls: 0.08866  loss_box_reg: 0.06247  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.02593  time: 2.6175  data_time: 0.0389  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:39:03 d2.utils.events]: \u001b[0m eta: 2:48:52  iter: 6839  total_loss: 0.187  loss_cls: 0.09369  loss_box_reg: 0.04962  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.01436  time: 2.6180  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:39:56 d2.utils.events]: \u001b[0m eta: 2:47:51  iter: 6859  total_loss: 0.1356  loss_cls: 0.06959  loss_box_reg: 0.0436  loss_rpn_cls: 0.008803  loss_rpn_loc: 0.012  time: 2.6182  data_time: 0.0278  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:40:47 d2.utils.events]: \u001b[0m eta: 2:46:58  iter: 6879  total_loss: 0.1988  loss_cls: 0.08839  loss_box_reg: 0.06865  loss_rpn_cls: 0.007942  loss_rpn_loc: 0.01801  time: 2.6179  data_time: 0.0294  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:41:37 d2.utils.events]: \u001b[0m eta: 2:45:56  iter: 6899  total_loss: 0.1722  loss_cls: 0.08653  loss_box_reg: 0.05607  loss_rpn_cls: 0.006397  loss_rpn_loc: 0.02119  time: 2.6175  data_time: 0.0325  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:42:30 d2.utils.events]: \u001b[0m eta: 2:45:08  iter: 6919  total_loss: 0.1948  loss_cls: 0.1024  loss_box_reg: 0.06678  loss_rpn_cls: 0.007158  loss_rpn_loc: 0.01305  time: 2.6177  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:43:23 d2.utils.events]: \u001b[0m eta: 2:44:22  iter: 6939  total_loss: 0.2161  loss_cls: 0.09787  loss_box_reg: 0.06851  loss_rpn_cls: 0.005915  loss_rpn_loc: 0.02131  time: 2.6177  data_time: 0.0272  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:44:17 d2.utils.events]: \u001b[0m eta: 2:43:41  iter: 6959  total_loss: 0.1745  loss_cls: 0.07895  loss_box_reg: 0.05343  loss_rpn_cls: 0.007944  loss_rpn_loc: 0.01205  time: 2.6179  data_time: 0.0285  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:45:10 d2.utils.events]: \u001b[0m eta: 2:42:54  iter: 6979  total_loss: 0.1727  loss_cls: 0.09034  loss_box_reg: 0.05478  loss_rpn_cls: 0.008796  loss_rpn_loc: 0.02173  time: 2.6181  data_time: 0.0246  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:46:03 d2.utils.events]: \u001b[0m eta: 2:42:02  iter: 6999  total_loss: 0.2185  loss_cls: 0.1004  loss_box_reg: 0.05502  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.03641  time: 2.6181  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:46:59 d2.utils.events]: \u001b[0m eta: 2:41:13  iter: 7019  total_loss: 0.1933  loss_cls: 0.09884  loss_box_reg: 0.06201  loss_rpn_cls: 0.009655  loss_rpn_loc: 0.01696  time: 2.6187  data_time: 0.0305  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:47:52 d2.utils.events]: \u001b[0m eta: 2:40:19  iter: 7039  total_loss: 0.1561  loss_cls: 0.07343  loss_box_reg: 0.04522  loss_rpn_cls: 0.008439  loss_rpn_loc: 0.01924  time: 2.6188  data_time: 0.0269  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:48:46 d2.utils.events]: \u001b[0m eta: 2:39:28  iter: 7059  total_loss: 0.1772  loss_cls: 0.07825  loss_box_reg: 0.05003  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.02818  time: 2.6189  data_time: 0.0257  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:49:37 d2.utils.events]: \u001b[0m eta: 2:38:33  iter: 7079  total_loss: 0.2193  loss_cls: 0.1118  loss_box_reg: 0.07373  loss_rpn_cls: 0.007564  loss_rpn_loc: 0.02768  time: 2.6188  data_time: 0.0322  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:50:31 d2.utils.events]: \u001b[0m eta: 2:37:42  iter: 7099  total_loss: 0.2121  loss_cls: 0.1009  loss_box_reg: 0.06125  loss_rpn_cls: 0.007722  loss_rpn_loc: 0.0198  time: 2.6189  data_time: 0.0315  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:51:20 d2.utils.events]: \u001b[0m eta: 2:36:43  iter: 7119  total_loss: 0.1999  loss_cls: 0.09511  loss_box_reg: 0.05622  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.01961  time: 2.6185  data_time: 0.0295  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:52:14 d2.utils.events]: \u001b[0m eta: 2:35:53  iter: 7139  total_loss: 0.1793  loss_cls: 0.09171  loss_box_reg: 0.0514  loss_rpn_cls: 0.009918  loss_rpn_loc: 0.01449  time: 2.6187  data_time: 0.0306  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:53:06 d2.utils.events]: \u001b[0m eta: 2:35:05  iter: 7159  total_loss: 0.1946  loss_cls: 0.09223  loss_box_reg: 0.05514  loss_rpn_cls: 0.00964  loss_rpn_loc: 0.02955  time: 2.6187  data_time: 0.0315  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:53:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 21:53:17 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 21:53:17 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 21:53:17 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 21:53:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 21:53:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 21:53:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1943 s / img. ETA=0:00:59\n",
      "\u001b[32m[04/29 21:53:26 d2.evaluation.evaluator]: \u001b[0mInference done 31/310. 0.2302 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/29 21:53:31 d2.evaluation.evaluator]: \u001b[0mInference done 48/310. 0.2301 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/29 21:53:36 d2.evaluation.evaluator]: \u001b[0mInference done 63/310. 0.2209 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/29 21:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 74/310. 0.2183 s / img. ETA=0:01:13\n",
      "\u001b[32m[04/29 21:53:47 d2.evaluation.evaluator]: \u001b[0mInference done 90/310. 0.2111 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/29 21:53:52 d2.evaluation.evaluator]: \u001b[0mInference done 107/310. 0.2052 s / img. ETA=0:01:04\n",
      "\u001b[32m[04/29 21:53:57 d2.evaluation.evaluator]: \u001b[0mInference done 124/310. 0.2015 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/29 21:54:02 d2.evaluation.evaluator]: \u001b[0mInference done 149/310. 0.1970 s / img. ETA=0:00:47\n",
      "\u001b[32m[04/29 21:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 173/310. 0.1947 s / img. ETA=0:00:38\n",
      "\u001b[32m[04/29 21:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 196/310. 0.1943 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/29 21:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 221/310. 0.1921 s / img. ETA=0:00:23\n",
      "\u001b[32m[04/29 21:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1914 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/29 21:54:28 d2.evaluation.evaluator]: \u001b[0mInference done 266/310. 0.1896 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/29 21:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 287/310. 0.1892 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/29 21:54:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:17.902138 (0.255417 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 21:54:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.189443 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 21:54:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 21:54:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 21:54:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.47 seconds.\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.14 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.116 | 22.107 | 18.039 | 2.701 | 15.196 | 17.810 |\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 43.657 | Carton          | 33.070 | Bottle cap     | 27.735 |\n",
      "| Can                   | 34.850 | Pop tab         | 5.130  | Cup            | 34.895 |\n",
      "| Plastic bag & wrapper | 30.282 | Styrofoam piece | 16.135 | Other plastic  | 8.342  |\n",
      "| Plastic container     | 24.788 | Paper           | 10.263 | Lid            | 17.172 |\n",
      "| Straw                 | 19.136 | Paper bag       | 16.832 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 57.228 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 22.277 |\n",
      "| Unlabeled litter      | 2.582  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 3.366  | Cigarette       | 15.513 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 21:54:38 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 21:54:38 d2.evaluation.testing]: \u001b[0mcopypaste: 15.1162,22.1069,18.0395,2.7009,15.1956,17.8104\n",
      "\u001b[32m[04/29 21:55:21 d2.utils.events]: \u001b[0m eta: 2:34:14  iter: 7179  total_loss: 0.1904  loss_cls: 0.08867  loss_box_reg: 0.05827  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.02641  time: 2.6187  data_time: 0.0284  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:56:17 d2.utils.events]: \u001b[0m eta: 2:33:25  iter: 7199  total_loss: 0.1955  loss_cls: 0.08848  loss_box_reg: 0.054  loss_rpn_cls: 0.006328  loss_rpn_loc: 0.01772  time: 2.6192  data_time: 0.0263  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:57:09 d2.utils.events]: \u001b[0m eta: 2:32:32  iter: 7219  total_loss: 0.1515  loss_cls: 0.07418  loss_box_reg: 0.04249  loss_rpn_cls: 0.00602  loss_rpn_loc: 0.01041  time: 2.6191  data_time: 0.0711  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:58:01 d2.utils.events]: \u001b[0m eta: 2:31:39  iter: 7239  total_loss: 0.1678  loss_cls: 0.07077  loss_box_reg: 0.0496  loss_rpn_cls: 0.007327  loss_rpn_loc: 0.02068  time: 2.6191  data_time: 0.0317  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:58:54 d2.utils.events]: \u001b[0m eta: 2:30:50  iter: 7259  total_loss: 0.1683  loss_cls: 0.08951  loss_box_reg: 0.05589  loss_rpn_cls: 0.007238  loss_rpn_loc: 0.01128  time: 2.6193  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 21:59:46 d2.utils.events]: \u001b[0m eta: 2:29:56  iter: 7279  total_loss: 0.1816  loss_cls: 0.08817  loss_box_reg: 0.06017  loss_rpn_cls: 0.009078  loss_rpn_loc: 0.01993  time: 2.6192  data_time: 0.0316  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:00:38 d2.utils.events]: \u001b[0m eta: 2:29:04  iter: 7299  total_loss: 0.1873  loss_cls: 0.07861  loss_box_reg: 0.05089  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.0207  time: 2.6191  data_time: 0.0276  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:01:29 d2.utils.events]: \u001b[0m eta: 2:28:12  iter: 7319  total_loss: 0.1818  loss_cls: 0.08988  loss_box_reg: 0.05636  loss_rpn_cls: 0.00706  loss_rpn_loc: 0.01755  time: 2.6189  data_time: 0.0286  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:02:22 d2.utils.events]: \u001b[0m eta: 2:27:21  iter: 7339  total_loss: 0.1947  loss_cls: 0.1043  loss_box_reg: 0.06662  loss_rpn_cls: 0.008561  loss_rpn_loc: 0.02228  time: 2.6189  data_time: 0.0313  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:03:11 d2.utils.events]: \u001b[0m eta: 2:26:29  iter: 7359  total_loss: 0.1881  loss_cls: 0.08409  loss_box_reg: 0.05031  loss_rpn_cls: 0.009437  loss_rpn_loc: 0.0211  time: 2.6186  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:04:05 d2.utils.events]: \u001b[0m eta: 2:25:44  iter: 7379  total_loss: 0.1701  loss_cls: 0.07042  loss_box_reg: 0.05978  loss_rpn_cls: 0.007961  loss_rpn_loc: 0.02024  time: 2.6187  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:04:56 d2.utils.events]: \u001b[0m eta: 2:24:49  iter: 7399  total_loss: 0.1835  loss_cls: 0.08885  loss_box_reg: 0.05027  loss_rpn_cls: 0.009431  loss_rpn_loc: 0.02651  time: 2.6185  data_time: 0.0322  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:05:48 d2.utils.events]: \u001b[0m eta: 2:23:53  iter: 7419  total_loss: 0.2135  loss_cls: 0.09455  loss_box_reg: 0.07123  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.02164  time: 2.6185  data_time: 0.0284  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:06:39 d2.utils.events]: \u001b[0m eta: 2:23:01  iter: 7439  total_loss: 0.143  loss_cls: 0.07357  loss_box_reg: 0.04583  loss_rpn_cls: 0.007373  loss_rpn_loc: 0.01545  time: 2.6183  data_time: 0.0277  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:07:32 d2.utils.events]: \u001b[0m eta: 2:22:08  iter: 7459  total_loss: 0.1796  loss_cls: 0.08867  loss_box_reg: 0.06517  loss_rpn_cls: 0.005699  loss_rpn_loc: 0.01494  time: 2.6183  data_time: 0.0373  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:08:26 d2.utils.events]: \u001b[0m eta: 2:21:16  iter: 7479  total_loss: 0.1632  loss_cls: 0.0855  loss_box_reg: 0.05499  loss_rpn_cls: 0.006314  loss_rpn_loc: 0.02082  time: 2.6186  data_time: 0.0366  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:09:21 d2.utils.events]: \u001b[0m eta: 2:20:25  iter: 7499  total_loss: 0.1506  loss_cls: 0.07398  loss_box_reg: 0.04674  loss_rpn_cls: 0.008381  loss_rpn_loc: 0.03393  time: 2.6190  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:10:16 d2.utils.events]: \u001b[0m eta: 2:19:35  iter: 7519  total_loss: 0.2123  loss_cls: 0.09229  loss_box_reg: 0.05863  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.02673  time: 2.6193  data_time: 0.0316  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:11:06 d2.utils.events]: \u001b[0m eta: 2:18:41  iter: 7539  total_loss: 0.1744  loss_cls: 0.09239  loss_box_reg: 0.05833  loss_rpn_cls: 0.008113  loss_rpn_loc: 0.01312  time: 2.6190  data_time: 0.0330  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:11:59 d2.utils.events]: \u001b[0m eta: 2:17:48  iter: 7559  total_loss: 0.1816  loss_cls: 0.08912  loss_box_reg: 0.05851  loss_rpn_cls: 0.008497  loss_rpn_loc: 0.02351  time: 2.6190  data_time: 0.0236  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:12:53 d2.utils.events]: \u001b[0m eta: 2:17:04  iter: 7579  total_loss: 0.2005  loss_cls: 0.0974  loss_box_reg: 0.05909  loss_rpn_cls: 0.009039  loss_rpn_loc: 0.02963  time: 2.6192  data_time: 0.0310  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:13:43 d2.utils.events]: \u001b[0m eta: 2:16:09  iter: 7599  total_loss: 0.1958  loss_cls: 0.08941  loss_box_reg: 0.06891  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.01664  time: 2.6190  data_time: 0.0303  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:14:36 d2.utils.events]: \u001b[0m eta: 2:15:19  iter: 7619  total_loss: 0.1509  loss_cls: 0.07026  loss_box_reg: 0.04253  loss_rpn_cls: 0.005266  loss_rpn_loc: 0.01712  time: 2.6190  data_time: 0.0325  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:15:27 d2.utils.events]: \u001b[0m eta: 2:14:30  iter: 7639  total_loss: 0.2008  loss_cls: 0.09652  loss_box_reg: 0.05935  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.02451  time: 2.6189  data_time: 0.0260  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:16:19 d2.utils.events]: \u001b[0m eta: 2:13:36  iter: 7659  total_loss: 0.1507  loss_cls: 0.07631  loss_box_reg: 0.0552  loss_rpn_cls: 0.007275  loss_rpn_loc: 0.01337  time: 2.6187  data_time: 0.0286  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:17:09 d2.utils.events]: \u001b[0m eta: 2:12:41  iter: 7679  total_loss: 0.2546  loss_cls: 0.1192  loss_box_reg: 0.07501  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.03744  time: 2.6185  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:18:00 d2.utils.events]: \u001b[0m eta: 2:11:49  iter: 7699  total_loss: 0.1798  loss_cls: 0.0988  loss_box_reg: 0.06686  loss_rpn_cls: 0.008205  loss_rpn_loc: 0.0139  time: 2.6183  data_time: 0.0251  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:18:55 d2.utils.events]: \u001b[0m eta: 2:10:58  iter: 7719  total_loss: 0.135  loss_cls: 0.062  loss_box_reg: 0.04352  loss_rpn_cls: 0.009889  loss_rpn_loc: 0.01363  time: 2.6187  data_time: 0.0322  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:19:46 d2.utils.events]: \u001b[0m eta: 2:10:04  iter: 7739  total_loss: 0.1482  loss_cls: 0.06964  loss_box_reg: 0.04918  loss_rpn_cls: 0.007099  loss_rpn_loc: 0.01275  time: 2.6184  data_time: 0.0261  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:20:39 d2.utils.events]: \u001b[0m eta: 2:09:17  iter: 7759  total_loss: 0.1792  loss_cls: 0.08753  loss_box_reg: 0.05913  loss_rpn_cls: 0.007205  loss_rpn_loc: 0.01689  time: 2.6185  data_time: 0.0286  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:21:30 d2.utils.events]: \u001b[0m eta: 2:08:26  iter: 7779  total_loss: 0.1632  loss_cls: 0.08673  loss_box_reg: 0.05635  loss_rpn_cls: 0.007771  loss_rpn_loc: 0.02151  time: 2.6184  data_time: 0.0247  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:22:23 d2.utils.events]: \u001b[0m eta: 2:07:36  iter: 7799  total_loss: 0.1916  loss_cls: 0.08705  loss_box_reg: 0.06286  loss_rpn_cls: 0.0078  loss_rpn_loc: 0.02322  time: 2.6184  data_time: 0.0288  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:23:16 d2.utils.events]: \u001b[0m eta: 2:06:44  iter: 7819  total_loss: 0.169  loss_cls: 0.07837  loss_box_reg: 0.05105  loss_rpn_cls: 0.009754  loss_rpn_loc: 0.02069  time: 2.6185  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:24:08 d2.utils.events]: \u001b[0m eta: 2:05:52  iter: 7839  total_loss: 0.1752  loss_cls: 0.07542  loss_box_reg: 0.05335  loss_rpn_cls: 0.009378  loss_rpn_loc: 0.01833  time: 2.6184  data_time: 0.0302  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:25:00 d2.utils.events]: \u001b[0m eta: 2:05:02  iter: 7859  total_loss: 0.163  loss_cls: 0.07823  loss_box_reg: 0.04766  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.01744  time: 2.6183  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:25:53 d2.utils.events]: \u001b[0m eta: 2:04:11  iter: 7879  total_loss: 0.1657  loss_cls: 0.07935  loss_box_reg: 0.0502  loss_rpn_cls: 0.009953  loss_rpn_loc: 0.01326  time: 2.6184  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:26:45 d2.utils.events]: \u001b[0m eta: 2:03:21  iter: 7899  total_loss: 0.1466  loss_cls: 0.06287  loss_box_reg: 0.04747  loss_rpn_cls: 0.006406  loss_rpn_loc: 0.01141  time: 2.6185  data_time: 0.0276  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:27:43 d2.utils.events]: \u001b[0m eta: 2:02:31  iter: 7919  total_loss: 0.2303  loss_cls: 0.09285  loss_box_reg: 0.07076  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.02515  time: 2.6192  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:28:33 d2.utils.events]: \u001b[0m eta: 2:01:40  iter: 7939  total_loss: 0.1788  loss_cls: 0.09694  loss_box_reg: 0.05066  loss_rpn_cls: 0.006443  loss_rpn_loc: 0.01823  time: 2.6188  data_time: 0.0268  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:29:24 d2.utils.events]: \u001b[0m eta: 2:00:42  iter: 7959  total_loss: 0.1544  loss_cls: 0.0721  loss_box_reg: 0.05105  loss_rpn_cls: 0.006888  loss_rpn_loc: 0.01139  time: 2.6186  data_time: 0.0264  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:30:15 d2.utils.events]: \u001b[0m eta: 1:59:46  iter: 7979  total_loss: 0.2021  loss_cls: 0.08811  loss_box_reg: 0.06044  loss_rpn_cls: 0.009221  loss_rpn_loc: 0.02186  time: 2.6184  data_time: 0.0278  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:31:09 d2.utils.events]: \u001b[0m eta: 1:58:54  iter: 7999  total_loss: 0.2287  loss_cls: 0.1163  loss_box_reg: 0.07655  loss_rpn_cls: 0.009919  loss_rpn_loc: 0.01932  time: 2.6186  data_time: 0.0303  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:32:02 d2.utils.events]: \u001b[0m eta: 1:57:55  iter: 8019  total_loss: 0.2315  loss_cls: 0.09392  loss_box_reg: 0.06516  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.02106  time: 2.6187  data_time: 0.0238  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:32:55 d2.utils.events]: \u001b[0m eta: 1:57:09  iter: 8039  total_loss: 0.1752  loss_cls: 0.07498  loss_box_reg: 0.0542  loss_rpn_cls: 0.008252  loss_rpn_loc: 0.0221  time: 2.6188  data_time: 0.0329  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:33:47 d2.utils.events]: \u001b[0m eta: 1:56:15  iter: 8059  total_loss: 0.1604  loss_cls: 0.08423  loss_box_reg: 0.06059  loss_rpn_cls: 0.005574  loss_rpn_loc: 0.01415  time: 2.6187  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:34:43 d2.utils.events]: \u001b[0m eta: 1:55:35  iter: 8079  total_loss: 0.1802  loss_cls: 0.08296  loss_box_reg: 0.05931  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.03372  time: 2.6193  data_time: 0.0296  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:35:33 d2.utils.events]: \u001b[0m eta: 1:54:35  iter: 8099  total_loss: 0.1826  loss_cls: 0.0825  loss_box_reg: 0.05183  loss_rpn_cls: 0.009973  loss_rpn_loc: 0.0224  time: 2.6189  data_time: 0.0284  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:36:25 d2.utils.events]: \u001b[0m eta: 1:53:48  iter: 8119  total_loss: 0.1606  loss_cls: 0.092  loss_box_reg: 0.06076  loss_rpn_cls: 0.006452  loss_rpn_loc: 0.0169  time: 2.6189  data_time: 0.0280  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:37:17 d2.utils.events]: \u001b[0m eta: 1:52:56  iter: 8139  total_loss: 0.1734  loss_cls: 0.08396  loss_box_reg: 0.0534  loss_rpn_cls: 0.006782  loss_rpn_loc: 0.01856  time: 2.6189  data_time: 0.0296  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:38:10 d2.utils.events]: \u001b[0m eta: 1:51:59  iter: 8159  total_loss: 0.1149  loss_cls: 0.06177  loss_box_reg: 0.03943  loss_rpn_cls: 0.006727  loss_rpn_loc: 0.01035  time: 2.6188  data_time: 0.0270  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:39:00 d2.utils.events]: \u001b[0m eta: 1:51:07  iter: 8179  total_loss: 0.1781  loss_cls: 0.09286  loss_box_reg: 0.06697  loss_rpn_cls: 0.004746  loss_rpn_loc: 0.02921  time: 2.6186  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:39:52 d2.utils.events]: \u001b[0m eta: 1:50:13  iter: 8199  total_loss: 0.1749  loss_cls: 0.08296  loss_box_reg: 0.05164  loss_rpn_cls: 0.006499  loss_rpn_loc: 0.01732  time: 2.6185  data_time: 0.0285  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:40:44 d2.utils.events]: \u001b[0m eta: 1:49:23  iter: 8219  total_loss: 0.2014  loss_cls: 0.1016  loss_box_reg: 0.0603  loss_rpn_cls: 0.006642  loss_rpn_loc: 0.01536  time: 2.6185  data_time: 0.0288  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:41:35 d2.utils.events]: \u001b[0m eta: 1:48:26  iter: 8239  total_loss: 0.1686  loss_cls: 0.08765  loss_box_reg: 0.05435  loss_rpn_cls: 0.009001  loss_rpn_loc: 0.01691  time: 2.6183  data_time: 0.0242  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:42:24 d2.utils.events]: \u001b[0m eta: 1:47:29  iter: 8259  total_loss: 0.1833  loss_cls: 0.09218  loss_box_reg: 0.06602  loss_rpn_cls: 0.00634  loss_rpn_loc: 0.01382  time: 2.6179  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:43:19 d2.utils.events]: \u001b[0m eta: 1:46:43  iter: 8279  total_loss: 0.1523  loss_cls: 0.07816  loss_box_reg: 0.05731  loss_rpn_cls: 0.006621  loss_rpn_loc: 0.01923  time: 2.6182  data_time: 0.0303  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:44:11 d2.utils.events]: \u001b[0m eta: 1:45:52  iter: 8299  total_loss: 0.1641  loss_cls: 0.08769  loss_box_reg: 0.06047  loss_rpn_cls: 0.006515  loss_rpn_loc: 0.01663  time: 2.6182  data_time: 0.0564  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:45:05 d2.utils.events]: \u001b[0m eta: 1:45:01  iter: 8319  total_loss: 0.1971  loss_cls: 0.1026  loss_box_reg: 0.06409  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.01864  time: 2.6184  data_time: 0.0298  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:45:57 d2.utils.events]: \u001b[0m eta: 1:44:08  iter: 8339  total_loss: 0.1423  loss_cls: 0.06422  loss_box_reg: 0.04422  loss_rpn_cls: 0.008505  loss_rpn_loc: 0.01686  time: 2.6184  data_time: 0.0312  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:46:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 22:46:46 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 22:46:46 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 22:46:46 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 22:46:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 22:46:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 22:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1840 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/29 22:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2261 s / img. ETA=0:01:04\n",
      "\u001b[32m[04/29 22:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 50/310. 0.2235 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/29 22:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 64/310. 0.2159 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/29 22:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2118 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/29 22:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 94/310. 0.2075 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/29 22:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 110/310. 0.2028 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/29 22:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 127/310. 0.1996 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/29 22:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 152/310. 0.1962 s / img. ETA=0:00:46\n",
      "\u001b[32m[04/29 22:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 178/310. 0.1934 s / img. ETA=0:00:36\n",
      "\u001b[32m[04/29 22:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 202/310. 0.1924 s / img. ETA=0:00:29\n",
      "\u001b[32m[04/29 22:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 227/310. 0.1914 s / img. ETA=0:00:21\n",
      "\u001b[32m[04/29 22:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 244/310. 0.1905 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/29 22:47:57 d2.evaluation.evaluator]: \u001b[0mInference done 268/310. 0.1894 s / img. ETA=0:00:10\n",
      "\u001b[32m[04/29 22:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 294/310. 0.1891 s / img. ETA=0:00:04\n",
      "\u001b[32m[04/29 22:48:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:17.387456 (0.253729 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 22:48:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.190147 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 22:48:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 22:48:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 22:48:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.42 seconds.\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.656 | 23.040 | 18.095 | 2.360 | 15.932 | 18.915 |\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.955 | Carton          | 38.231 | Bottle cap     | 30.118 |\n",
      "| Can                   | 38.187 | Pop tab         | 8.146  | Cup            | 28.766 |\n",
      "| Plastic bag & wrapper | 28.920 | Styrofoam piece | 16.843 | Other plastic  | 6.167  |\n",
      "| Plastic container     | 31.762 | Paper           | 12.025 | Lid            | 17.298 |\n",
      "| Straw                 | 19.195 | Paper bag       | 20.198 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 53.423 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 21.584 |\n",
      "| Unlabeled litter      | 2.142  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 8.837  | Cigarette       | 15.562 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 22:48:06 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 22:48:06 d2.evaluation.testing]: \u001b[0mcopypaste: 15.6557,23.0397,18.0953,2.3604,15.9322,18.9153\n",
      "\u001b[32m[04/29 22:48:13 d2.utils.events]: \u001b[0m eta: 1:43:20  iter: 8359  total_loss: 0.1879  loss_cls: 0.08478  loss_box_reg: 0.05633  loss_rpn_cls: 0.00799  loss_rpn_loc: 0.02062  time: 2.6185  data_time: 0.0314  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:49:06 d2.utils.events]: \u001b[0m eta: 1:42:27  iter: 8379  total_loss: 0.1847  loss_cls: 0.1003  loss_box_reg: 0.0652  loss_rpn_cls: 0.005706  loss_rpn_loc: 0.01821  time: 2.6186  data_time: 0.0244  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:49:57 d2.utils.events]: \u001b[0m eta: 1:41:36  iter: 8399  total_loss: 0.1443  loss_cls: 0.07335  loss_box_reg: 0.05389  loss_rpn_cls: 0.005933  loss_rpn_loc: 0.01183  time: 2.6184  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:50:47 d2.utils.events]: \u001b[0m eta: 1:40:43  iter: 8419  total_loss: 0.1795  loss_cls: 0.0741  loss_box_reg: 0.05431  loss_rpn_cls: 0.008861  loss_rpn_loc: 0.02606  time: 2.6181  data_time: 0.0548  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:51:39 d2.utils.events]: \u001b[0m eta: 1:39:52  iter: 8439  total_loss: 0.1791  loss_cls: 0.09105  loss_box_reg: 0.05101  loss_rpn_cls: 0.009601  loss_rpn_loc: 0.02111  time: 2.6181  data_time: 0.0250  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:52:30 d2.utils.events]: \u001b[0m eta: 1:38:59  iter: 8459  total_loss: 0.1646  loss_cls: 0.08256  loss_box_reg: 0.05554  loss_rpn_cls: 0.008376  loss_rpn_loc: 0.01416  time: 2.6180  data_time: 0.0230  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:53:22 d2.utils.events]: \u001b[0m eta: 1:38:08  iter: 8479  total_loss: 0.1438  loss_cls: 0.07751  loss_box_reg: 0.04796  loss_rpn_cls: 0.006232  loss_rpn_loc: 0.01217  time: 2.6179  data_time: 0.0300  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:54:17 d2.utils.events]: \u001b[0m eta: 1:37:15  iter: 8499  total_loss: 0.209  loss_cls: 0.09397  loss_box_reg: 0.06985  loss_rpn_cls: 0.008297  loss_rpn_loc: 0.02327  time: 2.6182  data_time: 0.0257  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:55:11 d2.utils.events]: \u001b[0m eta: 1:36:24  iter: 8519  total_loss: 0.1509  loss_cls: 0.07858  loss_box_reg: 0.05766  loss_rpn_cls: 0.006812  loss_rpn_loc: 0.01167  time: 2.6183  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:56:02 d2.utils.events]: \u001b[0m eta: 1:35:30  iter: 8539  total_loss: 0.1832  loss_cls: 0.08878  loss_box_reg: 0.05648  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.03298  time: 2.6182  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:56:54 d2.utils.events]: \u001b[0m eta: 1:34:39  iter: 8559  total_loss: 0.1972  loss_cls: 0.09691  loss_box_reg: 0.07081  loss_rpn_cls: 0.009648  loss_rpn_loc: 0.01944  time: 2.6182  data_time: 0.0283  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:57:45 d2.utils.events]: \u001b[0m eta: 1:33:42  iter: 8579  total_loss: 0.219  loss_cls: 0.09201  loss_box_reg: 0.0621  loss_rpn_cls: 0.008351  loss_rpn_loc: 0.02383  time: 2.6180  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:58:37 d2.utils.events]: \u001b[0m eta: 1:32:52  iter: 8599  total_loss: 0.1842  loss_cls: 0.08419  loss_box_reg: 0.05672  loss_rpn_cls: 0.007706  loss_rpn_loc: 0.02746  time: 2.6180  data_time: 0.0592  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 22:59:33 d2.utils.events]: \u001b[0m eta: 1:32:00  iter: 8619  total_loss: 0.1508  loss_cls: 0.06674  loss_box_reg: 0.05201  loss_rpn_cls: 0.006145  loss_rpn_loc: 0.01405  time: 2.6183  data_time: 0.0294  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:00:26 d2.utils.events]: \u001b[0m eta: 1:31:10  iter: 8639  total_loss: 0.1833  loss_cls: 0.09991  loss_box_reg: 0.0579  loss_rpn_cls: 0.005775  loss_rpn_loc: 0.0132  time: 2.6184  data_time: 0.0277  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:01:19 d2.utils.events]: \u001b[0m eta: 1:30:19  iter: 8659  total_loss: 0.1726  loss_cls: 0.08108  loss_box_reg: 0.05665  loss_rpn_cls: 0.004504  loss_rpn_loc: 0.01252  time: 2.6185  data_time: 0.0298  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:02:11 d2.utils.events]: \u001b[0m eta: 1:29:27  iter: 8679  total_loss: 0.2143  loss_cls: 0.09696  loss_box_reg: 0.07008  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.02512  time: 2.6185  data_time: 0.0260  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:03:04 d2.utils.events]: \u001b[0m eta: 1:28:32  iter: 8699  total_loss: 0.1679  loss_cls: 0.06486  loss_box_reg: 0.05377  loss_rpn_cls: 0.007088  loss_rpn_loc: 0.02028  time: 2.6185  data_time: 0.0328  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:03:56 d2.utils.events]: \u001b[0m eta: 1:27:39  iter: 8719  total_loss: 0.1507  loss_cls: 0.07879  loss_box_reg: 0.05133  loss_rpn_cls: 0.009444  loss_rpn_loc: 0.01576  time: 2.6185  data_time: 0.0291  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:04:47 d2.utils.events]: \u001b[0m eta: 1:26:47  iter: 8739  total_loss: 0.1869  loss_cls: 0.07536  loss_box_reg: 0.06746  loss_rpn_cls: 0.008451  loss_rpn_loc: 0.01744  time: 2.6183  data_time: 0.0312  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:05:39 d2.utils.events]: \u001b[0m eta: 1:25:53  iter: 8759  total_loss: 0.1687  loss_cls: 0.06967  loss_box_reg: 0.05642  loss_rpn_cls: 0.005176  loss_rpn_loc: 0.01347  time: 2.6183  data_time: 0.0329  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:06:32 d2.utils.events]: \u001b[0m eta: 1:25:01  iter: 8779  total_loss: 0.167  loss_cls: 0.07556  loss_box_reg: 0.04834  loss_rpn_cls: 0.008027  loss_rpn_loc: 0.01653  time: 2.6184  data_time: 0.0256  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:07:26 d2.utils.events]: \u001b[0m eta: 1:24:09  iter: 8799  total_loss: 0.2623  loss_cls: 0.119  loss_box_reg: 0.07673  loss_rpn_cls: 0.007535  loss_rpn_loc: 0.02123  time: 2.6186  data_time: 0.0300  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:08:18 d2.utils.events]: \u001b[0m eta: 1:23:17  iter: 8819  total_loss: 0.1717  loss_cls: 0.08092  loss_box_reg: 0.05259  loss_rpn_cls: 0.004975  loss_rpn_loc: 0.01373  time: 2.6185  data_time: 0.0309  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:09:12 d2.utils.events]: \u001b[0m eta: 1:22:27  iter: 8839  total_loss: 0.2391  loss_cls: 0.1122  loss_box_reg: 0.07707  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.02159  time: 2.6187  data_time: 0.0340  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:10:02 d2.utils.events]: \u001b[0m eta: 1:21:34  iter: 8859  total_loss: 0.1382  loss_cls: 0.07284  loss_box_reg: 0.05384  loss_rpn_cls: 0.005454  loss_rpn_loc: 0.01132  time: 2.6184  data_time: 0.0278  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:10:53 d2.utils.events]: \u001b[0m eta: 1:20:41  iter: 8879  total_loss: 0.1548  loss_cls: 0.07163  loss_box_reg: 0.05124  loss_rpn_cls: 0.005864  loss_rpn_loc: 0.01367  time: 2.6182  data_time: 0.0294  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:11:46 d2.utils.events]: \u001b[0m eta: 1:19:49  iter: 8899  total_loss: 0.2258  loss_cls: 0.1048  loss_box_reg: 0.07011  loss_rpn_cls: 0.009867  loss_rpn_loc: 0.02291  time: 2.6183  data_time: 0.0317  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:12:36 d2.utils.events]: \u001b[0m eta: 1:18:55  iter: 8919  total_loss: 0.186  loss_cls: 0.08361  loss_box_reg: 0.0665  loss_rpn_cls: 0.009445  loss_rpn_loc: 0.01853  time: 2.6180  data_time: 0.0301  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:13:28 d2.utils.events]: \u001b[0m eta: 1:18:04  iter: 8939  total_loss: 0.1979  loss_cls: 0.09228  loss_box_reg: 0.0628  loss_rpn_cls: 0.007105  loss_rpn_loc: 0.01583  time: 2.6181  data_time: 0.0268  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:14:22 d2.utils.events]: \u001b[0m eta: 1:17:14  iter: 8959  total_loss: 0.1786  loss_cls: 0.08416  loss_box_reg: 0.06243  loss_rpn_cls: 0.009322  loss_rpn_loc: 0.01701  time: 2.6182  data_time: 0.0525  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:15:13 d2.utils.events]: \u001b[0m eta: 1:16:22  iter: 8979  total_loss: 0.1697  loss_cls: 0.07088  loss_box_reg: 0.05212  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.02423  time: 2.6180  data_time: 0.0311  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:16:06 d2.utils.events]: \u001b[0m eta: 1:15:30  iter: 8999  total_loss: 0.181  loss_cls: 0.08477  loss_box_reg: 0.06504  loss_rpn_cls: 0.007304  loss_rpn_loc: 0.0151  time: 2.6180  data_time: 0.0279  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:17:00 d2.utils.events]: \u001b[0m eta: 1:14:38  iter: 9019  total_loss: 0.206  loss_cls: 0.09323  loss_box_reg: 0.06338  loss_rpn_cls: 0.008914  loss_rpn_loc: 0.03162  time: 2.6182  data_time: 0.0290  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:17:53 d2.utils.events]: \u001b[0m eta: 1:13:47  iter: 9039  total_loss: 0.1575  loss_cls: 0.07832  loss_box_reg: 0.05205  loss_rpn_cls: 0.009312  loss_rpn_loc: 0.01648  time: 2.6183  data_time: 0.0272  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:18:47 d2.utils.events]: \u001b[0m eta: 1:12:54  iter: 9059  total_loss: 0.1751  loss_cls: 0.08519  loss_box_reg: 0.05972  loss_rpn_cls: 0.008266  loss_rpn_loc: 0.02533  time: 2.6185  data_time: 0.0313  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:19:40 d2.utils.events]: \u001b[0m eta: 1:12:01  iter: 9079  total_loss: 0.1745  loss_cls: 0.07231  loss_box_reg: 0.05216  loss_rpn_cls: 0.008434  loss_rpn_loc: 0.01831  time: 2.6185  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:20:34 d2.utils.events]: \u001b[0m eta: 1:11:10  iter: 9099  total_loss: 0.1686  loss_cls: 0.08028  loss_box_reg: 0.05954  loss_rpn_cls: 0.006604  loss_rpn_loc: 0.01618  time: 2.6188  data_time: 0.0251  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:21:24 d2.utils.events]: \u001b[0m eta: 1:10:18  iter: 9119  total_loss: 0.265  loss_cls: 0.1113  loss_box_reg: 0.08146  loss_rpn_cls: 0.00949  loss_rpn_loc: 0.03142  time: 2.6185  data_time: 0.0291  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:22:15 d2.utils.events]: \u001b[0m eta: 1:09:23  iter: 9139  total_loss: 0.2116  loss_cls: 0.1012  loss_box_reg: 0.05855  loss_rpn_cls: 0.006906  loss_rpn_loc: 0.01952  time: 2.6184  data_time: 0.0289  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:23:06 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 9159  total_loss: 0.1963  loss_cls: 0.09297  loss_box_reg: 0.06743  loss_rpn_cls: 0.008523  loss_rpn_loc: 0.01627  time: 2.6181  data_time: 0.0324  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:24:00 d2.utils.events]: \u001b[0m eta: 1:07:39  iter: 9179  total_loss: 0.131  loss_cls: 0.0683  loss_box_reg: 0.0449  loss_rpn_cls: 0.006364  loss_rpn_loc: 0.01214  time: 2.6183  data_time: 0.0273  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:24:53 d2.utils.events]: \u001b[0m eta: 1:06:47  iter: 9199  total_loss: 0.204  loss_cls: 0.09605  loss_box_reg: 0.0592  loss_rpn_cls: 0.006087  loss_rpn_loc: 0.02015  time: 2.6184  data_time: 0.0297  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:25:44 d2.utils.events]: \u001b[0m eta: 1:05:55  iter: 9219  total_loss: 0.1829  loss_cls: 0.08661  loss_box_reg: 0.05898  loss_rpn_cls: 0.003747  loss_rpn_loc: 0.01322  time: 2.6182  data_time: 0.0304  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:26:36 d2.utils.events]: \u001b[0m eta: 1:05:06  iter: 9239  total_loss: 0.1742  loss_cls: 0.07748  loss_box_reg: 0.05473  loss_rpn_cls: 0.007061  loss_rpn_loc: 0.02235  time: 2.6182  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:27:27 d2.utils.events]: \u001b[0m eta: 1:04:15  iter: 9259  total_loss: 0.196  loss_cls: 0.07714  loss_box_reg: 0.0606  loss_rpn_cls: 0.006076  loss_rpn_loc: 0.01833  time: 2.6181  data_time: 0.0293  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:28:20 d2.utils.events]: \u001b[0m eta: 1:03:21  iter: 9279  total_loss: 0.156  loss_cls: 0.08447  loss_box_reg: 0.05378  loss_rpn_cls: 0.004902  loss_rpn_loc: 0.01967  time: 2.6182  data_time: 0.0274  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:29:14 d2.utils.events]: \u001b[0m eta: 1:02:29  iter: 9299  total_loss: 0.1644  loss_cls: 0.07369  loss_box_reg: 0.0505  loss_rpn_cls: 0.006091  loss_rpn_loc: 0.0178  time: 2.6183  data_time: 0.0285  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:30:07 d2.utils.events]: \u001b[0m eta: 1:01:37  iter: 9319  total_loss: 0.1797  loss_cls: 0.07819  loss_box_reg: 0.05575  loss_rpn_cls: 0.00811  loss_rpn_loc: 0.0131  time: 2.6184  data_time: 0.0326  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:30:59 d2.utils.events]: \u001b[0m eta: 1:00:47  iter: 9339  total_loss: 0.1913  loss_cls: 0.08007  loss_box_reg: 0.05796  loss_rpn_cls: 0.007458  loss_rpn_loc: 0.02495  time: 2.6183  data_time: 0.0263  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:31:53 d2.utils.events]: \u001b[0m eta: 0:59:55  iter: 9359  total_loss: 0.1781  loss_cls: 0.08085  loss_box_reg: 0.06081  loss_rpn_cls: 0.007532  loss_rpn_loc: 0.01305  time: 2.6185  data_time: 0.0271  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:32:46 d2.utils.events]: \u001b[0m eta: 0:59:02  iter: 9379  total_loss: 0.1989  loss_cls: 0.09131  loss_box_reg: 0.06911  loss_rpn_cls: 0.005541  loss_rpn_loc: 0.01961  time: 2.6185  data_time: 0.0292  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:33:44 d2.utils.events]: \u001b[0m eta: 0:58:13  iter: 9399  total_loss: 0.1595  loss_cls: 0.07807  loss_box_reg: 0.05526  loss_rpn_cls: 0.007025  loss_rpn_loc: 0.01616  time: 2.6192  data_time: 0.0270  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:34:37 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 9419  total_loss: 0.2327  loss_cls: 0.1018  loss_box_reg: 0.07832  loss_rpn_cls: 0.008251  loss_rpn_loc: 0.02119  time: 2.6193  data_time: 0.0261  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:35:32 d2.utils.events]: \u001b[0m eta: 0:56:30  iter: 9439  total_loss: 0.177  loss_cls: 0.08006  loss_box_reg: 0.06579  loss_rpn_cls: 0.00499  loss_rpn_loc: 0.02018  time: 2.6195  data_time: 0.0268  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:36:24 d2.utils.events]: \u001b[0m eta: 0:55:39  iter: 9459  total_loss: 0.2097  loss_cls: 0.1007  loss_box_reg: 0.06785  loss_rpn_cls: 0.008806  loss_rpn_loc: 0.02216  time: 2.6195  data_time: 0.0265  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:37:16 d2.utils.events]: \u001b[0m eta: 0:54:47  iter: 9479  total_loss: 0.1881  loss_cls: 0.0835  loss_box_reg: 0.05224  loss_rpn_cls: 0.007819  loss_rpn_loc: 0.02318  time: 2.6195  data_time: 0.0277  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:38:10 d2.utils.events]: \u001b[0m eta: 0:53:55  iter: 9499  total_loss: 0.1936  loss_cls: 0.0864  loss_box_reg: 0.05898  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.02421  time: 2.6196  data_time: 0.0309  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:39:02 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 9519  total_loss: 0.1627  loss_cls: 0.07287  loss_box_reg: 0.04377  loss_rpn_cls: 0.007619  loss_rpn_loc: 0.02259  time: 2.6196  data_time: 0.0282  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:39:55 d2.utils.events]: \u001b[0m eta: 0:52:12  iter: 9539  total_loss: 0.1424  loss_cls: 0.06088  loss_box_reg: 0.04715  loss_rpn_cls: 0.004061  loss_rpn_loc: 0.02068  time: 2.6197  data_time: 0.0267  lr: 0.001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:40:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/29 23:40:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/29 23:40:27 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/29 23:40:27 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/29 23:40:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/29 23:40:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/29 23:40:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1802 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/29 23:40:35 d2.evaluation.evaluator]: \u001b[0mInference done 31/310. 0.2288 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/29 23:40:40 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2314 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/29 23:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2210 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/29 23:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 74/310. 0.2174 s / img. ETA=0:01:14\n",
      "\u001b[32m[04/29 23:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 93/310. 0.2096 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/29 23:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 109/310. 0.2041 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/29 23:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 127/310. 0.1997 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/29 23:41:11 d2.evaluation.evaluator]: \u001b[0mInference done 149/310. 0.1969 s / img. ETA=0:00:47\n",
      "\u001b[32m[04/29 23:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 173/310. 0.1955 s / img. ETA=0:00:38\n",
      "\u001b[32m[04/29 23:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 197/310. 0.1933 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/29 23:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 222/310. 0.1912 s / img. ETA=0:00:23\n",
      "\u001b[32m[04/29 23:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 244/310. 0.1907 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/29 23:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 267/310. 0.1899 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/29 23:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 291/310. 0.1893 s / img. ETA=0:00:04\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:17.735517 (0.254871 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.190866 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.943 | 23.452 | 17.186 | 3.721 | 17.354 | 17.485 |\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 37.651 | Carton          | 31.458 | Bottle cap     | 30.823 |\n",
      "| Can                   | 32.103 | Pop tab         | 8.345  | Cup            | 27.181 |\n",
      "| Plastic bag & wrapper | 29.878 | Styrofoam piece | 16.070 | Other plastic  | 5.190  |\n",
      "| Plastic container     | 27.869 | Paper           | 12.535 | Lid            | 15.552 |\n",
      "| Straw                 | 25.694 | Paper bag       | 24.125 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 53.638 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 15.644 |\n",
      "| Unlabeled litter      | 1.794  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 7.574  | Cigarette       | 15.268 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/29 23:41:47 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/29 23:41:47 d2.evaluation.testing]: \u001b[0mcopypaste: 14.9427,23.4518,17.1862,3.7211,17.3543,17.4852\n",
      "\u001b[32m[04/29 23:42:09 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 9559  total_loss: 0.1641  loss_cls: 0.07899  loss_box_reg: 0.05365  loss_rpn_cls: 0.007335  loss_rpn_loc: 0.01889  time: 2.6195  data_time: 0.0297  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:42:59 d2.utils.events]: \u001b[0m eta: 0:50:27  iter: 9579  total_loss: 0.1542  loss_cls: 0.06996  loss_box_reg: 0.04202  loss_rpn_cls: 0.005187  loss_rpn_loc: 0.02169  time: 2.6193  data_time: 0.0294  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:43:52 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 9599  total_loss: 0.2213  loss_cls: 0.1099  loss_box_reg: 0.08253  loss_rpn_cls: 0.006402  loss_rpn_loc: 0.01745  time: 2.6194  data_time: 0.0316  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:44:46 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 9619  total_loss: 0.2231  loss_cls: 0.09941  loss_box_reg: 0.07971  loss_rpn_cls: 0.006962  loss_rpn_loc: 0.02007  time: 2.6195  data_time: 0.0301  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:45:38 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 9639  total_loss: 0.1505  loss_cls: 0.07413  loss_box_reg: 0.05089  loss_rpn_cls: 0.006354  loss_rpn_loc: 0.01562  time: 2.6195  data_time: 0.0310  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:46:28 d2.utils.events]: \u001b[0m eta: 0:46:58  iter: 9659  total_loss: 0.1511  loss_cls: 0.07878  loss_box_reg: 0.05435  loss_rpn_cls: 0.006621  loss_rpn_loc: 0.01452  time: 2.6192  data_time: 0.0294  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:47:20 d2.utils.events]: \u001b[0m eta: 0:46:05  iter: 9679  total_loss: 0.1642  loss_cls: 0.0886  loss_box_reg: 0.0597  loss_rpn_cls: 0.004323  loss_rpn_loc: 0.0166  time: 2.6192  data_time: 0.0287  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:48:12 d2.utils.events]: \u001b[0m eta: 0:45:15  iter: 9699  total_loss: 0.151  loss_cls: 0.07412  loss_box_reg: 0.05496  loss_rpn_cls: 0.005688  loss_rpn_loc: 0.01224  time: 2.6192  data_time: 0.0320  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:49:05 d2.utils.events]: \u001b[0m eta: 0:44:23  iter: 9719  total_loss: 0.168  loss_cls: 0.07846  loss_box_reg: 0.05852  loss_rpn_cls: 0.003116  loss_rpn_loc: 0.02046  time: 2.6192  data_time: 0.0290  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:49:58 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 9739  total_loss: 0.1437  loss_cls: 0.07473  loss_box_reg: 0.05248  loss_rpn_cls: 0.005697  loss_rpn_loc: 0.01878  time: 2.6193  data_time: 0.0271  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:50:50 d2.utils.events]: \u001b[0m eta: 0:42:42  iter: 9759  total_loss: 0.1754  loss_cls: 0.07269  loss_box_reg: 0.04712  loss_rpn_cls: 0.005907  loss_rpn_loc: 0.03948  time: 2.6193  data_time: 0.0234  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:51:44 d2.utils.events]: \u001b[0m eta: 0:41:48  iter: 9779  total_loss: 0.1308  loss_cls: 0.06693  loss_box_reg: 0.04902  loss_rpn_cls: 0.004146  loss_rpn_loc: 0.01388  time: 2.6194  data_time: 0.0270  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:52:39 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 9799  total_loss: 0.2246  loss_cls: 0.1155  loss_box_reg: 0.07548  loss_rpn_cls: 0.007149  loss_rpn_loc: 0.02908  time: 2.6197  data_time: 0.0270  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:53:31 d2.utils.events]: \u001b[0m eta: 0:40:04  iter: 9819  total_loss: 0.1859  loss_cls: 0.09601  loss_box_reg: 0.06799  loss_rpn_cls: 0.008468  loss_rpn_loc: 0.01391  time: 2.6196  data_time: 0.0699  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:54:25 d2.utils.events]: \u001b[0m eta: 0:39:12  iter: 9839  total_loss: 0.2369  loss_cls: 0.1213  loss_box_reg: 0.07877  loss_rpn_cls: 0.007118  loss_rpn_loc: 0.02115  time: 2.6198  data_time: 0.0314  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:55:17 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 9859  total_loss: 0.1702  loss_cls: 0.0834  loss_box_reg: 0.05329  loss_rpn_cls: 0.008273  loss_rpn_loc: 0.0114  time: 2.6198  data_time: 0.0262  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:56:10 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 9879  total_loss: 0.1474  loss_cls: 0.06651  loss_box_reg: 0.04801  loss_rpn_cls: 0.002822  loss_rpn_loc: 0.01835  time: 2.6198  data_time: 0.0259  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:57:04 d2.utils.events]: \u001b[0m eta: 0:36:38  iter: 9899  total_loss: 0.2005  loss_cls: 0.08699  loss_box_reg: 0.06313  loss_rpn_cls: 0.007374  loss_rpn_loc: 0.03152  time: 2.6200  data_time: 0.0317  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:57:56 d2.utils.events]: \u001b[0m eta: 0:35:47  iter: 9919  total_loss: 0.2152  loss_cls: 0.1169  loss_box_reg: 0.06344  loss_rpn_cls: 0.00448  loss_rpn_loc: 0.01699  time: 2.6200  data_time: 0.0283  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:58:50 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 9939  total_loss: 0.1712  loss_cls: 0.07895  loss_box_reg: 0.0567  loss_rpn_cls: 0.005123  loss_rpn_loc: 0.01317  time: 2.6201  data_time: 0.0495  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/29 23:59:46 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 9959  total_loss: 0.2135  loss_cls: 0.0956  loss_box_reg: 0.07313  loss_rpn_cls: 0.006874  loss_rpn_loc: 0.02324  time: 2.6204  data_time: 0.0305  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:00:37 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 9979  total_loss: 0.1461  loss_cls: 0.07441  loss_box_reg: 0.04625  loss_rpn_cls: 0.006333  loss_rpn_loc: 0.01279  time: 2.6203  data_time: 0.0301  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:01:30 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 9999  total_loss: 0.1533  loss_cls: 0.07045  loss_box_reg: 0.04818  loss_rpn_cls: 0.006464  loss_rpn_loc: 0.02284  time: 2.6203  data_time: 0.0932  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:02:23 d2.utils.events]: \u001b[0m eta: 0:31:27  iter: 10019  total_loss: 0.1533  loss_cls: 0.08049  loss_box_reg: 0.04865  loss_rpn_cls: 0.005484  loss_rpn_loc: 0.01136  time: 2.6203  data_time: 0.0288  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:03:15 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 10039  total_loss: 0.2185  loss_cls: 0.1005  loss_box_reg: 0.07427  loss_rpn_cls: 0.007289  loss_rpn_loc: 0.02481  time: 2.6203  data_time: 0.0674  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:04:08 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 10059  total_loss: 0.1309  loss_cls: 0.06744  loss_box_reg: 0.05129  loss_rpn_cls: 0.005852  loss_rpn_loc: 0.01376  time: 2.6203  data_time: 0.0274  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:04:57 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 10079  total_loss: 0.1908  loss_cls: 0.08941  loss_box_reg: 0.06996  loss_rpn_cls: 0.00785  loss_rpn_loc: 0.02429  time: 2.6200  data_time: 0.0247  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:05:53 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 10099  total_loss: 0.1458  loss_cls: 0.06835  loss_box_reg: 0.05084  loss_rpn_cls: 0.005895  loss_rpn_loc: 0.01168  time: 2.6204  data_time: 0.0315  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:06:44 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 10119  total_loss: 0.1555  loss_cls: 0.08378  loss_box_reg: 0.05954  loss_rpn_cls: 0.006838  loss_rpn_loc: 0.02052  time: 2.6202  data_time: 0.0273  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:07:35 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 10139  total_loss: 0.1632  loss_cls: 0.07186  loss_box_reg: 0.045  loss_rpn_cls: 0.005835  loss_rpn_loc: 0.01812  time: 2.6200  data_time: 0.0250  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:08:26 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 10159  total_loss: 0.1458  loss_cls: 0.06338  loss_box_reg: 0.05279  loss_rpn_cls: 0.005709  loss_rpn_loc: 0.01333  time: 2.6199  data_time: 0.0364  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:09:16 d2.utils.events]: \u001b[0m eta: 0:24:31  iter: 10179  total_loss: 0.1897  loss_cls: 0.0899  loss_box_reg: 0.06307  loss_rpn_cls: 0.005854  loss_rpn_loc: 0.02206  time: 2.6197  data_time: 0.0261  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:10:07 d2.utils.events]: \u001b[0m eta: 0:23:39  iter: 10199  total_loss: 0.1264  loss_cls: 0.05904  loss_box_reg: 0.0427  loss_rpn_cls: 0.006274  loss_rpn_loc: 0.01448  time: 2.6195  data_time: 0.0436  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:10:59 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 10219  total_loss: 0.2133  loss_cls: 0.08021  loss_box_reg: 0.07712  loss_rpn_cls: 0.005788  loss_rpn_loc: 0.04716  time: 2.6195  data_time: 0.0457  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:11:50 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 10239  total_loss: 0.1476  loss_cls: 0.06878  loss_box_reg: 0.04535  loss_rpn_cls: 0.004546  loss_rpn_loc: 0.0119  time: 2.6194  data_time: 0.0413  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:12:45 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 10259  total_loss: 0.1518  loss_cls: 0.06676  loss_box_reg: 0.05329  loss_rpn_cls: 0.005061  loss_rpn_loc: 0.01759  time: 2.6196  data_time: 0.0285  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:13:37 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 10279  total_loss: 0.1599  loss_cls: 0.07441  loss_box_reg: 0.0566  loss_rpn_cls: 0.005311  loss_rpn_loc: 0.01683  time: 2.6196  data_time: 0.0239  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:14:31 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 10299  total_loss: 0.1668  loss_cls: 0.07478  loss_box_reg: 0.05667  loss_rpn_cls: 0.005361  loss_rpn_loc: 0.01731  time: 2.6197  data_time: 0.0297  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:15:23 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 10319  total_loss: 0.1572  loss_cls: 0.06877  loss_box_reg: 0.05229  loss_rpn_cls: 0.006283  loss_rpn_loc: 0.01814  time: 2.6197  data_time: 0.0256  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:16:18 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 10339  total_loss: 0.156  loss_cls: 0.07582  loss_box_reg: 0.05511  loss_rpn_cls: 0.005341  loss_rpn_loc: 0.01292  time: 2.6200  data_time: 0.0295  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:17:10 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 10359  total_loss: 0.1822  loss_cls: 0.07616  loss_box_reg: 0.0589  loss_rpn_cls: 0.009012  loss_rpn_loc: 0.02752  time: 2.6199  data_time: 0.0289  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:18:01 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 10379  total_loss: 0.1632  loss_cls: 0.0772  loss_box_reg: 0.05524  loss_rpn_cls: 0.008179  loss_rpn_loc: 0.01777  time: 2.6198  data_time: 0.0313  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:18:52 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 10399  total_loss: 0.2348  loss_cls: 0.08877  loss_box_reg: 0.05869  loss_rpn_cls: 0.008697  loss_rpn_loc: 0.02754  time: 2.6196  data_time: 0.0550  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:19:43 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 10419  total_loss: 0.1573  loss_cls: 0.07144  loss_box_reg: 0.04821  loss_rpn_cls: 0.005017  loss_rpn_loc: 0.01422  time: 2.6196  data_time: 0.0263  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:20:34 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 10439  total_loss: 0.1953  loss_cls: 0.09287  loss_box_reg: 0.06927  loss_rpn_cls: 0.00738  loss_rpn_loc: 0.02281  time: 2.6194  data_time: 0.0678  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:21:27 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 10459  total_loss: 0.1517  loss_cls: 0.07591  loss_box_reg: 0.05622  loss_rpn_cls: 0.005326  loss_rpn_loc: 0.01175  time: 2.6194  data_time: 0.0291  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:22:19 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 10479  total_loss: 0.163  loss_cls: 0.07628  loss_box_reg: 0.04988  loss_rpn_cls: 0.005033  loss_rpn_loc: 0.01532  time: 2.6193  data_time: 0.0265  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:23:11 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 10499  total_loss: 0.1819  loss_cls: 0.0881  loss_box_reg: 0.06287  loss_rpn_cls: 0.006674  loss_rpn_loc: 0.01667  time: 2.6193  data_time: 0.0272  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:24:05 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 10519  total_loss: 0.1618  loss_cls: 0.07402  loss_box_reg: 0.06366  loss_rpn_cls: 0.003384  loss_rpn_loc: 0.01811  time: 2.6195  data_time: 0.0256  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:24:55 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 10539  total_loss: 0.1479  loss_cls: 0.06323  loss_box_reg: 0.0531  loss_rpn_cls: 0.008032  loss_rpn_loc: 0.0172  time: 2.6193  data_time: 0.0737  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:25:48 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 10559  total_loss: 0.1701  loss_cls: 0.07167  loss_box_reg: 0.05958  loss_rpn_cls: 0.008028  loss_rpn_loc: 0.01595  time: 2.6193  data_time: 0.0265  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:26:37 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 10579  total_loss: 0.1594  loss_cls: 0.07163  loss_box_reg: 0.05515  loss_rpn_cls: 0.005913  loss_rpn_loc: 0.01687  time: 2.6190  data_time: 0.0257  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:27:28 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 10599  total_loss: 0.1764  loss_cls: 0.08873  loss_box_reg: 0.06702  loss_rpn_cls: 0.006714  loss_rpn_loc: 0.01678  time: 2.6189  data_time: 0.0257  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:28:22 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 10619  total_loss: 0.1371  loss_cls: 0.06828  loss_box_reg: 0.04931  loss_rpn_cls: 0.005744  loss_rpn_loc: 0.01047  time: 2.6190  data_time: 0.0273  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:29:13 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 10639  total_loss: 0.1736  loss_cls: 0.07952  loss_box_reg: 0.06096  loss_rpn_cls: 0.005296  loss_rpn_loc: 0.02579  time: 2.6189  data_time: 0.0354  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:30:08 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 10659  total_loss: 0.1546  loss_cls: 0.06131  loss_box_reg: 0.04943  loss_rpn_cls: 0.005365  loss_rpn_loc: 0.02258  time: 2.6191  data_time: 0.0750  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:31:02 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 10679  total_loss: 0.1653  loss_cls: 0.07638  loss_box_reg: 0.05605  loss_rpn_cls: 0.005583  loss_rpn_loc: 0.01873  time: 2.6193  data_time: 0.0314  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:31:55 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 10699  total_loss: 0.1521  loss_cls: 0.06428  loss_box_reg: 0.05197  loss_rpn_cls: 0.00632  loss_rpn_loc: 0.01665  time: 2.6194  data_time: 0.0311  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:32:46 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 10719  total_loss: 0.1642  loss_cls: 0.08859  loss_box_reg: 0.05888  loss_rpn_cls: 0.006131  loss_rpn_loc: 0.01519  time: 2.6193  data_time: 0.0282  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:33:38 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 10739  total_loss: 0.1947  loss_cls: 0.09186  loss_box_reg: 0.06515  loss_rpn_cls: 0.008215  loss_rpn_loc: 0.02233  time: 2.6192  data_time: 0.0271  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:33:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 00:33:56 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 00:33:56 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 00:33:56 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 00:33:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 00:33:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 00:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1836 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/30 00:34:04 d2.evaluation.evaluator]: \u001b[0mInference done 30/310. 0.2277 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/30 00:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2301 s / img. ETA=0:01:13\n",
      "\u001b[32m[04/30 00:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2182 s / img. ETA=0:01:13\n",
      "\u001b[32m[04/30 00:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 74/310. 0.2142 s / img. ETA=0:01:17\n",
      "\u001b[32m[04/30 00:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 91/310. 0.2081 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/30 00:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 107/310. 0.2037 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 00:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 123/310. 0.2006 s / img. ETA=0:00:59\n",
      "\u001b[32m[04/30 00:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 148/310. 0.1973 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/30 00:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 172/310. 0.1941 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/30 00:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 195/310. 0.1930 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/30 00:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 218/310. 0.1921 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 00:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1910 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 00:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 265/310. 0.1903 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/30 00:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 289/310. 0.1892 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/30 00:35:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:18.324049 (0.256800 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:35:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.189814 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:35:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 00:35:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.245 | 25.450 | 18.516 | 2.953 | 16.750 | 19.000 |\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.976 | Carton          | 32.233 | Bottle cap     | 30.401 |\n",
      "| Can                   | 33.615 | Pop tab         | 9.522  | Cup            | 28.989 |\n",
      "| Plastic bag & wrapper | 31.628 | Styrofoam piece | 14.878 | Other plastic  | 6.108  |\n",
      "| Plastic container     | 24.313 | Paper           | 11.583 | Lid            | 17.667 |\n",
      "| Straw                 | 21.845 | Paper bag       | 27.772 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 58.007 | Glass jar       | 20.198 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 17.921 |\n",
      "| Unlabeled litter      | 2.735  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 9.498  | Cigarette       | 14.976 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 00:35:17 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 00:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: 16.2451,25.4496,18.5158,2.9525,16.7497,19.0001\n",
      "\u001b[32m[04/30 00:35:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 10745  total_loss: 0.1969  loss_cls: 0.09574  loss_box_reg: 0.06683  loss_rpn_cls: 0.008576  loss_rpn_loc: 0.03106  time: 2.6193  data_time: 0.0276  lr: 0.0001  max_mem: 9678M\n",
      "\u001b[32m[04/30 00:35:20 d2.engine.hooks]: \u001b[0mOverall training speed: 10744 iterations in 7:49:01 (2.6193 s / it)\n",
      "\u001b[32m[04/30 00:35:20 d2.engine.hooks]: \u001b[0mTotal training time: 8:01:42 (0:12:40 on hooks)\n",
      "\u001b[32m[04/30 00:35:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 00:35:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 00:35:20 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 00:35:20 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 00:35:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 00:35:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 00:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1870 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/30 00:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 30/310. 0.2312 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 00:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2326 s / img. ETA=0:01:11\n",
      "\u001b[32m[04/30 00:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2198 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/30 00:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 76/310. 0.2142 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/30 00:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 92/310. 0.2087 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/30 00:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 106/310. 0.2066 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 00:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 122/310. 0.2035 s / img. ETA=0:01:00\n",
      "\u001b[32m[04/30 00:36:05 d2.evaluation.evaluator]: \u001b[0mInference done 145/310. 0.1994 s / img. ETA=0:00:50\n",
      "\u001b[32m[04/30 00:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 170/310. 0.1963 s / img. ETA=0:00:40\n",
      "\u001b[32m[04/30 00:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 195/310. 0.1940 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/30 00:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 221/310. 0.1921 s / img. ETA=0:00:23\n",
      "\u001b[32m[04/30 00:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1911 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 00:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 263/310. 0.1908 s / img. ETA=0:00:12\n",
      "\u001b[32m[04/30 00:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 285/310. 0.1897 s / img. ETA=0:00:06\n",
      "\u001b[32m[04/30 00:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 308/310. 0.1905 s / img. ETA=0:00:00\n",
      "\u001b[32m[04/30 00:36:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:18.466303 (0.257267 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:36:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.190747 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:36:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 00:36:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 00:36:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.245 | 25.450 | 18.516 | 2.953 | 16.750 | 19.000 |\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.976 | Carton          | 32.233 | Bottle cap     | 30.401 |\n",
      "| Can                   | 33.615 | Pop tab         | 9.522  | Cup            | 28.989 |\n",
      "| Plastic bag & wrapper | 31.628 | Styrofoam piece | 14.878 | Other plastic  | 6.108  |\n",
      "| Plastic container     | 24.313 | Paper           | 11.583 | Lid            | 17.667 |\n",
      "| Straw                 | 21.845 | Paper bag       | 27.772 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 58.007 | Glass jar       | 20.198 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 17.921 |\n",
      "| Unlabeled litter      | 2.735  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 9.498  | Cigarette       | 14.976 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 00:36:42 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.testing]: \u001b[0mcopypaste: 16.2451,25.4496,18.5158,2.9525,16.7497,19.0001\n",
      "\u001b[32m[04/30 00:36:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 00:36:42 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 00:36:42 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 00:36:42 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 00:36:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 00:36:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 00:36:46 d2.evaluation.evaluator]: \u001b[0mInference done 13/310. 0.1852 s / img. ETA=0:01:00\n",
      "\u001b[32m[04/30 00:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 33/310. 0.2287 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/30 00:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 50/310. 0.2223 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 00:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2163 s / img. ETA=0:01:15\n",
      "\u001b[32m[04/30 00:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 74/310. 0.2144 s / img. ETA=0:01:16\n",
      "\u001b[32m[04/30 00:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 92/310. 0.2076 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 00:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 106/310. 0.2042 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 00:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 122/310. 0.2002 s / img. ETA=0:01:00\n",
      "\u001b[32m[04/30 00:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 148/310. 0.1956 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/30 00:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 169/310. 0.1948 s / img. ETA=0:00:41\n",
      "\u001b[32m[04/30 00:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 194/310. 0.1924 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/30 00:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 218/310. 0.1909 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 00:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 242/310. 0.1896 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 00:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 264/310. 0.1894 s / img. ETA=0:00:12\n",
      "\u001b[32m[04/30 00:37:58 d2.evaluation.evaluator]: \u001b[0mInference done 286/310. 0.1887 s / img. ETA=0:00:06\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 310/310. 0.1897 s / img. ETA=0:00:00\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:18.781244 (0.258299 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.189654 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.245 | 25.450 | 18.516 | 2.953 | 16.750 | 19.000 |\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.976 | Carton          | 32.233 | Bottle cap     | 30.401 |\n",
      "| Can                   | 33.615 | Pop tab         | 9.522  | Cup            | 28.989 |\n",
      "| Plastic bag & wrapper | 31.628 | Styrofoam piece | 14.878 | Other plastic  | 6.108  |\n",
      "| Plastic container     | 24.313 | Paper           | 11.583 | Lid            | 17.667 |\n",
      "| Straw                 | 21.845 | Paper bag       | 27.772 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 58.007 | Glass jar       | 20.198 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 17.921 |\n",
      "| Unlabeled litter      | 2.735  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 9.498  | Cigarette       | 14.976 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 00:38:03 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 00:38:03 d2.evaluation.testing]: \u001b[0mcopypaste: 16.2451,25.4496,18.5158,2.9525,16.7497,19.0001\n"
     ]
    }
   ],
   "source": [
    "train(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goIHpnTXED-y",
    "papermill": {
     "duration": 0.402082,
     "end_time": "2021-04-30T00:38:04.688704",
     "exception": false,
     "start_time": "2021-04-30T00:38:04.286622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:38:05.507122Z",
     "iopub.status.busy": "2021-04-30T00:38:05.504391Z",
     "iopub.status.idle": "2021-04-30T00:38:05.542971Z",
     "shell.execute_reply": "2021-04-30T00:38:05.542413Z"
    },
    "id": "9sWii-FSED-z",
    "papermill": {
     "duration": 0.44848,
     "end_time": "2021-04-30T00:38:05.543072",
     "exception": false,
     "start_time": "2021-04-30T00:38:05.094592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(CONFIG_PATH,\"detectron_config.yaml\"),\"w\") as f:\n",
    "    f.write(get_config().dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:38:06.372227Z",
     "iopub.status.busy": "2021-04-30T00:38:06.371459Z",
     "iopub.status.idle": "2021-04-30T00:38:07.039480Z",
     "shell.execute_reply": "2021-04-30T00:38:07.038561Z"
    },
    "id": "uhOMK3cOED-z",
    "outputId": "d59b43a2-356f-4c5f-fcaa-4868e516b450",
    "papermill": {
     "duration": 1.09089,
     "end_time": "2021-04-30T00:38:07.039588",
     "exception": false,
     "start_time": "2021-04-30T00:38:05.948698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1619713967.fe1403dc9858.17.0  experiment.yaml  metrics.json\r\n"
     ]
    }
   ],
   "source": [
    "%ls logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:38:07.876151Z",
     "iopub.status.busy": "2021-04-30T00:38:07.856464Z",
     "iopub.status.idle": "2021-04-30T00:38:08.518927Z",
     "shell.execute_reply": "2021-04-30T00:38:08.517998Z"
    },
    "id": "yjShC_zvED-z",
    "outputId": "6bc3e6d9-f081-46ad-955a-4ab47c79c8a4",
    "papermill": {
     "duration": 1.07161,
     "end_time": "2021-04-30T00:38:08.519038",
     "exception": false,
     "start_time": "2021-04-30T00:38:07.447428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.pth   model_0004999.pth  model_final.pth\r\n",
      "last_checkpoint  model_0009999.pth\r\n"
     ]
    }
   ],
   "source": [
    "%ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:38:09.342835Z",
     "iopub.status.busy": "2021-04-30T00:38:09.342060Z",
     "iopub.status.idle": "2021-04-30T00:38:09.998808Z",
     "shell.execute_reply": "2021-04-30T00:38:09.998323Z"
    },
    "id": "OK_zwp-2ED-0",
    "outputId": "4254b986-bc1e-4194-e172-bfe1d5ec7020",
    "papermill": {
     "duration": 1.072232,
     "end_time": "2021-04-30T00:38:09.998921",
     "exception": false,
     "start_time": "2021-04-30T00:38:08.926689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detectron_config.yaml\r\n"
     ]
    }
   ],
   "source": [
    "%ls configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F5_h9ZLED-1",
    "papermill": {
     "duration": 0.404627,
     "end_time": "2021-04-30T00:38:10.813723",
     "exception": false,
     "start_time": "2021-04-30T00:38:10.409096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Dataset (without validation augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:38:11.861339Z",
     "iopub.status.busy": "2021-04-30T00:38:11.859453Z",
     "iopub.status.idle": "2021-04-30T00:38:11.862017Z",
     "shell.execute_reply": "2021-04-30T00:38:11.862463Z"
    },
    "id": "QJggkCNbED-1",
    "papermill": {
     "duration": 0.623461,
     "end_time": "2021-04-30T00:38:11.862585",
     "exception": false,
     "start_time": "2021-04-30T00:38:11.239124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:38:12.686706Z",
     "iopub.status.busy": "2021-04-30T00:38:12.685879Z",
     "iopub.status.idle": "2021-04-30T00:38:14.151597Z",
     "shell.execute_reply": "2021-04-30T00:38:14.152237Z"
    },
    "id": "mOyVMdxYED-1",
    "papermill": {
     "duration": 1.881857,
     "end_time": "2021-04-30T00:38:14.152393",
     "exception": false,
     "start_time": "2021-04-30T00:38:12.270536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg=get_config()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(MODELS_PATH, \"best_model.pth\")  # path to the model we just trained\n",
    "model = build_model(cfg)\n",
    "m=DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:38:15.084794Z",
     "iopub.status.busy": "2021-04-30T00:38:15.083951Z",
     "iopub.status.idle": "2021-04-30T00:40:02.727753Z",
     "shell.execute_reply": "2021-04-30T00:40:02.727208Z"
    },
    "id": "QhmN1En7ED-2",
    "outputId": "8b3f4e84-62f0-4354-fc39-1e9c8b3a22bd",
    "papermill": {
     "duration": 108.141581,
     "end_time": "2021-04-30T00:40:02.727865",
     "exception": false,
     "start_time": "2021-04-30T00:38:14.586284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 00:38:15 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 00:38:15 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 00:38:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/30 00:38:15 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 00:38:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 00:38:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 00:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1268 s / img. ETA=0:01:11\n",
      "\u001b[32m[04/30 00:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 29/310. 0.1294 s / img. ETA=0:01:17\n",
      "\u001b[32m[04/30 00:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 42/310. 0.1275 s / img. ETA=0:01:30\n",
      "\u001b[32m[04/30 00:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 54/310. 0.1312 s / img. ETA=0:01:32\n",
      "\u001b[32m[04/30 00:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.1340 s / img. ETA=0:01:39\n",
      "\u001b[32m[04/30 00:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 74/310. 0.1363 s / img. ETA=0:01:39\n",
      "\u001b[32m[04/30 00:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 86/310. 0.1354 s / img. ETA=0:01:34\n",
      "\u001b[32m[04/30 00:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 100/310. 0.1340 s / img. ETA=0:01:26\n",
      "\u001b[32m[04/30 00:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 112/310. 0.1335 s / img. ETA=0:01:21\n",
      "\u001b[32m[04/30 00:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 126/310. 0.1329 s / img. ETA=0:01:17\n",
      "\u001b[32m[04/30 00:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 146/310. 0.1319 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 00:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 165/310. 0.1314 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 00:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 182/310. 0.1311 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/30 00:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 201/310. 0.1309 s / img. ETA=0:00:40\n",
      "\u001b[32m[04/30 00:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 218/310. 0.1302 s / img. ETA=0:00:33\n",
      "\u001b[32m[04/30 00:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 238/310. 0.1307 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 00:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 250/310. 0.1316 s / img. ETA=0:00:21\n",
      "\u001b[32m[04/30 00:39:51 d2.evaluation.evaluator]: \u001b[0mInference done 268/310. 0.1311 s / img. ETA=0:00:15\n",
      "\u001b[32m[04/30 00:39:56 d2.evaluation.evaluator]: \u001b[0mInference done 288/310. 0.1317 s / img. ETA=0:00:07\n",
      "\u001b[32m[04/30 00:40:01 d2.evaluation.evaluator]: \u001b[0mInference done 307/310. 0.1313 s / img. ETA=0:00:01\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:45.448756 (0.345734 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.131051 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to logs/coco_instances_results.json\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.109 | 23.068 | 18.149 | 1.238 | 14.767 | 18.706 |\n",
      "\u001b[32m[04/30 00:40:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 38.997 | Carton          | 32.254 | Bottle cap     | 27.368 |\n",
      "| Can                   | 32.842 | Pop tab         | 11.858 | Cup            | 26.797 |\n",
      "| Plastic bag & wrapper | 29.296 | Styrofoam piece | 15.619 | Other plastic  | 3.667  |\n",
      "| Plastic container     | 21.484 | Paper           | 10.796 | Lid            | 22.713 |\n",
      "| Straw                 | 17.671 | Paper bag       | 20.619 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 59.147 | Glass jar       | 0.000  | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 19.736 |\n",
      "| Unlabeled litter      | 1.148  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 20.198 | Cigarette       | 10.856 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n"
     ]
    }
   ],
   "source": [
    "evaluator = COCOEvaluator(\"my_dataset_test_0\", (\"bbox\",), False, output_dir=LOGS_PATH)\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test_0\")\n",
    "train_metric=inference_on_dataset(model, val_loader, evaluator)\n",
    "metrics[\"train_metric\"]=train_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:40:03.601963Z",
     "iopub.status.busy": "2021-04-30T00:40:03.601012Z",
     "iopub.status.idle": "2021-04-30T00:46:43.650154Z",
     "shell.execute_reply": "2021-04-30T00:46:43.649472Z"
    },
    "id": "6ec3dABzED-2",
    "outputId": "002c844b-5e8c-457a-b4fe-7f66c9c85732",
    "papermill": {
     "duration": 400.485685,
     "end_time": "2021-04-30T00:46:43.650294",
     "exception": false,
     "start_time": "2021-04-30T00:40:03.164609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 00:40:03 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 00:40:03 d2.data.datasets.coco]: \u001b[0mLoaded 1190 images in COCO format from my_dataset_train_0.json\n",
      "\u001b[32m[04/30 00:40:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/30 00:40:03 d2.data.common]: \u001b[0mSerializing 1190 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 00:40:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.80 MiB\n",
      "\u001b[32m[04/30 00:40:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 1190 images\n",
      "\u001b[32m[04/30 00:40:06 d2.evaluation.evaluator]: \u001b[0mInference done 12/1190. 0.1222 s / img. ETA=0:02:56\n",
      "\u001b[32m[04/30 00:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 40/1190. 0.1220 s / img. ETA=0:03:29\n",
      "\u001b[32m[04/30 00:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 60/1190. 0.1270 s / img. ETA=0:03:59\n",
      "\u001b[32m[04/30 00:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 80/1190. 0.1279 s / img. ETA=0:04:13\n",
      "\u001b[32m[04/30 00:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 99/1190. 0.1284 s / img. ETA=0:04:18\n",
      "\u001b[32m[04/30 00:40:32 d2.evaluation.evaluator]: \u001b[0mInference done 119/1190. 0.1277 s / img. ETA=0:04:17\n",
      "\u001b[32m[04/30 00:40:37 d2.evaluation.evaluator]: \u001b[0mInference done 136/1190. 0.1276 s / img. ETA=0:04:21\n",
      "\u001b[32m[04/30 00:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 156/1190. 0.1289 s / img. ETA=0:04:20\n",
      "\u001b[32m[04/30 00:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 173/1190. 0.1298 s / img. ETA=0:04:20\n",
      "\u001b[32m[04/30 00:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 184/1190. 0.1300 s / img. ETA=0:04:34\n",
      "\u001b[32m[04/30 00:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 196/1190. 0.1304 s / img. ETA=0:04:42\n",
      "\u001b[32m[04/30 00:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 208/1190. 0.1298 s / img. ETA=0:04:48\n",
      "\u001b[32m[04/30 00:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 220/1190. 0.1296 s / img. ETA=0:04:52\n",
      "\u001b[32m[04/30 00:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 232/1190. 0.1300 s / img. ETA=0:04:56\n",
      "\u001b[32m[04/30 00:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 244/1190. 0.1311 s / img. ETA=0:05:02\n",
      "\u001b[32m[04/30 00:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 254/1190. 0.1322 s / img. ETA=0:05:06\n",
      "\u001b[32m[04/30 00:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 263/1190. 0.1332 s / img. ETA=0:05:11\n",
      "\u001b[32m[04/30 00:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 272/1190. 0.1335 s / img. ETA=0:05:20\n",
      "\u001b[32m[04/30 00:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 288/1190. 0.1334 s / img. ETA=0:05:15\n",
      "\u001b[32m[04/30 00:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 300/1190. 0.1342 s / img. ETA=0:05:13\n",
      "\u001b[32m[04/30 00:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 312/1190. 0.1341 s / img. ETA=0:05:14\n",
      "\u001b[32m[04/30 00:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 324/1190. 0.1339 s / img. ETA=0:05:11\n",
      "\u001b[32m[04/30 00:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 336/1190. 0.1338 s / img. ETA=0:05:10\n",
      "\u001b[32m[04/30 00:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 348/1190. 0.1335 s / img. ETA=0:05:07\n",
      "\u001b[32m[04/30 00:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 360/1190. 0.1333 s / img. ETA=0:05:05\n",
      "\u001b[32m[04/30 00:42:21 d2.evaluation.evaluator]: \u001b[0mInference done 372/1190. 0.1336 s / img. ETA=0:05:03\n",
      "\u001b[32m[04/30 00:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 384/1190. 0.1333 s / img. ETA=0:05:01\n",
      "\u001b[32m[04/30 00:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 396/1190. 0.1330 s / img. ETA=0:04:58\n",
      "\u001b[32m[04/30 00:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 408/1190. 0.1329 s / img. ETA=0:04:55\n",
      "\u001b[32m[04/30 00:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 422/1190. 0.1327 s / img. ETA=0:04:50\n",
      "\u001b[32m[04/30 00:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 434/1190. 0.1326 s / img. ETA=0:04:47\n",
      "\u001b[32m[04/30 00:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 444/1190. 0.1327 s / img. ETA=0:04:45\n",
      "\u001b[32m[04/30 00:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 456/1190. 0.1328 s / img. ETA=0:04:42\n",
      "\u001b[32m[04/30 00:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 469/1190. 0.1326 s / img. ETA=0:04:38\n",
      "\u001b[32m[04/30 00:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 480/1190. 0.1327 s / img. ETA=0:04:34\n",
      "\u001b[32m[04/30 00:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 500/1190. 0.1322 s / img. ETA=0:04:23\n",
      "\u001b[32m[04/30 00:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 514/1190. 0.1319 s / img. ETA=0:04:19\n",
      "\u001b[32m[04/30 00:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 530/1190. 0.1317 s / img. ETA=0:04:12\n",
      "\u001b[32m[04/30 00:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 554/1190. 0.1317 s / img. ETA=0:03:58\n",
      "\u001b[32m[04/30 00:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 573/1190. 0.1314 s / img. ETA=0:03:49\n",
      "\u001b[32m[04/30 00:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 591/1190. 0.1312 s / img. ETA=0:03:41\n",
      "\u001b[32m[04/30 00:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 608/1190. 0.1310 s / img. ETA=0:03:34\n",
      "\u001b[32m[04/30 00:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 626/1190. 0.1309 s / img. ETA=0:03:26\n",
      "\u001b[32m[04/30 00:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 640/1190. 0.1312 s / img. ETA=0:03:20\n",
      "\u001b[32m[04/30 00:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 660/1190. 0.1309 s / img. ETA=0:03:12\n",
      "\u001b[32m[04/30 00:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 676/1190. 0.1308 s / img. ETA=0:03:05\n",
      "\u001b[32m[04/30 00:44:13 d2.evaluation.evaluator]: \u001b[0mInference done 696/1190. 0.1307 s / img. ETA=0:02:57\n",
      "\u001b[32m[04/30 00:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 715/1190. 0.1306 s / img. ETA=0:02:49\n",
      "\u001b[32m[04/30 00:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 732/1190. 0.1304 s / img. ETA=0:02:42\n",
      "\u001b[32m[04/30 00:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 748/1190. 0.1309 s / img. ETA=0:02:36\n",
      "\u001b[32m[04/30 00:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 768/1190. 0.1306 s / img. ETA=0:02:29\n",
      "\u001b[32m[04/30 00:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 784/1190. 0.1306 s / img. ETA=0:02:23\n",
      "\u001b[32m[04/30 00:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 801/1190. 0.1306 s / img. ETA=0:02:16\n",
      "\u001b[32m[04/30 00:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 818/1190. 0.1306 s / img. ETA=0:02:10\n",
      "\u001b[32m[04/30 00:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 836/1190. 0.1305 s / img. ETA=0:02:03\n",
      "\u001b[32m[04/30 00:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 854/1190. 0.1307 s / img. ETA=0:01:56\n",
      "\u001b[32m[04/30 00:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 873/1190. 0.1305 s / img. ETA=0:01:49\n",
      "\u001b[32m[04/30 00:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 890/1190. 0.1305 s / img. ETA=0:01:43\n",
      "\u001b[32m[04/30 00:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 909/1190. 0.1304 s / img. ETA=0:01:36\n",
      "\u001b[32m[04/30 00:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 926/1190. 0.1303 s / img. ETA=0:01:30\n",
      "\u001b[32m[04/30 00:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 938/1190. 0.1304 s / img. ETA=0:01:27\n",
      "\u001b[32m[04/30 00:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 954/1190. 0.1306 s / img. ETA=0:01:21\n",
      "\u001b[32m[04/30 00:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 974/1190. 0.1305 s / img. ETA=0:01:14\n",
      "\u001b[32m[04/30 00:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 992/1190. 0.1305 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 00:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 1010/1190. 0.1304 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/30 00:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 1026/1190. 0.1305 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/30 00:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 1046/1190. 0.1304 s / img. ETA=0:00:49\n",
      "\u001b[32m[04/30 00:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 1062/1190. 0.1305 s / img. ETA=0:00:43\n",
      "\u001b[32m[04/30 00:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 1085/1190. 0.1303 s / img. ETA=0:00:35\n",
      "\u001b[32m[04/30 00:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 1101/1190. 0.1305 s / img. ETA=0:00:30\n",
      "\u001b[32m[04/30 00:46:22 d2.evaluation.evaluator]: \u001b[0mInference done 1118/1190. 0.1307 s / img. ETA=0:00:24\n",
      "\u001b[32m[04/30 00:46:27 d2.evaluation.evaluator]: \u001b[0mInference done 1138/1190. 0.1306 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/30 00:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 1154/1190. 0.1306 s / img. ETA=0:00:12\n",
      "\u001b[32m[04/30 00:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 1172/1190. 0.1306 s / img. ETA=0:00:06\n",
      "\u001b[32m[04/30 00:46:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:36.906095 (0.334942 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:46:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:34 (0.130446 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 00:46:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 00:46:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to logs/coco_instances_results.json\n",
      "\u001b[32m[04/30 00:46:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 00:46:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 00:46:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.83 seconds.\n",
      "\u001b[32m[04/30 00:46:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 00:46:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.18 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.415\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
      "\u001b[32m[04/30 00:46:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.118 | 41.521 | 28.193 | 3.844 | 16.032 | 31.070 |\n",
      "\u001b[32m[04/30 00:46:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 54.350 | Carton          | 41.163 | Bottle cap     | 40.086 |\n",
      "| Can                   | 52.929 | Pop tab         | 19.383 | Cup            | 45.044 |\n",
      "| Plastic bag & wrapper | 36.806 | Styrofoam piece | 34.266 | Other plastic  | 17.573 |\n",
      "| Plastic container     | 29.604 | Paper           | 26.774 | Lid            | 34.310 |\n",
      "| Straw                 | 28.052 | Paper bag       | 29.147 | Broken glass   | 7.084  |\n",
      "| Plastic utensils      | 27.398 | Glass jar       | 31.584 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 30.842 | Aluminium foil | 37.080 |\n",
      "| Unlabeled litter      | 11.159 | Blister pack    | 22.376 | Battery        | 0.000  |\n",
      "| Rope & strings        | 22.836 | Cigarette       | 17.111 | Scrap metal    | 6.337  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n"
     ]
    }
   ],
   "source": [
    "evaluator = COCOEvaluator(\"my_dataset_train_0\", (\"bbox\",), False, output_dir=LOGS_PATH)\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_train_0\")\n",
    "valid_metric=inference_on_dataset(model, val_loader, evaluator)\n",
    "metrics[\"valid_metric\"]=valid_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:46:44.550806Z",
     "iopub.status.busy": "2021-04-30T00:46:44.547710Z",
     "iopub.status.idle": "2021-04-30T00:46:44.553471Z",
     "shell.execute_reply": "2021-04-30T00:46:44.552974Z"
    },
    "id": "iE3NWP7uED-2",
    "papermill": {
     "duration": 0.45752,
     "end_time": "2021-04-30T00:46:44.553559",
     "exception": false,
     "start_time": "2021-04-30T00:46:44.096039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dump_dict(metrics,os.path.join(LOGS_PATH,\"metrics.yaml\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 29708.220813,
   "end_time": "2021-04-30T00:46:46.720475",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-29T16:31:38.499662",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
