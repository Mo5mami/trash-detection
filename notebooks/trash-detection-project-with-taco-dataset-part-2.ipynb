{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wEymMceED94",
    "papermill": {
     "duration": 0.033736,
     "end_time": "2021-04-30T00:55:41.093182",
     "exception": false,
     "start_time": "2021-04-30T00:55:41.059446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:55:41.165199Z",
     "iopub.status.busy": "2021-04-30T00:55:41.163458Z",
     "iopub.status.idle": "2021-04-30T00:55:41.165788Z",
     "shell.execute_reply": "2021-04-30T00:55:41.166191Z"
    },
    "id": "eTJ6aqypED-G",
    "outputId": "b651123e-ef7a-4b76-94e3-bb5bd7edee37",
    "papermill": {
     "duration": 0.040539,
     "end_time": "2021-04-30T00:55:41.166331",
     "exception": false,
     "start_time": "2021-04-30T00:55:41.125792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python -m pip install detectron2==0.4 -f \\\n",
    "#  https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:55:41.238112Z",
     "iopub.status.busy": "2021-04-30T00:55:41.237376Z",
     "iopub.status.idle": "2021-04-30T00:56:09.712952Z",
     "shell.execute_reply": "2021-04-30T00:56:09.711846Z"
    },
    "papermill": {
     "duration": 28.513609,
     "end_time": "2021-04-30T00:56:09.713091",
     "exception": false,
     "start_time": "2021-04-30T00:55:41.199482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html\r\n",
      "Collecting detectron2==0.4\r\n",
      "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/detectron2-0.4%2Bcu102-cp37-cp37m-linux_x86_64.whl (5.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 810 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (0.8.7)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (1.3.0)\r\n",
      "Collecting pycocotools>=2.0.2\r\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\r\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (8.0.1)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (1.1.0)\r\n",
      "Collecting yacs>=0.1.6\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Collecting fvcore<0.1.4,>=0.1.3\r\n",
      "  Downloading fvcore-0.1.3.post20210317.tar.gz (47 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 47 kB 895 kB/s \r\n",
      "\u001b[?25hCollecting iopath>=0.1.2\r\n",
      "  Downloading iopath-0.1.8-py3-none-any.whl (19 kB)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (4.45.0)\r\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (3.2.1)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (2.3.0)\r\n",
      "Collecting omegaconf>=2\r\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from detectron2==0.4) (0.18.2)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2==0.4) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2==0.4) (0.29.21)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs>=0.1.6->detectron2==0.4) (5.3.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore<0.1.4,>=0.1.3->detectron2==0.4) (1.18.5)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath>=0.1.2->detectron2==0.4) (2.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot->detectron2==0.4) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.4) (2.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.4) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.4) (0.10.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.14.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.7.0)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (0.34.2)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.14.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (2.23.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (0.11.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (0.4.1)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (3.13.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (1.33.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.4) (3.2.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf>=2->detectron2==0.4) (3.7.4.1)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (4.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (3.1.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.2.7)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (1.25.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2020.6.20)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (3.0.1)\r\n",
      "Building wheels for collected packages: pycocotools, fvcore\r\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=273762 sha256=c0de48c57c1670acf873668756bcd096c5af0fa904ebbaaf899a5cafc98c4342\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.3.post20210317-py3-none-any.whl size=58540 sha256=2a83f054b81883810dbdb10d2cd5cd693e03c98517ed160acdff241b07e32481\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a6/02/09/10e3a0150eb92e5ecbee3677a813bffc32a8ec6f876bfe4adf\r\n",
      "Successfully built pycocotools fvcore\r\n",
      "Installing collected packages: pycocotools, yacs, iopath, fvcore, omegaconf, detectron2\r\n",
      "Successfully installed detectron2-0.4+cu102 fvcore-0.1.3.post20210317 iopath-0.1.8 omegaconf-2.0.6 pycocotools-2.0.2 yacs-0.1.8\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install detectron2==0.4 -f \\\n",
    "  https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:09.874777Z",
     "iopub.status.busy": "2021-04-30T00:56:09.873874Z",
     "iopub.status.idle": "2021-04-30T00:56:11.650895Z",
     "shell.execute_reply": "2021-04-30T00:56:11.650410Z"
    },
    "papermill": {
     "duration": 1.862771,
     "end_time": "2021-04-30T00:56:11.651007",
     "exception": false,
     "start_time": "2021-04-30T00:56:09.788236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-ignite==0.4.2\r\n",
      "pytorch-lightning==1.0.4\r\n",
      "torch==1.6.0\r\n",
      "torchaudio==0.6.0a0+f17ae39\r\n",
      "torchtext==0.8.0a0+c851c3e\r\n",
      "torchvision==0.7.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:11.756320Z",
     "iopub.status.busy": "2021-04-30T00:56:11.753371Z",
     "iopub.status.idle": "2021-04-30T00:56:12.381185Z",
     "shell.execute_reply": "2021-04-30T00:56:12.380370Z"
    },
    "id": "wK4MocOFED-O",
    "papermill": {
     "duration": 0.680908,
     "end_time": "2021-04-30T00:56:12.381297",
     "exception": false,
     "start_time": "2021-04-30T00:56:11.700389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p models logs configs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:12.488535Z",
     "iopub.status.busy": "2021-04-30T00:56:12.485825Z",
     "iopub.status.idle": "2021-04-30T00:56:13.971403Z",
     "shell.execute_reply": "2021-04-30T00:56:13.970808Z"
    },
    "id": "ij6R7KtAED-P",
    "outputId": "691fa7cd-93e1-4182-bbad-d38da4171805",
    "papermill": {
     "duration": 1.540042,
     "end_time": "2021-04-30T00:56:13.971513",
     "exception": false,
     "start_time": "2021-04-30T00:56:12.431471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 30 00:56:13 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQP0yElOED-Q",
    "papermill": {
     "duration": 0.052548,
     "end_time": "2021-04-30T00:56:14.077950",
     "exception": false,
     "start_time": "2021-04-30T00:56:14.025402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:14.193459Z",
     "iopub.status.busy": "2021-04-30T00:56:14.192155Z",
     "iopub.status.idle": "2021-04-30T00:56:17.496623Z",
     "shell.execute_reply": "2021-04-30T00:56:17.495465Z"
    },
    "id": "4u5GjrIPED-R",
    "papermill": {
     "duration": 3.368379,
     "end_time": "2021-04-30T00:56:17.496764",
     "exception": false,
     "start_time": "2021-04-30T00:56:14.128385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "\n",
    "import detectron2\n",
    "from detectron2.data.transforms import Transform as T\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper, build_detection_test_loader , build_detection_train_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.config import configurable\n",
    "from detectron2.engine.hooks import EvalHook\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,StratifiedShuffleSplit,GroupKFold\n",
    "from sklearn.utils import check_random_state\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from IPython.display import FileLink, FileLinks\n",
    "import yaml\n",
    "from abc import ABC,ABCMeta, abstractmethod\n",
    "from yacs.config import CfgNode as CN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR0PbMOBED-T",
    "papermill": {
     "duration": 0.050438,
     "end_time": "2021-04-30T00:56:17.597799",
     "exception": false,
     "start_time": "2021-04-30T00:56:17.547361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:17.707093Z",
     "iopub.status.busy": "2021-04-30T00:56:17.705320Z",
     "iopub.status.idle": "2021-04-30T00:56:17.707731Z",
     "shell.execute_reply": "2021-04-30T00:56:17.708142Z"
    },
    "id": "RsqnTOaRR-5C",
    "papermill": {
     "duration": 0.058467,
     "end_time": "2021-04-30T00:56:17.708272",
     "exception": false,
     "start_time": "2021-04-30T00:56:17.649805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../input/tacotrashdataset\"\n",
    "LOGS_PATH = \"logs\"\n",
    "MODELS_PATH = \"models\"\n",
    "CONFIG_PATH = \"configs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:17.817961Z",
     "iopub.status.busy": "2021-04-30T00:56:17.817283Z",
     "iopub.status.idle": "2021-04-30T00:56:17.820782Z",
     "shell.execute_reply": "2021-04-30T00:56:17.821159Z"
    },
    "id": "9mL5TQiXSFEm",
    "papermill": {
     "duration": 0.062745,
     "end_time": "2021-04-30T00:56:17.821290",
     "exception": false,
     "start_time": "2021-04-30T00:56:17.758545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_C = CN()\n",
    "_C.general=CN()\n",
    "_C.general.seed = 42\n",
    "_C.general.n_folds = 5\n",
    "_C.general.tool = \"detectron2\"\n",
    "_C.general.experiment_id = \"26-04-2021\"\n",
    "_C.general.category = \"super_category\"\n",
    "_C.general.augmentations = True\n",
    "_C.general.TTA = False\n",
    "\n",
    "_C.preprocess=CN()\n",
    "_C.preprocess.height = 1500\n",
    "_C.preprocess.width = 1500\n",
    "_C.preprocess.longest_max_size = 1500\n",
    "_C.preprocess.smallest_max_size = 1000\n",
    "\n",
    "_C.model=CN()\n",
    "_C.model.base_lr = 0.0004\n",
    "_C.model.num_classes = 29 #29 if super category 60 if normal category \n",
    "_C.model.model_name = \"faster_rcnn_R_101_FPN_3x\"\n",
    "_C.model.batchsize_per_image = 1024\n",
    "#_C.model.images_per_batch = 4\n",
    "_C.model.images_per_batch = 4\n",
    "_C.model.epochs = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:17.930085Z",
     "iopub.status.busy": "2021-04-30T00:56:17.929394Z",
     "iopub.status.idle": "2021-04-30T00:56:17.932634Z",
     "shell.execute_reply": "2021-04-30T00:56:17.933028Z"
    },
    "id": "0QQlNoxsED-U",
    "papermill": {
     "duration": 0.061297,
     "end_time": "2021-04-30T00:56:17.933139",
     "exception": false,
     "start_time": "2021-04-30T00:56:17.871842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cfg_defaults():\n",
    "    \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
    "    # Return a clone so that the defaults will not be altered\n",
    "    # This is for the \"local variable\" use pattern\n",
    "    #return _C.clone()\n",
    "    return _C\n",
    "\n",
    "def dump_cfg(config = get_cfg_defaults() , path = \"experiment.yaml\"):\n",
    "    \"\"\"Save a yacs CfgNode object in a yaml file in path.\"\"\"\n",
    "    stream = open(path, 'w')\n",
    "    stream.write(config.dump())\n",
    "    stream.close()\n",
    "\n",
    "def inject_config(funct):\n",
    "    \"\"\"Inject a yacs CfgNode object in a function as first arg.\"\"\"\n",
    "    def function_wrapper(*args,**kwargs):\n",
    "        return funct(_C,*args,**kwargs)  \n",
    "    return function_wrapper\n",
    "\n",
    "def dump_dict(config,path=\"config.yaml\"):\n",
    "        stream = open(path, 'w')\n",
    "        yaml.dump(config,stream)\n",
    "        stream.close()\n",
    "\n",
    "c=get_cfg_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:18.040745Z",
     "iopub.status.busy": "2021-04-30T00:56:18.039352Z",
     "iopub.status.idle": "2021-04-30T00:56:18.042536Z",
     "shell.execute_reply": "2021-04-30T00:56:18.042114Z"
    },
    "id": "NWhZpAG8ED-W",
    "papermill": {
     "duration": 0.059828,
     "end_time": "2021-04-30T00:56:18.042659",
     "exception": false,
     "start_time": "2021-04-30T00:56:17.982831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dump_cfg(path = os.path.join(LOGS_PATH , \"experiment.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM4UyIkMED-X",
    "papermill": {
     "duration": 0.050007,
     "end_time": "2021-04-30T00:56:18.143023",
     "exception": false,
     "start_time": "2021-04-30T00:56:18.093016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:18.253377Z",
     "iopub.status.busy": "2021-04-30T00:56:18.251586Z",
     "iopub.status.idle": "2021-04-30T00:56:18.253970Z",
     "shell.execute_reply": "2021-04-30T00:56:18.254371Z"
    },
    "id": "jJdQmFwbED-Z",
    "papermill": {
     "duration": 0.061284,
     "end_time": "2021-04-30T00:56:18.254485",
     "exception": false,
     "start_time": "2021-04-30T00:56:18.193201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def seed_all(config):\n",
    "    \"\"\"\n",
    "    seed my experiments to be able to reproduce\n",
    "    \"\"\"\n",
    "    seed_value=config.general[\"seed\"]\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDqBVC89ED-a",
    "papermill": {
     "duration": 0.0501,
     "end_time": "2021-04-30T00:56:18.354814",
     "exception": false,
     "start_time": "2021-04-30T00:56:18.304714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FIX annotation duplicated ids and negative bboxes\n",
    "\n",
    "repeated annotations idx \n",
    "\n",
    "308 => 0\n",
    "\n",
    "4039  =>2197\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:18.460407Z",
     "iopub.status.busy": "2021-04-30T00:56:18.459772Z",
     "iopub.status.idle": "2021-04-30T00:56:18.716440Z",
     "shell.execute_reply": "2021-04-30T00:56:18.714997Z"
    },
    "id": "ANn9_6WsED-a",
    "papermill": {
     "duration": 0.311398,
     "end_time": "2021-04-30T00:56:18.716564",
     "exception": false,
     "start_time": "2021-04-30T00:56:18.405166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot=json.load(open(os.path.join(DATASET_PATH,\"data/annotations.json\")))\n",
    "annot[\"annotations\"][308][\"id\"]=0\n",
    "annot[\"annotations\"][4039][\"id\"]=2197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xFUGtpxED-a",
    "papermill": {
     "duration": 0.052195,
     "end_time": "2021-04-30T00:56:18.819567",
     "exception": false,
     "start_time": "2021-04-30T00:56:18.767372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## delete negative BBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:18.932946Z",
     "iopub.status.busy": "2021-04-30T00:56:18.931147Z",
     "iopub.status.idle": "2021-04-30T00:56:18.933684Z",
     "shell.execute_reply": "2021-04-30T00:56:18.934098Z"
    },
    "id": "-VlzvW8JED-b",
    "papermill": {
     "duration": 0.064702,
     "end_time": "2021-04-30T00:56:18.934209",
     "exception": false,
     "start_time": "2021-04-30T00:56:18.869507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_to_delete=[]\n",
    "for idx,annotation in enumerate(annot[\"annotations\"]):\n",
    "    if (annotation[\"bbox\"][0]<0 or annotation[\"bbox\"][1]<0 or\n",
    "        annotation[\"bbox\"][2]<0 or annotation[\"bbox\"][3]<0):\n",
    "        annot_to_delete.append(idx)\n",
    "for pos,idx in enumerate(annot_to_delete):\n",
    "    del annot[\"annotations\"][idx-pos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:19.053639Z",
     "iopub.status.busy": "2021-04-30T00:56:19.039971Z",
     "iopub.status.idle": "2021-04-30T00:56:19.545820Z",
     "shell.execute_reply": "2021-04-30T00:56:19.545296Z"
    },
    "id": "kZcq7GCDED-b",
    "papermill": {
     "duration": 0.561502,
     "end_time": "2021-04-30T00:56:19.545933",
     "exception": false,
     "start_time": "2021-04-30T00:56:18.984431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(annot,open(\"new_annotations.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptphgt97ED-c",
    "papermill": {
     "duration": 0.050256,
     "end_time": "2021-04-30T00:56:19.646822",
     "exception": false,
     "start_time": "2021-04-30T00:56:19.596566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Annotation Preprocess and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sR-XOdvED-c",
    "papermill": {
     "duration": 0.050375,
     "end_time": "2021-04-30T00:56:19.747322",
     "exception": false,
     "start_time": "2021-04-30T00:56:19.696947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Categories and Super categories dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:19.899610Z",
     "iopub.status.busy": "2021-04-30T00:56:19.897775Z",
     "iopub.status.idle": "2021-04-30T00:56:19.908971Z",
     "shell.execute_reply": "2021-04-30T00:56:19.909659Z"
    },
    "id": "afefHsVYED-d",
    "papermill": {
     "duration": 0.105424,
     "end_time": "2021-04-30T00:56:19.909864",
     "exception": false,
     "start_time": "2021-04-30T00:56:19.804440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories={ annotation[\"id\"] : annotation[\"name\"] for annotation in annot[\"categories\"]}\n",
    "super_categories={ annotation[\"id\"] : annotation[\"supercategory\"] for annotation in annot[\"categories\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IA_JHKt0ED-f",
    "papermill": {
     "duration": 0.096476,
     "end_time": "2021-04-30T00:56:20.105217",
     "exception": false,
     "start_time": "2021-04-30T00:56:20.008741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:20.295832Z",
     "iopub.status.busy": "2021-04-30T00:56:20.295063Z",
     "iopub.status.idle": "2021-04-30T00:56:20.330002Z",
     "shell.execute_reply": "2021-04-30T00:56:20.330616Z"
    },
    "id": "2VFDgjvVED-f",
    "papermill": {
     "duration": 0.133432,
     "end_time": "2021-04-30T00:56:20.330780",
     "exception": false,
     "start_time": "2021-04-30T00:56:20.197348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_df=pd.DataFrame(annot[\"annotations\"])\n",
    "images_df=pd.DataFrame(annot[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:20.521993Z",
     "iopub.status.busy": "2021-04-30T00:56:20.521185Z",
     "iopub.status.idle": "2021-04-30T00:56:20.550565Z",
     "shell.execute_reply": "2021-04-30T00:56:20.551559Z"
    },
    "id": "axg8vADJED-f",
    "outputId": "5add80ef-22f9-4d09-9b39-f4d465d58eb3",
    "papermill": {
     "duration": 0.120056,
     "end_time": "2021-04-30T00:56:20.551735",
     "exception": false,
     "start_time": "2021-04-30T00:56:20.431679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>749.500000</td>\n",
       "      <td>2824.88400</td>\n",
       "      <td>3222.825333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>433.157015</td>\n",
       "      <td>758.65017</td>\n",
       "      <td>802.357852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>842.00000</td>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>374.750000</td>\n",
       "      <td>2448.00000</td>\n",
       "      <td>2448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>749.500000</td>\n",
       "      <td>2448.00000</td>\n",
       "      <td>3264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1124.250000</td>\n",
       "      <td>3264.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1499.000000</td>\n",
       "      <td>6000.00000</td>\n",
       "      <td>5312.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       width       height\n",
       "count  1500.000000  1500.00000  1500.000000\n",
       "mean    749.500000  2824.88400  3222.825333\n",
       "std     433.157015   758.65017   802.357852\n",
       "min       0.000000   842.00000   474.000000\n",
       "25%     374.750000  2448.00000  2448.000000\n",
       "50%     749.500000  2448.00000  3264.000000\n",
       "75%    1124.250000  3264.00000  4000.000000\n",
       "max    1499.000000  6000.00000  5312.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUiH0qtEXj58",
    "papermill": {
     "duration": 0.061051,
     "end_time": "2021-04-30T00:56:20.723352",
     "exception": false,
     "start_time": "2021-04-30T00:56:20.662301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Choose between normal categories or super categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:20.891765Z",
     "iopub.status.busy": "2021-04-30T00:56:20.891002Z",
     "iopub.status.idle": "2021-04-30T00:56:20.921714Z",
     "shell.execute_reply": "2021-04-30T00:56:20.922657Z"
    },
    "id": "nY1UmdtiED-g",
    "papermill": {
     "duration": 0.124743,
     "end_time": "2021-04-30T00:56:20.922830",
     "exception": false,
     "start_time": "2021-04-30T00:56:20.798087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_df[\"category\"]=annot_df[\"category_id\"].apply(lambda value : categories[value])\n",
    "annot_df[\"super_category\"]=annot_df[\"category_id\"].apply(lambda value : super_categories[value])\n",
    "super_category_to_index={value : key for key,value in enumerate(annot_df[\"super_category\"].unique())}\n",
    "annot_df[\"super_category_id\"]=annot_df[\"super_category\"].apply(lambda value : super_category_to_index[value])\n",
    "annot_df[\"normal_category_id\"]=annot_df[\"category_id\"]\n",
    "annot_df[\"normal_category\"]=annot_df[\"category\"]\n",
    "if c.general[\"category\"] != \"normal_category\":\n",
    "    annot_df[\"category_id\"]=annot_df[\"super_category_id\"]\n",
    "    annot_df[\"category\"]=annot_df[\"super_category\"]\n",
    "    annot_cat=annot_df.groupby(\"category_id\")[[\"category_id\",\"category\",\"super_category\"]].first()\n",
    "    annot_cat.columns=[\"id\",\"name\",\"supercategory\"]\n",
    "    annot[\"categories\"]=annot_cat.to_dict(\"records\")\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:21.068450Z",
     "iopub.status.busy": "2021-04-30T00:56:21.067900Z",
     "iopub.status.idle": "2021-04-30T00:56:21.072090Z",
     "shell.execute_reply": "2021-04-30T00:56:21.071452Z"
    },
    "id": "kbeKt9MKED-h",
    "papermill": {
     "duration": 0.065811,
     "end_time": "2021-04-30T00:56:21.072188",
     "exception": false,
     "start_time": "2021-04-30T00:56:21.006377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for id , name in zip(annot_df[\"category_id\"],annot_df[\"category\"]):\n",
    "    categories[id]=name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:21.181397Z",
     "iopub.status.busy": "2021-04-30T00:56:21.180888Z",
     "iopub.status.idle": "2021-04-30T00:56:21.185896Z",
     "shell.execute_reply": "2021-04-30T00:56:21.185452Z"
    },
    "id": "KKi6DDiZED-h",
    "outputId": "d6afa885-1ba2-4a7a-eab6-f1a3a12bf555",
    "papermill": {
     "duration": 0.06124,
     "end_time": "2021-04-30T00:56:21.185990",
     "exception": false,
     "start_time": "2021-04-30T00:56:21.124750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bottle',\n",
       " 1: 'Carton',\n",
       " 2: 'Bottle cap',\n",
       " 3: 'Can',\n",
       " 4: 'Pop tab',\n",
       " 5: 'Cup',\n",
       " 6: 'Plastic bag & wrapper',\n",
       " 7: 'Styrofoam piece',\n",
       " 8: 'Other plastic',\n",
       " 9: 'Plastic container',\n",
       " 10: 'Paper',\n",
       " 11: 'Lid',\n",
       " 12: 'Straw',\n",
       " 13: 'Paper bag',\n",
       " 14: 'Broken glass',\n",
       " 15: 'Plastic utensils',\n",
       " 16: 'Glass jar',\n",
       " 17: 'Food waste',\n",
       " 18: 'Squeezable tube',\n",
       " 19: 'Shoe',\n",
       " 20: 'Aluminium foil',\n",
       " 21: 'Unlabeled litter',\n",
       " 22: 'Blister pack',\n",
       " 23: 'Battery',\n",
       " 24: 'Rope & strings',\n",
       " 25: 'Cigarette',\n",
       " 26: 'Scrap metal',\n",
       " 27: 'Plastic glooves'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcJOY-OPED-i",
    "papermill": {
     "duration": 0.051284,
     "end_time": "2021-04-30T00:56:21.289500",
     "exception": false,
     "start_time": "2021-04-30T00:56:21.238216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:21.421867Z",
     "iopub.status.busy": "2021-04-30T00:56:21.420800Z",
     "iopub.status.idle": "2021-04-30T00:56:21.425398Z",
     "shell.execute_reply": "2021-04-30T00:56:21.424896Z"
    },
    "id": "NxqT7Z8fED-i",
    "outputId": "5cc8cf94-2fc3-4492-8876-a629141aa0de",
    "papermill": {
     "duration": 0.084213,
     "end_time": "2021-04-30T00:56:21.425505",
     "exception": false,
     "start_time": "2021-04-30T00:56:21.341292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>category</th>\n",
       "      <th>super_category</th>\n",
       "      <th>super_category_id</th>\n",
       "      <th>normal_category_id</th>\n",
       "      <th>normal_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[561.0, 1238.0, 568.0, 1201.0, 567.0, 1175.0,...</td>\n",
       "      <td>403954.0</td>\n",
       "      <td>[517.0, 127.0, 447.0, 1322.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Glass bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[928.0, 1876.0, 938.0, 1856.0, 968.0, 1826.0,...</td>\n",
       "      <td>1071259.5</td>\n",
       "      <td>[1.0, 457.0, 1429.0, 1519.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Carton</td>\n",
       "      <td>Carton</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Meal carton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[617.0, 383.0, 703.0, 437.0, 713.0, 456.0, 72...</td>\n",
       "      <td>99583.5</td>\n",
       "      <td>[531.0, 292.0, 1006.0, 672.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Carton</td>\n",
       "      <td>Carton</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Other carton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[670.0, 993.0, 679.0, 998.0, 684.0, 1001.0, 6...</td>\n",
       "      <td>73832.5</td>\n",
       "      <td>[632.0, 987.0, 500.0, 374.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Clear plastic bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[647.0, 1028.0, 650.0, 1022.0, 653.0, 1016.0,...</td>\n",
       "      <td>915.0</td>\n",
       "      <td>[632.0, 989.0, 44.0, 51.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottle cap</td>\n",
       "      <td>Bottle cap</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>Plastic bottle cap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  image_id  category_id  \\\n",
       "0   1         0            0   \n",
       "1   2         1            1   \n",
       "2   3         1            1   \n",
       "3   4         2            0   \n",
       "4   5         2            2   \n",
       "\n",
       "                                        segmentation       area  \\\n",
       "0  [[561.0, 1238.0, 568.0, 1201.0, 567.0, 1175.0,...   403954.0   \n",
       "1  [[928.0, 1876.0, 938.0, 1856.0, 968.0, 1826.0,...  1071259.5   \n",
       "2  [[617.0, 383.0, 703.0, 437.0, 713.0, 456.0, 72...    99583.5   \n",
       "3  [[670.0, 993.0, 679.0, 998.0, 684.0, 1001.0, 6...    73832.5   \n",
       "4  [[647.0, 1028.0, 650.0, 1022.0, 653.0, 1016.0,...      915.0   \n",
       "\n",
       "                            bbox  iscrowd    category super_category  \\\n",
       "0  [517.0, 127.0, 447.0, 1322.0]        0      Bottle         Bottle   \n",
       "1   [1.0, 457.0, 1429.0, 1519.0]        0      Carton         Carton   \n",
       "2  [531.0, 292.0, 1006.0, 672.0]        0      Carton         Carton   \n",
       "3   [632.0, 987.0, 500.0, 374.0]        0      Bottle         Bottle   \n",
       "4     [632.0, 989.0, 44.0, 51.0]        0  Bottle cap     Bottle cap   \n",
       "\n",
       "   super_category_id  normal_category_id       normal_category  \n",
       "0                  0                   6          Glass bottle  \n",
       "1                  1                  18           Meal carton  \n",
       "2                  1                  14          Other carton  \n",
       "3                  0                   5  Clear plastic bottle  \n",
       "4                  2                   7    Plastic bottle cap  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:21.551664Z",
     "iopub.status.busy": "2021-04-30T00:56:21.550944Z",
     "iopub.status.idle": "2021-04-30T00:56:21.750329Z",
     "shell.execute_reply": "2021-04-30T00:56:21.750808Z"
    },
    "id": "WbXgBm4tED-i",
    "outputId": "5b6df7e0-802c-4739-c7df-06d6487cba68",
    "papermill": {
     "duration": 0.26618,
     "end_time": "2021-04-30T00:56:21.750939",
     "exception": false,
     "start_time": "2021-04-30T00:56:21.484759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14f3951710>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[\"category\"].value_counts().head(10).plot(kind=\"bar\",title=\"annotations category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:21.873287Z",
     "iopub.status.busy": "2021-04-30T00:56:21.872410Z",
     "iopub.status.idle": "2021-04-30T00:56:22.026125Z",
     "shell.execute_reply": "2021-04-30T00:56:22.026549Z"
    },
    "id": "UxvCar9RED-j",
    "outputId": "f74b7df2-293c-485c-da10-d6b9deba255e",
    "papermill": {
     "duration": 0.215877,
     "end_time": "2021-04-30T00:56:22.026686",
     "exception": false,
     "start_time": "2021-04-30T00:56:21.810809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14f3834890>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[\"super_category\"].value_counts().head(10).plot(kind=\"bar\",title=\"annotations super category distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ut0e6sLmED-k",
    "papermill": {
     "duration": 0.056514,
     "end_time": "2021-04-30T00:56:22.142205",
     "exception": false,
     "start_time": "2021-04-30T00:56:22.085691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:22.312958Z",
     "iopub.status.busy": "2021-04-30T00:56:22.312100Z",
     "iopub.status.idle": "2021-04-30T00:56:22.314873Z",
     "shell.execute_reply": "2021-04-30T00:56:22.314444Z"
    },
    "id": "8ABEczYtTURi",
    "papermill": {
     "duration": 0.11429,
     "end_time": "2021-04-30T00:56:22.314966",
     "exception": false,
     "start_time": "2021-04-30T00:56:22.200676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RepeatedStratifiedGroupKFold():\n",
    "\n",
    "    def __init__(self, n_splits=5, n_repeats=1, random_state=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_repeats = n_repeats\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        k = self.n_splits\n",
    "        def eval_y_counts_per_fold(y_counts, fold):\n",
    "            y_counts_per_fold[fold] += y_counts\n",
    "            std_per_label = []\n",
    "            for label in range(labels_num):\n",
    "                label_std = np.std(\n",
    "                    [y_counts_per_fold[i][label] / y_distr[label] for i in range(k)]\n",
    "                )\n",
    "                std_per_label.append(label_std)\n",
    "            y_counts_per_fold[fold] -= y_counts\n",
    "            return np.mean(std_per_label)\n",
    "            \n",
    "        rnd = check_random_state(self.random_state)\n",
    "        for repeat in range(self.n_repeats):\n",
    "            #print(np.max(y))\n",
    "            labels_num = np.max(y) + 1\n",
    "            y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "            y_distr = Counter()\n",
    "            for label, g in zip(y, groups):\n",
    "                y_counts_per_group[g][label] += 1\n",
    "                y_distr[label] += 1\n",
    "\n",
    "            y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "            groups_per_fold = defaultdict(set)\n",
    "        \n",
    "            groups_and_y_counts = list(y_counts_per_group.items())\n",
    "            rnd.shuffle(groups_and_y_counts)\n",
    "\n",
    "            for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "                best_fold = None\n",
    "                min_eval = None\n",
    "                for i in range(k):\n",
    "                    fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "                    if min_eval is None or fold_eval < min_eval:\n",
    "                        min_eval = fold_eval\n",
    "                        best_fold = i\n",
    "                y_counts_per_fold[best_fold] += y_counts\n",
    "                groups_per_fold[best_fold].add(g)\n",
    "            \n",
    "            all_groups = set(groups)\n",
    "            for i in range(k):\n",
    "                train_groups = all_groups - groups_per_fold[i]\n",
    "                test_groups = groups_per_fold[i]\n",
    "\n",
    "                train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "                test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "                yield train_indices, test_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:22.440417Z",
     "iopub.status.busy": "2021-04-30T00:56:22.439649Z",
     "iopub.status.idle": "2021-04-30T00:56:22.442801Z",
     "shell.execute_reply": "2021-04-30T00:56:22.442326Z"
    },
    "id": "3brGgIm0ED-l",
    "papermill": {
     "duration": 0.069218,
     "end_time": "2021-04-30T00:56:22.442895",
     "exception": false,
     "start_time": "2021-04-30T00:56:22.373677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def kfold_split(config,df):\n",
    "    seed_all()\n",
    "    df[\"folds\"]=-1\n",
    "    #kf = GroupKFold(n_splits=config.general[\"n_folds\"])\n",
    "    kf = RepeatedStratifiedGroupKFold(n_splits=config.general[\"n_folds\"], random_state=config.general[\"seed\"])\n",
    "    #for fold, (_, val_index) in enumerate(kf.split(df,groups=df[\"image_id\"])):\n",
    "    for fold, (_, val_index) in enumerate(kf.split(df,df.category_id, df.image_id)):\n",
    "            df.loc[val_index, \"folds\"] = fold\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:22.569500Z",
     "iopub.status.busy": "2021-04-30T00:56:22.568548Z",
     "iopub.status.idle": "2021-04-30T00:56:30.608399Z",
     "shell.execute_reply": "2021-04-30T00:56:30.607896Z"
    },
    "id": "J3HS1q84ED-l",
    "papermill": {
     "duration": 8.104269,
     "end_time": "2021-04-30T00:56:30.608513",
     "exception": false,
     "start_time": "2021-04-30T00:56:22.504244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_df=kfold_split(annot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:30.725567Z",
     "iopub.status.busy": "2021-04-30T00:56:30.725033Z",
     "iopub.status.idle": "2021-04-30T00:56:30.963461Z",
     "shell.execute_reply": "2021-04-30T00:56:30.964354Z"
    },
    "id": "iP7jcmIKED-l",
    "outputId": "4e027238-31e5-4832-97c8-e83c6c9bcebe",
    "papermill": {
     "duration": 0.300131,
     "end_time": "2021-04-30T00:56:30.964541",
     "exception": false,
     "start_time": "2021-04-30T00:56:30.664410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14f3732210>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]==0][\"category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Test annotations category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:31.182173Z",
     "iopub.status.busy": "2021-04-30T00:56:31.181259Z",
     "iopub.status.idle": "2021-04-30T00:56:31.417785Z",
     "shell.execute_reply": "2021-04-30T00:56:31.416986Z"
    },
    "id": "4_wUBaCAED-n",
    "outputId": "ffcf435d-e0da-4ed1-9a71-91b28db0b7ef",
    "papermill": {
     "duration": 0.337047,
     "end_time": "2021-04-30T00:56:31.417890",
     "exception": false,
     "start_time": "2021-04-30T00:56:31.080843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14e9d28a90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFsCAYAAAA30fmmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3debwcVZn/8c83QcIuRAICAQISgURlMSyiuIEDiLIMIvGHGhAFxoio4wIz4AJmRB1XZlBR0YgIRAWJMCIYWUWWhD0sEiCEECABQSMokvD8/jinSaXTd0nu7aruut/363Vf3XW6us/Tfbufrj51FkUEZmZWL8OqDsDMzAafk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObl3MEm/kTSp6jjKJmm2pDdXHUedSRojKSStlrcH7b0maU9J9xa250raezAeOz+e3x/9IPdzH1yS/lbYXAt4Dliat4+JiHPKj6o8kuYCH4yI3/Vz/x8D8yPipHbG1Q6SjiA91zdUHcvKkjQGeBB4SUQsWYn7BTA2IuasxH3mshLviab7/pgufX9UbbWqA6ibiFincb23N7Wk1VbmQ2VW1Knvn06Na0iKCP+16Q+YC+ydr78ZmA98BngMOBvYALgYWAQ8la+PLtz/StKXA8ARwLXAf+d9HwT266XuE4D7gcXAXcDBhdt6faxc76nAH/L9LwM2LNx+ADAbeDrvu30uPxt4Afg78Dfg07n85/k5/wW4Ghify48Gngf+mff/dYvXbQTwTWBB/vsmMKLpNf13YCHwKHBkIc635+e+GHgE+GQvr9eHgLsLr9fOvb2OwPbAP0i/yv4GPF2I97+BecDjwHeBNQv1fDrHuQD4IBDANvm2lwI/ye+Hh4CTgGGF/9kfgG8Afwa+lC9fXXjsjfJrP6rF8xue43oCeACYnOtercV7bRvgqvz/egI4P5dfne/zTH7Oh9H6ff1m0tF28XNwYn79ngJ+BKxRfC82xRo5hra+P+r+V3kAdf5jxeS+BPhyfkOuCbwMOITUfLMuKQn+qnD/4gfuiPxG/1D+oP5bfjOrh7oPBTYlnVc5LH8gN+nPY+V67wdemeO8Ejgt3/bK/FhvA15CSlZzgNWbn3Mhlg/k59f4IN5auO3HwBd7ed1OAa4nJa5RwHXAqU2v6Sk5lrcDzwIb5NsfBfbM1zcgJ+weXqtHgF0AkRLLlv18HZsT0zeB6cDI/Jx/DXwp37YvKQGOz//zs1k+uf8EuCjfbwzwJ+CoQl1LgONIv7jXBM4Avlyo+3hyAmzxHI8F7gE2z7FdQc/J/VzgP/NzXgN4Q+FxXoy3l/f1m1kxud9ZqPsPjf95D69h8TX5MW16f9T9r/IA6vzHisn9n+Qjlh723xF4qrBd/MAdAcwp3LZW/hC8vJ+x3Aoc2J/HyvWeVLj9w8Cl+frJwLTCbcNIifHNzc+5hzjWz3W9NG/39eG9H3h74bZ9gLmF1/Tv5ASVyxYCu+fr84BjgPX6eG1+Cxy/iq/jtYXbREr+ryiUvQ54MF8/i5zo8/Y2LDtKHU46PzOucPsxwJWFuuY1xbIb8DDLju5nAu/uIe7fA8cWtv+FnpP7T4AzKfyKLNyvVXJf7n1N6+RerPvtwP2tXsPmOtr5/qj7n3vLlGtRRPyjsSFpLUnfk/SQpL+SfvauL2l4D/d/rHElIp7NV9dptaOk90u6VdLTkp4GXgVsuBKP9Vjh+rOF2zYlNRk07vsCKcFs1kMcwyWdJun+/Bzn5ps2bLV/C8vVl69vWth+MpZv4y3GeggpkTwk6SpJr+uhjs1JSaJV/H29jkWjSF+Uswr7X5rLG8/l4cL+xesbAquz4nPdrIf9iYgbSF8mb5K0HelLYnoPsTXX/VAP+0H6NSbgxtwz5QO97AtN7+seNNe9aU87rqSBvD9qzcm9XNG0/e/AtsBuEbEe8MZcroFUImlL4PvAR4CXRcT6pJ/FA3rcbAGwZaEukZLjI7mo+Tn+P+BAYG9Sm/KYxl172L/X+oAtclmfIuKmiDiQ9JP9V8C0HnZ9GHhFc2E/Xsfm2J8gHSmOj4j1899LY9lJ9keB0YX9N2+67/Os+FwfKWy3eq2mAu8F3gf8opck+2hTfVv0sB8R8VhEfCgiNiX9ejhD0jY97d9DXM2a6278D58hfSECIOnlK/nYq/z+qDsn92qtS0oGT0saCXxukB53bdKHYhGApCNJR5yDYRqwv6S9JL2E9AX1HKmtE9JJxK0L+6+bb3+S9CH+r6bHa96/2bnASZJGSdoQ+Czw076ClLS6pMMlvTQingf+yrIuqc1+AHxS0muVbJMTe1+v4+PAaEmrw4u/Yr4PfEPSRvk+m0naJ+8/DThS0vaS1srPhXzfpfn2KZLWzfV/oh/P9WzgYFKC/0kv+00DPipptKQNSCeKW5J0qKTGl9BT+TVovHZ9/b96MjnXPRL4D+D8XH4bMF7SjpLWAD7fdL+2vD+GAif3an2TdALqCdJJoUsH40Ej4i7ga8AfSR+OV5NOYg3GY99LSiSnk+J+J/DOiPhn3uVLpA/b05I+SUo4D5GOQO8iPc+iHwLj8v6/alHlF0ltybcDdwA357L+eB8wNzcHHZvjbvWcfg5MAX5G6hXzK2BkP17H35N6DT0m6Ylc9hnSCebrc72/I/06IyJ+A3ybdDJzTn5cSF9+kE6WPkPqzXJtjues3p5gRMwnvSYBXNPLrt8nnVu4Le9/QS/77gLckMdsTCedj3gw3/Z5YGr+f727t9ia/IzU6+qB/PfFHP+fSCc8fwfcR3reRe18f9SaBzGZVUTS9qRmnhExgL7hks4CFoQH+liBk7tZiSQdDFxCavKZCrwQEQcN4PHGkHrw7FQ4ujZzs4xZyY4hteHfT2rH/rdVfSBJp5KO/L/qxG7NfORuZlZDPnI3M6shJ3czsxrqc1ZISduyrE8qpD6nnyV1cTufNChlLmnY81P5PicCR5HaFD8aEb/trY4NN9wwxowZs/LRm5kNYbNmzXoiIka1um2l2tzzsPhHSHNaTAb+HBGnSTqBNBnPZySNIw0s2JU0DPh3wCvzII2WJkyYEDNnzux3HGZmBpJmRcSEVretbLPMXqQJfx4iDSmfmsunAo3uXAcC50XEc/kM/hxSojczs5KsbHKfSDoqB9g4Ih4FyJcb5fLNWH6SoPm0mFRK0tGSZkqauWjRopUMw8zMetPv5J7nzziANOd4r7u2KFuh7ScizoyICRExYdSolk1GZma2ilbmyH0/4OaIeDxvPy5pE4B8uTCXz2f5GeBG41nazMxKtTLJ/T0sa5KBNKHQpHx9EmkFmUb5REkjJG0FjAVuHGigZmbWf/1aIDtPT/o20tDphtOAaZKOIq14cyhARMyWNI00A+ASYHJvPWXMzGzw9Su555V6XtZU9iSp90yr/aeQplA1M7MKeISqmVkN9evIvROMOeGSAd1/7mn7D1IkZmadz0fuZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY11K/kLml9Sb+QdI+kuyW9TtJISZdLui9fblDY/0RJcyTdK2mf9oVvZmat9PfI/VvApRGxHbADcDdwAjAjIsYCM/I2ksYBE4HxwL7AGZKGD3bgZmbWsz6Tu6T1gDcCPwSIiH9GxNPAgcDUvNtU4KB8/UDgvIh4LiIeBOYAuw524GZm1rP+HLlvDSwCfiTpFkk/kLQ2sHFEPAqQLzfK+28GPFy4//xcZmZmJelPcl8N2Bn4TkTsBDxDboLpgVqUxQo7SUdLmilp5qJFi/oVrJmZ9U9/kvt8YH5E3JC3f0FK9o9L2gQgXy4s7L954f6jgQXNDxoRZ0bEhIiYMGrUqFWN38zMWugzuUfEY8DDkrbNRXsBdwHTgUm5bBJwUb4+HZgoaYSkrYCxwI2DGrWZmfVqtX7udxxwjqTVgQeAI0lfDNMkHQXMAw4FiIjZkqaRvgCWAJMjYumgR25mZj3qV3KPiFuBCS1u2quH/acAUwYQl5mZDYBHqJqZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVUH8X6zBgzAmXDPgx5p62/yBEYmbWOx+5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDfUruUuaK+kOSbdKmpnLRkq6XNJ9+XKDwv4nSpoj6V5J+7QreDMza21ljtzfEhE7RsSEvH0CMCMixgIz8jaSxgETgfHAvsAZkoYPYsxmZtaHgTTLHAhMzdenAgcVys+LiOci4kFgDrDrAOoxM7OV1N/kHsBlkmZJOjqXbRwRjwLky41y+WbAw4X7zs9ly5F0tKSZkmYuWrRo1aI3M7OW+jv9wOsjYoGkjYDLJd3Ty75qURYrFEScCZwJMGHChBVuNzOzVdevI/eIWJAvFwIXkppZHpe0CUC+XJh3nw9sXrj7aGDBYAVsZmZ96zO5S1pb0rqN68C/AHcC04FJebdJwEX5+nRgoqQRkrYCxgI3DnbgZmbWs/40y2wMXCipsf/PIuJSSTcB0yQdBcwDDgWIiNmSpgF3AUuAyRGxtC3Rm5lZS30m94h4ANihRfmTwF493GcKMGXA0ZmZ2SrxCFUzsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGlqtvztKGg7MBB6JiHdIGgmcD4wB5gLvjoin8r4nAkcBS4GPRsRvBznuIW3MCZcM6P5zT9t/kCIxs061MkfuxwN3F7ZPAGZExFhgRt5G0jhgIjAe2Bc4I38xmJlZSfqV3CWNBvYHflAoPhCYmq9PBQ4qlJ8XEc9FxIPAHGDXwQnXzMz6o79H7t8EPg28UCjbOCIeBciXG+XyzYCHC/vNz2VmZlaSPpO7pHcACyNiVj8fUy3KosXjHi1ppqSZixYt6udDm5lZf/TnyP31wAGS5gLnAW+V9FPgcUmbAOTLhXn/+cDmhfuPBhY0P2hEnBkREyJiwqhRowbwFMzMrFmfyT0iToyI0RExhnSi9PcR8V5gOjAp7zYJuChfnw5MlDRC0lbAWODGQY/czMx61O+ukC2cBkyTdBQwDzgUICJmS5oG3AUsASZHxNIBR2pmZv22Usk9Iq4ErszXnwT26mG/KcCUAcZmZmaryCNUzcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIYGMreMDWEDXeoPvNyfWTv5yN3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyG+kzuktaQdKOk2yTNlvSFXD5S0uWS7suXGxTuc6KkOZLulbRPO5+AmZmtqD9H7s8Bb42IHYAdgX0l7Q6cAMyIiLHAjLyNpHHARGA8sC9whqTh7QjezMxa6zO5R/K3vPmS/BfAgcDUXD4VOChfPxA4LyKei4gHgTnAroMatZmZ9apfbe6Shku6FVgIXB4RNwAbR8SjAPlyo7z7ZsDDhbvPz2VmZlaSfiX3iFgaETsCo4FdJb2ql93V6iFW2Ek6WtJMSTMXLVrUv2jNzKxfVqq3TEQ8DVxJakt/XNImAPlyYd5tPrB54W6jgQUtHuvMiJgQERNGjRq1CqGbmVlP+tNbZpSk9fP1NYG9gXuA6cCkvNsk4KJ8fTowUdIISVsBY4EbBztwMzPrWX+W2dsEmJp7vAwDpkXExZL+CEyTdBQwDzgUICJmS5oG3AUsASZHxNL2hG9mZq30mdwj4nZgpxblTwJ79XCfKcCUAUdnZmarxCNUzcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIb6sxKTWccac8IlA7r/3NP2H6RIzDqLj9zNzGrIyd3MrIac3M3Masht7mYDNNB2fxictn+ff7AiH7mbmdVQn8ld0uaSrpB0t6TZko7P5SMlXS7pvny5QeE+J0qaI+leSfu08wmYmdmK+nPkvgT494jYHtgdmCxpHHACMCMixgIz8jb5tonAeGBf4AxJw9sRvJmZtdZnco+IRyPi5nx9MXA3sBlwIDA17zYVOChfPxA4LyKei4gHgTnAroMduJmZ9WylTqhKGgPsBNwAbBwRj0L6ApC0Ud5tM+D6wt3m57LmxzoaOBpgiy22WNm4zawDdcrJZVuJE6qS1gF+CXwsIv7a264tymKFgogzI2JCREwYNWpUf8MwM7N+6Fdyl/QSUmI/JyIuyMWPS9ok374JsDCXzwc2L9x9NLBgcMI1M7P+6E9vGQE/BO6OiK8XbpoOTMrXJwEXFconShohaStgLHDj4IVsZmZ96U+b++uB9wF3SLo1l/0HcBowTdJRwDzgUICImC1pGnAXqafN5IhYOuiRm5lZj/pM7hFxLa3b0QH26uE+U4ApA4jLzMwGwCNUzcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGvMyemdWOlxz0kbuZWS05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ25n7uZWRsMtK89DKy/vY/czcxqyMndzKyGnNzNzGrIyd3MrIb6TO6SzpK0UNKdhbKRki6XdF++3KBw24mS5ki6V9I+7QrczMx61p8j9x8D+zaVnQDMiIixwIy8jaRxwERgfL7PGZKGD1q0ZmbWL30m94i4GvhzU/GBwNR8fSpwUKH8vIh4LiIeBOYAuw5SrGZm1k+r2ua+cUQ8CpAvN8rlmwEPF/abn8vMzKxEg31CVS3KouWO0tGSZkqauWjRokEOw8xsaFvV5P64pE0A8uXCXD4f2Lyw32hgQasHiIgzI2JCREwYNWrUKoZhZmatrGpynw5MytcnARcVyidKGiFpK2AscOPAQjQzs5XV59wyks4F3gxsKGk+8DngNGCapKOAecChABExW9I04C5gCTA5Ipa2KXYzM+tBn8k9It7Tw0179bD/FGDKQIIyM7OB8QhVM7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczq6G2JXdJ+0q6V9IcSSe0qx4zM1tRW5K7pOHA/wL7AeOA90ga1466zMxsRe06ct8VmBMRD0TEP4HzgAPbVJeZmTVRRAz+g0rvAvaNiA/m7fcBu0XERwr7HA0cnTe3Be4dYLUbAk8M8DEGQyfE0QkxQGfE4RiW6YQ4OiEG6Iw4BiOGLSNiVKsbVhvgA/dELcqW+xaJiDOBMwetQmlmREwYrMfr5jg6IYZOicMxdFYcnRBDp8TR7hja1SwzH9i8sD0aWNCmuszMrEm7kvtNwFhJW0laHZgITG9TXWZm1qQtzTIRsUTSR4DfAsOBsyJidjvqKhi0Jp4B6oQ4OiEG6Iw4HMMynRBHJ8QAnRFHW2NoywlVMzOrlkeompnVkJO7mVkNdWVylzRc0lerjqMTSBom6d1Vx9FpJK0nad2q4zCrSlcm94hYCrxWUqv+9ENKRLwAfKTPHUsmae2K6p0g6Q7gduBOSbdJem0VsVRN0sGSXlrYXl/SQVXGNNRJWqO0urr1hKqkrwFjgZ8DzzTKI+KCkuMQcDiwdUScImkL4OURcWOJMZwM/B04n+Vfiz+XFUMhlj2AHwDrRMQWknYAjomID5dU/+3A5Ii4Jm+/ATgjIl5TRv2FOEYAhwBjKPRKi4hTSozh1ojYsanslojYqawYcp2d8FpsDXwLeB3wAvBH4OMR8UBZMeQ45gCPA9cAVwN/iIi/tKOudo1QLcNI4EngrYWyAEpN7sAZpDfLW4FTgMXAL4FdSozhA/lycqEsgK1LjKHhG8A+5HENEXGbpDeWWP/iRmLP9V8raXGJ9TdcBPwFmAU8V0H90PqXeRWf+U54LX5Gmszw4Lw9ETgX2K3MICJim3wAuCfwDuAMSU83fwkPhq5N7hFxZNUxZLtFxM6SbgGIiKfywK3SRMRWZdbXl4h4uKnFbGmJ1d8o6XukD24AhwFXSto5x3ZzSXGMjoh9S6qrJzMlfZ2U1AI4jpRgy9YJr4Ui4uzC9k/zWJxyg5BGA68nJfcdgNnAte2oq2uTu6RXAt8BNo6IV0l6DXBARHyx5FCez1McR45rFOlIvjSS1gI+AWwREUdLGgtsGxEXlxlH9nBumon8JfdR4O4S628cAX2uqXwP0v/orZTjOkmvjog7SqqvleOAk0nNdQIuY/lfd2XphNfiiryuxHks+9K/RNJIKLUJcx5pBP9/RcSx7ayom9vcrwI+BXyv0YYo6c6IeFXJcRxOeqPsDEwF3gWcHBHTSozhfNIR2fvzF92awB/b8VOvH7FsSGrb3JtlCeX4iHiy7FiqJOkuYBvgQVJThIAou+2/E3TCayHpwV5ujogopQkzn4N6A/BGYAvgPuCqiPjhoNfVxcn9pojYpXiCqNUJpJJi2Q7Yi/SmnRERZR6pvji7XNNrcVtE7FBmHJ1C0v7AeODFngllnrzLMWzZqjwiHiqh7m9GxMck/Zqm2VhzDAe0O4ameCp7LTqRpHVICX5P4L2kL5cxg11P1zbLAE9IegXLmkPeBTxadhCSzo6I9wH3tCgryz/z0XrjtXgFJZ+4knQ6LRJJQ0R8tKQ4vgusBbyF1GvnXUBpPZcaGolL0kYUvmRK0mhb/u+S620pIh7KR6x75qJrIuK2MmOQ9P5W5RHxk5LjmAmMAK4jtbW/sV1fct2c3CeTJt7ZTtIjpJ98h1cQx/jiRm5/L7tf9eeBS4HNJZ1DOmFT9gnnmSXX15M9IuI1km6PiC/kLrNl96BC0gHA14BNgYXAlqRzD+N7u99giIjGSdMdI+JbTXEdD1zV7hha1Pkhlv0ffirpzIg4vcQwir3X1iD90r4ZKDW5A/tFxKIyKuraZpmGPFhmWESU2t1N0onAfwBrAs82ioF/At+PiFIXBZf0MmD3HMP1EVHJKjOSDo2In/dV1sb6b4iI3SRdD/wrqbvsnRExtoz6C3HcRjp5+7uI2EnSW4D3RMTRfdx1MGO4OSJ2biqrop/77cDrIuKZvL026ZxQZecf8uCus8tuosp1l9Js2JUjVCElM0nfJg0GuFLSt3KCK0VEfCki1gW+GhHr5b91I+JlFST2GRHxZERcEhEXR8QTkmaUGUPBif0sa5eLJa0PfJV0ZDaX1EOibM/nk8jDJA2LiCtY1pOnrSS9J7e3byVpeuHvStKXXdnE8t1hl9J6tbYyPUsaBFmq3Gx4GKknk4BDSb/qBl03N8ucRxrhdUjePpzU5WvvkuPYtbkgJ9u92l1xHsq8FrChpA1Y9oFZj9QcUBpJ+wFvBzbLX7oN6wFLyoojIk7NV38p6WJgjXaNAOzD0/nE2dXAOZIWUt7rcB3p/NOGpKahhsWkaRnK9iPgBkkX5u2DgLPKDKDp5PIwYBxQWo+2gtKaDbs5uY8sfJABvqgS583IiXVtqk2sxwAfy/XNKsTwV9LAlTItILW7H8DyA2UWAx8vKwhJk4FzIuLpiHhO0lqSPhwRZ5RU/zbAxsCBpCkhPk468NiSdLTWdvkE3UOS9gb+HhEv5HEh2wGl9zWPiK/nXw1vIL1Hj4yIW8qou/D/KJ5cXkJaROiRMmJo8o98+aykTUm/pNozCDEiuvKP9M+aSPoWHga8G/hCifUfz7J+uw8W/m4DPlLya/HRFmUjKvq/fLrVa1Vi/be2KLulxPovBl7TonwC8OuS/xezSL/sNgMeBi4kffGV/Z44uz9ldf9/5HpPBtYntTg8RvqFdUo76uraE6p5vpC1WTYadBjLJs2KiFivpDiOi3LP+reKodWJsxXKKoyltJN4+eTdDpHf2Ln30u0R0fZeKrm+HgfSSbojIl5dRhy5vpsjTY1xHLBmRHylohOqy70n8v/kjogYV0LdnfT/GAbsHhHX5e0RtLHZsGubZSKdzOwEZ0k6iQqG/kt6OemobE1JO7F809Ba7a6/KZb3AP+PfBKvcNO6lHsS77fAtHziKoBjSd1Ey9Jbn/Y1S4sikaTXkZqFjsplpX3miz3KJP21UUzqUVbWGqYd8/+I1Dz2NdLMlETEc7RxPErXJncASf9KascL0sCIX1UQxlmkn7975O35pGmIy5jXZR/gCGA08PVC+WLSh6pMnXIS7zPA0cC/sWz6gx+UWP9Nkj4UEd8vFko6ivIn7Tqe1FPpwoiYrTTt7RVlVR4RX5L0ZeAHEfGBPu/QHp30/wC4TNIhwAWNX5ft0s3NMmeQ5qs4NxcdBtwfEaVOjKQOGPov6ZCI+GVZ9fVF0sYsGzRyY0QsrDKeMuXnfiHp6LSRPCYAqwMHR8RjVcVWFUmzIqKSBVM67f9RaE5eQjq52phnZ9Cbkbv5yP1NwKsKbatTqaAnABUO/Zf03oj4KTBG0ieab4+Ir7e4W7tjOpR0svtK0hv3dEmfiohflB1LFSLicWCPPGip0dZ7SUT8vuxYlGYo/TQrDpgpa2bMhusl7RIRN5Vcb0f9P3I8pTUnd3Nyv5c0q1pjXobNqaYP7+dYcej/ESXV3VjKbp2S6uuPk4BdGkfrOcH8DhgSyb0h0qCl0ppAenAOaezHO0jnHiYBpQx9b/IW4BhJD5E6PZQ+K2SH/D9ajoFp17iYbm6WuYr0078xKdQupKWznoVyZr7LZ7/fBcygA4b+d4LmHgj5NbqtzF4Jud61Iw93H6oazSF5wMxrctlVEfGmkuMY8moKqwcAAA6SSURBVLNCFgYcXgG8meU7P/wmIrYf7Dq7+cj9s1UHkM9+fyTS3O2XlF1/00jQFURJMzE2uVTSb1n+XMj/lVW5Cmu4AqWv4dphns+Xj+b5TBaQTr6XKqqdIbNTNA84bFhMmwYcdu2Re6dQhYtTS5rU2+0RMbXdMbRS6MUk4OqIuLCPuwxm3TeQfk1NjwoXcekEkt5Bmntpc+B00lHiFyJieq93HPw4Ws6QWdbYg04gaRdST7p3RcTp+bN7CGnuo8+3I190bXKXtDvpDbs96cz3cOCZsgYvFeJotcJLREkru3QypVWZnmx3l6+mOhuzQnrhkg6hDpghs2qSbgb2jog/Ky0Yfx5pOoodge0j4l2DXWc3N8v8D2n6gZ+Tuja9nwpmeYsOW5y6KvnL9jTgz8CppAUjNiTNivj+iChrIFHVa7hWTh2ycErB8xHxpKQXZ8jM/d+HkuGFo/PDgDNz9+VfSrq1HRV2c3InIuZIGh4RS4EfSbquijgkvYo0y1yxu1nZiwBU7X9IA6deCvyetCjB9UpLEJ5LeaNEjyWt4boZ6WdwVYtCV6lTFk5pqHKGzE4xXNJqEbGEtFBI8VdLW/JwNyf3Z/OR2a2SvkIaHbl2H/cZdJI+Rzr7PY504nA/0vJZQy25rxYRlwFIOiUirgeIiHuk8qbuzj2VqliRq2M0n2uRtF4qLn1Bm8pnyOwg5wJXSXqC9FpcAy++Rm2ZW6ab29y3BB4ntbd/nHTEeEZEzCk5jjuAHUgzD+6QR8T9ICLeWULdHfPzuzg5VIuJoto+iVknvRadQtIE0lzq65JObj8NfCCWLcPX7vovBv4jIm5vKp8AfK6Mz0gnyU2XmwCXxbJVqV4JrBMRNw92fV155J5nlZsSEe8lDeH9QoXhNObLXpKPkBYCZZ1Mbfz8fj3pl8P5eftQyp83Y4c8OZRYcaKoMrq/dVpTRCc4C/hwRDSOEt9ASvZlDR4a05zYASJipqQxJcXQMRq/ZpvK/tSu+royuUfEUkmjJK0eEf+sOJyZSsu6fZ+UUP/GsoFVbdX4+S3pCOAtEfF83v4uqa25NBExvMz6WtTfeC1aruFaTVSVW9xI7AARcW2e26QsHTMj41DUzc0y3wN2BqazfP/y0udTKcQ0Bliv1dFKm+u9l7QA8Z/z9gakkbLblhlHJ2jVBFRGs1AnkvQN0qjIc0lNVocBTwG/BGhHU0BT/ecCv4/WMzL+S0Qc1s76h7quPHLPFuS/YaQ2xUpIWiFp5MnDHspnxstwGnCLpMbcGW8CPl9S3R1BHbKGa4dpLMj9uabyPUjJvt0TiH0MuFDS4bSYkbHNdQ953XzkvnVEPNABcVxP+gVxO6l9+VX5+suAYxs9SEqI4+XAbnnzhqE2tWyeZmBH4BSWn5piMXBFRDxVSWBG04yMs6uakXGo6ebkfjWpL/NNpP6z10RE6VP+SjoPODUiZuftccCnSAN5LoiIHXu7/yDFIFIXs60j4hRJWwAvj4hS2v47iaRPR8RXmsqOj4hvVRWTWRWGVR3AqoqIN5KmHjgd2AC4RFLb53NpYbtGYs9x3QXsVPKvijNIS3e9J2+3bTKiLjCxRdkRZQdhVrWubXPP3br2zH/rk5a1u6bXO7XHvZK+Q5orAtJJqz8pLX77fM93G1S7RVoI+RaAiHgqD/AaMtQ5a7h2BDUtxmxDT9cmd+AqUt/mLwH/V2GXyCOAD5NOHok0OvWTpMT+lpJieD73/W+sBjUKeKGkujtFp6zh2hGiaTFmG3q6uc19fdLgnTeSFup4AfhjRJxcaWAVyL0RDiOd2J1KmvL2pOb+3kOFhvAarkWSvkD6Ymv7YszWebo2uQNI2p7U7W9PUveueWWtMiNpWkS8O08/sMKLGCUuIZbj2Y40IZGAGRExpGZCbNCKa7juCQyZNVyLtGwx5qWk+UzathizdZ6uTe6S7ieto3oNqSnkhjKbZiTtSfq1ML/ppi2BBWXMcSNpZG+3l7FgSKfJc4e/LZrWcPV87jbUdHOb+9iIqLJd+TOkSZGWWwcyJ5NvAGVMijSL9KuhOO1iYzsob46bTjKsqRnmSbq4V9hAFLrIbhURp0raHNhkKHaRHYq69si9aupl6TY1LRJt5ZH0VdLEWMU1XG+PiM9UF1U1ci+uF4C3RsT2eVqKyyJilz7uajXQzUfuVeuYSZFaHKEN2UFMEfEpLb+G65lR4hquHWbId5EdypzcV91Nkj7Uw6RIZU+3ewb5CI00MnYxaXKoIXmEFhEXABcor+FadTwVchfZIazr2yIlfVnSa/P1b5RY9ceAIyVdKelr+e8q4IPA8SXGAekIbTJpbnvyPCpD6ghN0u75f3GBpJ0k3QncCTwuad+q46vIt4ELgY0kTSF1PPivakOystThyH0m8ClJ40nzzJQiIh4H9miaFOmSiiZF8hFa56zh2jEi4hxJs1jWRfagodpFdijquhOqko4ljUidl7fXBH5OGmZ+aUR8qcr4qlAYxPRa4McMwUFMkm5tTNIm6e6I2L5w2y0RsVN10VUnf+lvTOFArvHZsXrrxiP3yRHxXXhxUYpfAxeQuh/eQJqOYEhpOkKDoXmEVvyl8vem27rrCGaQSDqONJf746SBTI0usqUOsLNqdGNyf4mktUlziPwK+FpE/BRA0lqVRlattYBG08xQXMKs6jVcO9HxwLYRMZRPKg9Z3ZjcvwY8QEpkd5CS/RbAJNKI1SFH0mdJi2L/kpTMfiTp5xHxxWojK0/Va7h2qIeBv1QdhFWj69rc4cV2REhfTl8C9gFuBj4eEU9UFlhFJN1NmkP+H3l7TeDmYruzDR2SPpGvjge2BS4BnmvcXuU6w1aebjxyJyKW5qtLgU/0tu8QMZfU9PCPvD0CuL+yaKxqjTWF5+W/1VnWNbb7juZslXRlcrdE0umkD+tzwGxJl+ftt5H6NNsQFBFfgDRDZnOPqTxrpg0BXdksY4mkSb3dHhFTy4rFOo+kmyNi577KrJ585N7FnLytFUn7AW8HNpP07cJN6wFLqonKyta1yb1w0qjoL8CsiLi17HiqJGks6cTyOArd/iJiKE75a7CANL/RASw/z9Fi4OOVRGSl69pmGUk/AyaQBjEB7E+afmA74OcR8ZWqYiubpGtJg1Ua88gfSfrffq7SwKxSktYBxpDOw9zf6E1lQ0M3J/ffAodExN/y9jrAL4CDSUfv46qMr0ySZkXEa4vzyEu6JiL2rDo2K5+k1UgThB1J6i0zDBgN/Aj4z4h4vsLwrCTdPCvkFkBxWb3ngS0j4u8U+vQOEf+QNAy4T9JHJB0MbFR1UFaZrwIjga0j4rV5Xp1XAOuT1pe1IaCbj9xPJh2lX5SL3glMJ41gPTMiDq8qtrJJ2gW4m/ThPZU0M+JXIuL6SgOzSki6D3hlNH248+C/eyJibDWRWZm6NrkDSJoAvJ405P7aiJhZcUhmlZP0p4h45creZvXStb1lACJipqR55B4ikrYYStOZSvo1vYw4jIgDSgzHOsddkt4fET8pFkp6L3BPRTFZybr2yF3SAaQmmE2BhaQ2+HsiYnylgZVI0pt6uz0iriorFusckjYjTYP9d1JXyCAtubgmcHBEPFJheFaSbk7ut5HWDP1dROyUV0R6T0QcXXFoZh1B0ltJk4cJmB0RMyoOyUrUzcl9ZkRMyEl+p4h4QdKNEbFr1bGVTdLrgc8DW5Ka2gSEBzGZDV3d3Ob+dO7bfg1wjqSFDN2h1T8kjTycRZop08yGuG4+cl+bNMWtgMNJ3f/OGYqrzki6ISJ2qzoOM+scXZvcASS9HNiVdMLopoh4rOKQKiHpNNLKVBew/KIMN1cWlJlVqmuTu6QPAp8Ffk86en8TcEpEnFVpYBWQdEWL4oiIt5YejJl1hG5O7vcCezSaYSS9DLguIratNjIzs+p18wnV+aQpTBsWkxYEHjJaTHscwBOk0boPVhCSmXWIrkvuhYT2CHCDpItISe1A4MbKAqvGui3KxgD/KenzEXFeyfGYWYfoumYZSb3OUd5YP3IokzSSNLjLy6mZDVFdl9ytfyTdkqd6NbMhqJvnc7ce5GHnT1Udh5lVp+va3G0ZSXew4qyQI0lraL6//IjMrFO4WaaLSdqyqSiAJyPimSriMbPO0bXNMpKmSlq/sL2BpCE1gCkiHmr6m+fEbmbQxckdeE1EPN3YiIinAJ9ANDOju5P7MEkbNDZy9z+fQzAzo7uT4deA6yT9Im8fCkypMB4zs47R1SdUJY0jrcYkYEZE3FVxSGZmHaHrkruk9SLir7kZZgUR8eeyYzIz6zTdmNwvjoh3SHqQ5ft4e2k5M7Os65K7mZn1rWt7y0haYSX3VmVmZkNR1/WWkbQGsBawYe4KqXzTesCmlQVmZtZBui65A8cAHyMl8lksS+5/Bf63qqDMzDpJ17a5SzouIk6vOg4zs07UtW3uwGOS1gWQdJKkCyR5cQozM7o7uZ8cEYslvQHYB5gKfKfimMzMOkI3J/el+XJ/4DsRcRGweoXxmJl1jG5O7o9I+h7wbuD/JI2gu5+Pmdmg6eYTqmsB+wJ3RMR9kjYBXh0Rl1UcmplZ5bo2uTdI2ghYo7EdEfMqDMfMrCN0bTOGpAMk3Qc8CFyVL39TbVRmZp2ha5M7cCqwO/CniNgK2Bv4Q7UhmZl1hm5O7s9HxJOkFZmGRcQVwI5VB2Vm1gm6cfqBhqclrQNcDZwjaSGwpOKYzMw6QteeUJW0NvAP0twyhwMvBc7JR/NmZkNa1yZ3MzPrWdc1y0haTFqBqTEbZOPbqbES03qVBGZm1kF85G5mVkPdeOS+BnAssA1wO3BWRPhEqplZQdcduUs6H3geuAbYD3goIo6vNiozs87Sjcn9joh4db6+GnBjRHgedzOzgm4cxPR844qbY8zMWuvGI/elwDONTWBN4FncW8bM7EVdl9zNzKxv3dgsY2ZmfXByNzOrISd3M7MacnI3M6shJ3czsxpycjczq6H/D4tXC6W4XETJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]!=0][\"category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Train annotations category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:31.553014Z",
     "iopub.status.busy": "2021-04-30T00:56:31.552103Z",
     "iopub.status.idle": "2021-04-30T00:56:31.694570Z",
     "shell.execute_reply": "2021-04-30T00:56:31.695014Z"
    },
    "id": "9-jU6eJQED-n",
    "outputId": "be0a3412-e3f6-41b0-f83c-2f6626145584",
    "papermill": {
     "duration": 0.217679,
     "end_time": "2021-04-30T00:56:31.695136",
     "exception": false,
     "start_time": "2021-04-30T00:56:31.477457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14e9c2dc50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]==0][\"super_category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Test annotations super category distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:31.831934Z",
     "iopub.status.busy": "2021-04-30T00:56:31.822390Z",
     "iopub.status.idle": "2021-04-30T00:56:31.972112Z",
     "shell.execute_reply": "2021-04-30T00:56:31.972544Z"
    },
    "id": "3sM5GkMeED-n",
    "outputId": "dd9794d1-b555-4316-d4c0-c6173157f18e",
    "papermill": {
     "duration": 0.217182,
     "end_time": "2021-04-30T00:56:31.972684",
     "exception": false,
     "start_time": "2021-04-30T00:56:31.755502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f14e9bc4350>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFsCAYAAAA30fmmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3debxbVbn/8c+3RWbKYAsyFApaEFAQLIgoTugFRQGvIPADRUUriogTCk4gyBX1oiJeVFSkKoIVQRAcwMrkwFBmyiAoU6HQMmkFhbY8vz/WCt1Nc4aeJHsn+3zfr9d5newhWU92kicra6+9liICMzOrlzFVB2BmZp3n5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDTu4dJuk3kg6sOo6ySZol6TVVx2Hlk/QaSbMLyx17L0jaX9KFheWQ9IJOPHZ+vH9J2qRTj9dL5H7u6QUuLK4MPAUsysvvj4jTy4+qPJLuBt4bEb8f5v6nAbMj4rPdjGs0kXQ08IKIOKDqWJZVTuQ/iYgNluE+k4C7gOdExMJluF8AkyPizmUME0mXkOL8/rLetx8tV3UAvSAiVm3cHizRSVpuWd6IVm91eT/06vPo1bj6RkT4r/AH3A28Pt9+DTAb+BTwIPBjYE3gfGAe8Fi+vUHh/peQvhwA3gX8EfjfvO9dwBsHKfsI4G/AfOAW4K2FbYM+Vi73WOBP+f4XAuML23cHZgGP5303z+t/DDwD/Bv4F/DJvP7n+Tn/A7gM2DKvnwosAJ7O+/+qxXFbAfgG8ED++wawQtMx/TgwF5gDvLsQ55vyc58P3A98YoBj9QLg0hzfw8DP8vpJQADLDfKa/Ak4Kd/3NmDnwr6rAz/Icd0PfBEY23TfrwOPAl9sEddY4NOF1/EaYGLediJwH/DPvH6nvH7XfDwX5GN6wzBiGQuckJ/7XcCHis8bWA84L8d5J/C+QoxHA2cBP8mxfBZ4EnhuYZ+Xkt7jz2nxHFcCTiO9D28BDif9kmv1GdoemJnLeQj4Wl5/b473X/nv5a2Ob173x8JjB/Bh4O/5uX8VGFN4Xj8p7PvsewE4jvRr/D+5vG8VHu8FheP9o/y878nHZUzhtR/2Z7kX/ioPoNf+WDq5LwS+TEpYKwHPBd5Gar5ZjZQEf1m4/yUsmUgWAO/LH8YPkJKdBih77/yhHAPsAzwBrDucx8rl/g3YNMd5CXB83rZpfqw3AM8BPkn6wC/f/JwLsbwnP79Gor6+sO00mhJb03E7BrgCWBuYAPwZOLbpmB6TY3kTKbGsmbfPYXHSWxPYdoBjdQbwmXysVgRemddPYujkvhD4aC5/H1KSXytv/yXwXWCVHP9VpKa54n0PJSWMlVrEdThwE7AZIGBrctIEDiC9f5Yjfbk9CKyYtx1NITENI5aDSYl1g3ycfs+Syf1S4OR8bF5CSlg7F8paAOyZj99KwK+BDxTK/jpw0gDH/njgcmAtYCJwMwMn978A78i3VwV2GOR1Wur40jq5X5zL3hD4a+G1XeIYNpdRfB80PV4juf8IOJf0vp+UH/ugkXyWe+Gv8gB67Y+lk/vTjQ/gAPu/BHissPzsGyi/Ie4sbFs5v5meN8xYrgf2GM5j5XI/W9j+QeC3+fbngOmFbWNINcHXND/nAeJYI5e1el4+jcGT+9+ANxW27QLcXTim/276UM9l8Yf+XuD9wLghjs2PgFMo/GrK65f4QA/wmizxoSQlzXcA65DOt6xU2LYfcHHhvvcOEdftjddsGK/vY8DW+fbRLJmYhorlD+REn5dfz+Ja6kRSLXW1wvYvAacVyrqsKZZ9gD/l22NJXzzbDxD334FdC8tTGTi5XwZ8gcKvyEFep6WOL62Te7HsDwIzBjiGS5TBIMk9P+engC0K294PXNKJz3IVf+4tM7R5EfGfxoKklSV9V9I9kv5JevOuIWnsAPd/sHEjIp7MN1dttaOkd0q6XtLjkh4HXgSMX4bHerBw+8nCtvVIPzMb932G1Dyw/gBxjJV0vKS/5ed4d940vtX+LSxRXr69XmH5kViyLbUY69tItfl7JF0q6eUDlPFJUs34qtw74z3DjA3g/sif0Kb4NiLV5ucUXoPvkmrNDfcN8dgTSV9uS5H0cUm3SvpHfuzVGfiYDhXLek2xFG+vBzwaEfObnuP6A+wPqca6Re458gbgHxFx1QCxNZd9zwD7ARxE+uV4m6SrJb15kH1bxTXUPs3vrZEaDyzP0u/b4jEb9me5Fzi5Dy2alj9O+sn9sogYB7wqr1c7hUjaCPgeqe30uRGxBunnbluPmz1AShaNskRKQvfnVc3P8f8Be5Bqg6uTakAUYmnef9DySD+fHxhOoBFxdUTsQUpivwSmD7DfgxHxvohYj1TDOjl3kXsi77JyYffnNd19/XwMmuO7j1R7Gx8Ra+S/cRGxZbHoIZ7CfcDzm1dK2ol07ubtpCaoNUjNQQMd06FimUNqkmmYWLj9ALCWpNWanuP9heUlyssVmOnA/qRfMT8e5DnOaSpvw4F2jIg7ImI/0uv5ZeAsSas0lz9QXANoLrvx3nqCwV/3wR77YVKzS/P79v7Wu/c+J/dltxqpWeFxSWsBR3XocRtv+HkAkt5Nqrl3wnRgN0k7S3oO6QvqKVJbOKQTXcW+vqvl7Y+QPiz/0/R4zfs3OwP4rKQJksYDnyedvBuUpOVzv+bVI2IB6STcogH23VtSI7k9Rjp2iyJiHukDeUD+BfIelk62awMflvQcSXsDmwO/jog5pBPRJ0gaJ2mMpOdLevVQsRd8HzhW0mQlW0l6LumYLiS9vstJ+jwwrnC/h4BJksYADCOW6cBhktaXtAbpi4N83/tIr+2XJK0oaStSDXqoLr0/IjU/7M7gr9d04EhJa+bX4NCBdpR0gKQJ+dfi43n1onwcnmHw99FADs9lTwQOA36W118PvErShpJWB45sut+A79uIWJSf13GSVsuVrY8xjPdtr3JyX3bfIJ3oeZh00vC3nXjQiLiF1PvhL6Q34YtJPQc68di3k07mnUSK+y3AWyLi6bzLl0jJ+HFJnyB9yO8hJclbSM+z6Aekn/CPS/pliyK/SOohcSPp5OK1ed1wvAO4OzcHHZzjbmU74Mp8jcJ5wGERcVfe9j7Sic1HgC1Z/CXWcCUwmXQsjgP2iohH8rZ3kn6e30L60jgLWHeYsQN8jZQkLiR9Of2A9H75HfAb0km6e0i9NorNCz/P/x+RdO0wYvleLuNG4DrSCdGFLP4y3I/0i+sB4BzgqIi4aLDAI+JPpIR7bUTcPciuX8jP4a4cw2C1/F2BWfl1OhHYNyL+k5s1jgP+lN9HOwwWW5NzSb2NrgcuIB1j8vP7GemYXEPqyVZ0IrCXpMckfbPF4x5Kqv3/ndQz5qfAqcsQV0/xRUw2qkh6F+mk2iurjqWTJL0R+E5EbDTkzoM/zh+An8YoudCnzlxzN+tDklaS9CZJy0lan9Q8eE6bj7kdsC2Lmzmsjzm5m/UnkZpHHiM1y9xKOrcxsgeTppH6yn+kqZeN9Sk3y5iZ1ZBr7mZmNeTkbmZWQz0xKuT48eNj0qRJVYdhZtZXrrnmmocjYkKrbT2R3CdNmsTMmTOrDsPMrK9IGnDoBzfLmJnVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkN9cRFTMMx6YgL2rr/3cfv1qFIzMx6n2vuZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZDQyZ3SadKmivp5qb1h0q6XdIsSV8prD9S0p152y7dCNrMzAY3nCtUTwO+BfyosULSa4E9gK0i4ilJa+f1WwD7AlsC6wG/l7RpRCzqdOBmZjawIWvuEXEZ8GjT6g8Ax0fEU3mfuXn9HsCZEfFURNwF3Als38F4zcxsGEba5r4psJOkKyVdKmm7vH594L7CfrPzuqVImipppqSZ8+bNG2EYZmbWykiT+3LAmsAOwOHAdEkC1GLfaPUAEXFKREyJiCkTJkwYYRhmZtbKSJP7bODsSK4CngHG5/UTC/ttADzQXohmZrasRprcfwm8DkDSpsDywMPAecC+klaQtDEwGbiqE4GamdnwDdlbRtIZwGuA8ZJmA0cBpwKn5u6RTwMHRkQAsyRNB24BFgKHuKeMmVn5hkzuEbHfAJsOGGD/44Dj2gnKzMza4ytUzcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGpoyOQu6VRJc/PEHM3bPiEpJI0vrDtS0p2Sbpe0S6cDNjOzoQ2n5n4asGvzSkkTgTcA9xbWbQHsC2yZ73OypLEdidTMzIZtyOQeEZcBj7bY9HXgk0AU1u0BnBkRT0XEXcCdwPadCNTMzIZvRG3uknYH7o+IG5o2rQ/cV1iendeZmVmJhpxDtZmklYHPAP/VanOLddFiHZKmAlMBNtxww2UNw8zMBjGSmvvzgY2BGyTdDWwAXCvpeaSa+sTCvhsAD7R6kIg4JSKmRMSUCRMmjCAMMzMbyDIn94i4KSLWjohJETGJlNC3jYgHgfOAfSWtIGljYDJwVUcjNjOzIQ2nK+QZwF+AzSTNlnTQQPtGxCxgOnAL8FvgkIhY1KlgzcxseIZsc4+I/YbYPqlp+TjguPbCMjOzdvgKVTOzGnJyNzOroWXuCjmaTTrigrYf4+7jd+tAJGZmg3PN3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIac3M3Mamg4k3WcKmmupJsL674q6TZJN0o6R9IahW1HSrpT0u2SdulW4GZmNrDh1NxPA3ZtWncR8KKI2Ar4K3AkgKQtgH2BLfN9TpY0tmPRmpnZsAyZ3CPiMuDRpnUXRsTCvHgFaSJsgD2AMyPiqYi4C7gT2L6D8ZqZ2TB0os39PcBv8u31gfsK22bndWZmVqK2krukzwALgdMbq1rsFgPcd6qkmZJmzps3r50wzMysyYiTu6QDgTcD+0dEI4HPBiYWdtsAeKDV/SPilIiYEhFTJkyYMNIwzMyshREld0m7Ap8Cdo+IJwubzgP2lbSCpI2BycBV7YdpZmbLYsg5VCWdAbwGGC9pNnAUqXfMCsBFkgCuiIiDI2KWpOnALaTmmkMiYlG3gjczs9aGTO4RsV+L1T8YZP/jgOPaCcrMzNrjK1TNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIac3M3MasjJ3cyshpzczcxqyMndzKyGnNzNzGrIyd3MrIaGHPLXes+kIy5o6/53H79bhyIxs17lmruZWQ0NmdwlnSpprqSbC+vWknSRpDvy/zUL246UdKek2yXt0q3AzcxsYMOpuZ8G7Nq07ghgRkRMBmbkZSRtAewLbJnvc7KksR2L1szMhmXI5B4RlwGPNq3eA5iWb08D9iysPzMinoqIu4A7ge07FKuZmQ3TSNvc14mIOQD5/9p5/frAfYX9Zud1S5E0VdJMSTPnzZs3wjDMzKyVTp9QVYt10WrHiDglIqZExJQJEyZ0OAwzs9FtpMn9IUnrAuT/c/P62cDEwn4bAA+MPDwzMxuJkSb384AD8+0DgXML6/eVtIKkjYHJwFXthWhmZstqyIuYJJ0BvAYYL2k2cBRwPDBd0kHAvcDeABExS9J04BZgIXBIRCzqUuxmZjaAIZN7ROw3wKadB9j/OOC4doIyM7P2+ApVM7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxryHKo2Iu3O4wqey9Wsm1xzNzOrISd3M7MacnI3M6shJ3czsxpycjczq6G2krukj0qaJelmSWdIWlHSWpIuknRH/r9mp4I1M7PhGXFyl7Q+8GFgSkS8CBgL7AscAcyIiMnAjLxsZmYlardZZjlgJUnLASuTJsPeA5iWt08D9myzDDMzW0YjTu4RcT/wv6Q5VOcA/4iIC4F1ImJO3mcOsHYnAjUzs+Frp1lmTVItfWNgPWAVSQcsw/2nSpopaea8efNGGoaZmbXQTrPM64G7ImJeRCwAzgZ2BB6StC5A/j+31Z0j4pSImBIRUyZMmNBGGGZm1qyd5H4vsIOklSUJ2Bm4FTgPODDvcyBwbnshmpnZshrxwGERcaWks4BrgYXAdcApwKrAdEkHkb4A9u5EoGZmNnxtjQoZEUcBRzWtfopUizczs4r4ClUzsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrobaSu6Q1JJ0l6TZJt0p6uaS1JF0k6Y78f81OBWtmZsPTbs39ROC3EfFCYGvSHKpHADMiYjIwIy+bmVmJRpzcJY0DXgX8ACAino6Ix4E9gGl5t2nAnu0GaWZmy6admvsmwDzgh5Kuk/R9SasA60TEHID8f+1Wd5Y0VdJMSTPnzZvXRhhmZtasneS+HLAt8O2I2AZ4gmVogomIUyJiSkRMmTBhQhthmJlZs3aS+2xgdkRcmZfPIiX7hyStC5D/z20vRDMzW1bLjfSOEfGgpPskbRYRtwM7A7fkvwOB4/P/czsSqVkLk464oK373338bh2KxKy3jDi5Z4cCp0taHvg78G7Sr4Hpkg4C7gX2brMMMzNbRm0l94i4HpjSYtPO7TyumZm1p92au9mo127TEHSmechNVFbk4QfMzGrIyd3MrIac3M3MasjJ3cyshnxC1cw6pldOLptr7mZmteTkbmZWQ07uZmY15ORuZlZDTu5mZjXk5G5mVkNO7mZmNeTkbmZWQ07uZmY11HZylzQ2T5B9fl5eS9JFku7I/9dsP0wzM1sWnai5HwbcWlg+ApgREZOBGSzDpNlmZtYZbSV3SRsAuwHfL6zeA5iWb08D9mynDDMzW3bt1ty/AXwSeKawbp2ImAOQ/6/d6o6SpkqaKWnmvHnz2gzDzMyKRpzcJb0ZmBsR14zk/hFxSkRMiYgpEyZMGGkYZmbWQjtD/r4C2F3Sm4AVgXGSfgI8JGndiJgjaV1gbicCNTMbLs8n20bNPSKOjIgNImISsC/wh4g4ADgPODDvdiBwbttRmpnZMulGP/fjgTdIugN4Q142M7MSdWQmpoi4BLgk334E2LkTj2tmZiPjK1TNzGrIyd3MrIac3M3Maqgjbe5mZrakdrtjQntdMl1zNzOrISd3M7MacnI3M6shJ3czsxpycjczqyEndzOzGnJyNzOrISd3M7MacnI3M6shJ3czsxpycjczq6F25lCdKOliSbdKmiXpsLx+LUkXSboj/1+zc+GamdlwtFNzXwh8PCI2B3YADpG0BXAEMCMiJgMz8rKZmZWonTlU50TEtfn2fOBWYH1gD2Ba3m0asGe7QZqZ2bLpSJu7pEnANsCVwDoRMQfSFwCwdifKMDOz4Ws7uUtaFfgF8JGI+Ocy3G+qpJmSZs6bN6/dMMzMrKCt5C7pOaTEfnpEnJ1XPyRp3bx9XWBuq/tGxCkRMSUipkyYMKGdMMzMrEk7vWUE/AC4NSK+Vth0HnBgvn0gcO7IwzMzs5FoZ5q9VwDvAG6SdH1e92ngeGC6pIOAe4G92wvRzMyW1YiTe0T8EdAAm3ce6eOamVn7fIWqmVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1ZCTu5lZDTm5m5nVkJO7mVkNObmbmdWQk7uZWQ05uZuZ1VDXkrukXSXdLulOSUd0qxwzM1taV5K7pLHA/wFvBLYA9pO0RTfKMjOzpXWr5r49cGdE/D0ingbOBPboUllmZtZEEdH5B5X2AnaNiPfm5XcAL4uIDxX2mQpMzYubAbe3Wex44OE2H6MTeiGOXogBeiMOx7BYL8TRCzFAb8TRiRg2iogJrTaMeILsIbSaOHuJb5GIOAU4pWMFSjMjYkqnHq+f4+iFGHolDsfQW3H0Qgy9Eke3Y+hWs8xsYGJheQPggS6VZWZmTbqV3K8GJkvaWNLywL7AeV0qy8zMmnSlWSYiFkr6EPA7YCxwakTM6kZZBR1r4mlTL8TRCzFAb8ThGBbrhTh6IQbojTi6GkNXTqiamVm1fIWqmVkNObmbmdVQXyZ3SWMlfbXqOHqBpDGS3l51HL1G0jhJq1Udh1lV+jK5R8Qi4KWSWvWnH1Ui4hngQ0PuWDJJq1RU7hRJNwE3AjdLukHSS6uIpWqS3ipp9cLyGpL2rDKm0U7SiqWV1a8nVCWdAEwGfg480VgfEWeXHIeA/YFNIuIYSRsCz4uIq0qM4XPAv4GfseSxeLSsGAqx7Ah8H1g1IjaUtDXw/oj4YEnl3wgcEhGX5+VXAidHxFZllF+IYwXgbcAkCr3SIuKYEmO4PiJe0rTuuojYpqwYcpm9cCw2AU4EXg48A/wF+GhE/L2sGHIcdwIPAZcDlwF/ioh/dKOsbl2hWoa1gEeA1xXWBVBqcgdOJr1ZXgccA8wHfgFsV2IM78n/DymsC2CTEmNo+DqwC/m6hoi4QdKrSix/fiOx5/L/KGl+ieU3nAv8A7gGeKqC8qH1L/MqPvO9cCx+ShrM8K15eV/gDOBlZQYRES/IFcCdgDcDJ0t6vPlLuBP6NrlHxLurjiF7WURsK+k6gIh4LF+4VZqI2LjM8oYSEfc1tZgtKrH4qyR9l/TBDWAf4BJJ2+bYri0pjg0iYteSyhrITElfIyW1AA4lJdiy9cKxUET8uLD8k3wtTrlBSBsAryAl962BWcAfu1FW3yZ3SZsC3wbWiYgXSdoK2D0ivlhyKAvyEMeR45pAqsmXRtLKwMeADSNiqqTJwGYRcX6ZcWT35aaZyF9yHwZuLbH8Rg3oqKb1O5Jeo9dRjj9LenFE3FRSea0cCnyO1Fwn4EKW/HVXll44FhfneSXOZPGX/gWS1oJSmzDvJV3B/z8RcXA3C+rnNvdLgcOB7zbaECXdHBEvKjmO/UlvlG2BacBewOciYnqJMfyMVCN7Z/6iWwn4Szd+6g0jlvGkts3XszihHBYRj5QdS5Uk3QK8ALiL1BQhIMpu++8FvXAsJN01yOaIiFKaMPM5qFcCrwI2BO4ALo2IH3S8rD5O7ldHxHbFE0StTiCVFMsLgZ1Jb9oZEVFmTfXZ0eWajsUNEbF1mXH0Ckm7AVsCz/ZMKPPkXY5ho1brI+KeEsr+RkR8RNKvaBqNNcewe7djaIqnsmPRiyStSkrwOwEHkL5cJnW6nL5tlgEelvR8FjeH7AXMKTsIST+OiHcAt7VYV5anc229cSyeT8knriSdRItE0hARHy4pju8AKwOvJfXa2QsoredSQyNxSVqbwpdMSRpty/9bcrktRcQ9uca6U151eUTcUGYMkt7Zan1E/KjkOGYCKwB/JrW1v6pbX3L9nNwPIQ2880JJ95N+8u1fQRxbFhdy+3vZ/aqPBn4LTJR0OumETdknnGeWXN5AdoyIrSTdGBFfyF1my+5BhaTdgROA9YC5wEakcw9bDna/ToiIxknTl0TEiU1xHQZc2u0YWpT5Pha/Dj+RdEpEnFRiGMXeayuSfmlfC5Sa3IE3RsS8Mgrq22aZhnyxzJiIKLW7m6QjgU8DKwFPNlYDTwPfi4hSJwWX9FxghxzDFRFRySwzkvaOiJ8Pta6L5V8ZES+TdAXw36TusjdHxOQyyi/EcQPp5O3vI2IbSa8F9ouIqUPctZMxXBsR2zatq6Kf+43AyyPiiby8CumcUGXnH/LFXT8uu4kql11Ks2FfXqEKKZlJ+ibpYoBLJJ2YE1wpIuJLEbEa8NWIGJf/VouI51aQ2GdExCMRcUFEnB8RD0uaUWYMBUcOc123nC9pDeCrpJrZ3aQeEmVbkE8ij5E0JiIuZnFPnq6StF9ub99Y0nmFv0tIX3ZlE0t2h11E69nayvQk6SLIUuVmw31IPZkE7E36Vddx/dwscybpCq+35eX9SV2+Xl9yHNs3r8jJduduF5wvZV4ZGC9pTRZ/YMaRmgNKI+mNwJuA9fOXbsM4YGFZcUTEsfnmLySdD6zYrSsAh/B4PnF2GXC6pLmUdxz+TDr/NJ7UNNQwnzQsQ9l+CFwp6Zy8vCdwapkBNJ1cHgNsAZTWo62gtGbDfk7uaxU+yABfVInjZuTEugrVJtb3Ax/J5V1TiOGfpAtXyvQAqd19d5a8UGY+8NGygpB0CHB6RDweEU9JWlnSByPi5JLKfwGwDrAHaUiIj5IqHhuRamtdl0/Q3SPp9cC/I+KZfF3IC4HS+5pHxNfyr4ZXkt6j746I68oou/B6FE8uLyRNInR/GTE0+U/+/6Sk9Ui/pLpzEWJE9OUf6cXal/QtPAZ4O/CFEss/jMX9du8q/N0AfKjkY/HhFutWqOh1+WSrY1Vi+de3WHddieWfD2zVYv0U4FclvxbXkH7ZrQ/cB5xD+uIr+z3x4+Gsq/vrkcv9HLAGqcXhQdIvrGO6UVbfnlDN44WswuKrQceweNCsiIhxJcVxaJR71r9VDK1OnC21rsJYSjuJl0/ebR35jZ17L90YEV3vpZLLG/BCOkk3RcSLy4gjl3dtpKExDgVWioivVHRCdYn3RH5NboqILUoou5dejzHADhHx57y8Al1sNuzbZplIJzN7wamSPksFl/5Leh6pVraSpG1Ysmlo5W6X3xTLfsD/I5/EK2xajXJP4v0OmJ5PXAVwMKmbaFkG69O+UmlRJJL0clKz0EF5XWmf+WKPMkn/bKwm9Sgraw7Tnnk9IjWPnUAamZKIeIouXo/St8kdQNJ/k9rxgnRhxC8rCONU0s/fHfPybNIwxGWM67IL8C5gA+BrhfXzSR+qMvXKSbxPAVOBD7B4+IPvl1j+1ZLeFxHfK66UdBDlD9p1GKmn0jkRMUtp2NuLyyo8Ir4k6cvA9yPiPUPeoTt66fUAuFDS24CzG78uu6Wfm2VOJo1XcUZetQ/wt4godWAk9cCl/5LeFhG/KKu8oUhah8UXjVwVEXOrjFQ5VcYAAA/LSURBVKdM+bmfQ6qdNpLHFGB54K0R8WBVsVVF0jURUcmEKb32ehSakxeSTq42xtnpeDNyP9fcXw28qNC2Oo0KegJQ4aX/kg6IiJ8AkyR9rHl7RHytxd26HdPepJPdl5DeuCdJOjwizio7lipExEPAjvmipUZb7wUR8YeyY1EaofSTLH3BTFkjYzZcIWm7iLi65HJ76vXI8ZTWnNzPyf120qhqjXEZJlJNH96jWPrS/3eVVHZjKrtVSypvOD4LbNeorecE83tgVCT3hkgXLZXWBDKA00nXfryZdO7hQKCUS9+bvBZ4v6R7SJ0eSh8Vskdej5bXwHTruph+bpa5lPTTvzEo1HakqbOehHJGvstnv/cCZtADl/73guYeCPkY3VBmr4Rc7iqRL3cfrRrNIfmCma3yuksj4tUlxzHqR4UsXHB4MfAaluz88JuI2LzTZfZzzf3zVQeQz35/KNLY7ReUXX7TlaBLiZJGYmzyW0m/Y8lzIb8uq3AV5nAFSp/DtccsyP/n5PFMHiCdfC9VVDtCZq9ovuCwYT5duuCwb2vuvUIVTk4t6cDBtkfEtG7H0EqhF5OAyyLinCHu0smyryT9mjovKpzEpRdIejNp7KWJwEmkWuIXIuK8Qe/Y+ThajpBZ1rUHvUDSdqSedHtFxEn5s/s20thHR3cjX/Rtcpe0A+kNuznpzPdY4ImyLl4qxNFqhpeIkmZ26WVKszI90u0uX01lNkaF9MQlPUI9MEJm1SRdC7w+Ih5VmjD+TNJwFC8BNo+IvTpdZj83y3yLNPzAz0ldm95JBaO8RY9NTl2V/GV7PPAocCxpwojxpFER3xkRZV1IVPUcrpVTj0ycUrAgIh6R9OwImbn/+2gytlA73wc4JXdf/oWk67tRYD8ndyLiTkljI2IR8ENJf64iDkkvIo0yV+xuVvYkAFX7FunCqdWBP5AmJbhCaQrCMyjvKtGDSXO4rk/6GVzVpNBV6pWJUxqqHCGzV4yVtFxELCRNFFL81dKVPNzPyf3JXDO7XtJXSFdHrjLEfTpO0lGks99bkE4cvpE0fdZoS+7LRcSFAJKOiYgrACLiNqm8obtzT6UqZuTqGc3nWiSNS6tLn9Cm8hEye8gZwKWSHiYdi8vh2WPUlbFl+rnNfSPgIVJ7+0dJNcaTI+LOkuO4CdiaNPLg1vmKuO9HxFtKKLtnfn4XB4dqMVBU1wcx66Vj0SskTSGNpb4a6eT248B7YvE0fN0u/3zg0xFxY9P6KcBRZXxGekluulwXuDAWz0q1KbBqRFzb6fL6suaeR5U7LiIOIF3C+4UKw2mMl70w15DmAmWdTG38/H4F6ZfDz/Ly3pQ/bsbWeXAosfRAUWV0f+u1pohecCrwwYho1BJfSUr2ZV08NKk5sQNExExJk0qKoWc0fs02rftrt8rry+QeEYskTZC0fEQ8XXE4M5WmdfseKaH+i8UXVnVV4+e3pHcBr42IBXn5O6S25tJExNgyy2tRfuNYtJzDtZqoKje/kdgBIuKPeWyTsvTMiIyjUT83y3wX2BY4jyX7l5c+nkohpknAuFa1lS6XeztpAuJH8/KapCtlNyszjl7QqgmojGahXiTp66SrIs8gNVntAzwG/AKgG00BTeWfAfwhWo/I+F8RsU83yx/t+rLmnj2Q/8aQ2hQrIWmppJEHD7snnxkvw/HAdZIaY2e8Gji6pLJ7gnpkDtce05iQ+6im9TuSkn23BxD7CHCOpP1pMSJjl8se9fq55r5JRPy9B+K4gvQL4kZS+/KL8u3nAgc3epCUEMfzgJflxStH29CyeZiBlwDHsOTQFPOBiyPisUoCM5pGZJxV1YiMo00/J/fLSH2Zryb1n708Ikof8lfSmcCxETErL28BHE66kOfsiHjJYPfvUAwidTHbJCKOkbQh8LyIKKXtv5dI+mREfKVp3WERcWJVMZlVYUzVAYxURLyKNPTAScCawAWSuj6eSwsvbCT2HNctwDYl/6o4mTR11355uWuDEfWBfVuse1fZQZhVrW/b3HO3rp3y3xqkae0uH/RO3XG7pG+TxoqAdNLqr0qT3y4Y+G4d9bJIEyFfBxARj+ULvEYN9c4crj1BTZMx2+jTt8kduJTUt/lLwK8r7BL5LuCDpJNHIl2d+glSYn9tSTEsyH3/G7NBTQCeKansXtErc7j2hGiajNlGn35uc1+DdPHOq0gTdTwD/CUiPldpYBXIvRH2IZ3YnUYa8vazzf29RwuN4jlciyR9gfTF1vXJmK339G1yB5C0Oanb306k7l33ljXLjKTpEfH2PPzAUgcxSpxCLMfzQtKARAJmRMSoGgmxQUvP4boTMGrmcC3S4smYF5HGM+naZMzWe/o2uUv6G2ke1ctJTSFXltk0I2kn0q+F2U2bNgIeKGOMG0lrDba9jAlDek0eO/wN0TSHq8dzt9Gmn9vcJ0dEle3KnyINirTEPJA5mXwdKGNQpGtIvxqKwy42loPyxrjpJWOammEeoY97hbWj0EV244g4VtJEYN3R2EV2NOrbmnvVNMjUbWqaJNrKI+mrpIGxinO43hgRn6ouqmrkXlzPAK+LiM3zsBQXRsR2Q9zVaqCfa+5V65lBkVrU0EbtRUwRcbiWnMP1lChxDtceM+q7yI5mTu4jd7Wk9w0wKFLZw+2eTK6hka6MnU8aHGpU1tAi4mzgbOU5XKuOp0LuIjuK9X1bpKQvS3ppvv31Eov+CPBuSZdIOiH/XQq8FzisxDgg1dAOIY1tTx5HZVTV0CTtkF+LsyVtI+lm4GbgIUm7Vh1fRb4JnAOsLek4UseD/6k2JCtLHWruM4HDJW1JGmemFBHxELBj06BIF1Q0KJJraL0zh2vPiIjTJV3D4i6ye47WLrKjUd+dUJV0MOmK1Hvz8krAz0mXmf82Ir5UZXxVKFzE9FLgNEbhRUySrm8M0ibp1ojYvLDtuojYprroqpO/9NehUJFrfHas3vqx5n5IRHwHnp2U4lfA2aTuh1eShiMYVZpqaDA6a2jFXyr/btrWXzWYDpF0KGks94dIFzI1usiWeoGdVaMfk/tzJK1CGkPkl8AJEfETAEkrVxpZtVYGGk0zo3EKs6rncO1FhwGbRcRoPqk8avVjcj8B+Dspkd1ESvYbAgeSrlgddSR9njQp9i9IyeyHkn4eEV+sNrLyVD2Ha4+6D/hH1UFYNfquzR2ebUeE9OX0JWAX4FrgoxHxcGWBVUTSraQx5P+Tl1cCri22O9voIelj+eaWwGbABcBTje1VzjNs5enHmjsRsSjfXAR8bLB9R4m7SU0P/8nLKwB/qywaq1pjTuF789/yLO4a23+1ORuRvkzulkg6ifRhfQqYJemivPwGUp9mG4Ui4guQRshs7jGVR820UaAvm2UskXTgYNsjYlpZsVjvkXRtRGw71DqrJ9fc+5iTt7Ui6Y3Am4D1JX2zsGkcsLCaqKxsfZvcCyeNiv4BXBMR15cdT5UkTSadWN6CQre/iBiNQ/4aPEAa32h3lhznaD7w0UoistL1bbOMpJ8CU0gXMQHsRhp+4IXAzyPiK1XFVjZJfyRdrNIYR/7dpNf2qEoDs0pJWhWYRDoP87dGbyobHfo5uf8OeFtE/CsvrwqcBbyVVHvfosr4yiTpmoh4aXEceUmXR8ROVcdm5ZO0HGmAsHeTesuMATYAfgh8JiIWVBielaSfR4XcEChOq7cA2Cgi/k2hT+8o8R9JY4A7JH1I0luBtasOyirzVWAtYJOIeGkeV+f5wBqk+WVtFOjnmvvnSLX0c/OqtwDnka5gPSUi9q8qtrJJ2g64lfThPZY0MuJXIuKKSgOzSki6A9g0mj7c+eK/2yJicjWRWZn6NrkDSJoCvIJ0yf0fI2JmxSGZVU7SXyNi02XdZvXSt71lACJipqR7yT1EJG04moYzlfQrBrniMCJ2LzEc6x23SHpnRPyouFLSAcBtFcVkJevbmruk3UlNMOsBc0lt8LdFxJaVBlYiSa8ebHtEXFpWLNY7JK1PGgb736SukEGacnEl4K0RcX+F4VlJ+jm530CaM/T3EbFNnhFpv4iYWnFoZj1B0utIg4cJmBURMyoOyUrUz8l9ZkRMyUl+m4h4RtJVEbF91bGVTdIrgKOBjUhNbQLCFzGZjV793Ob+eO7bfjlwuqS5jN5Lq39AuvLwGtJImWY2yvVzzX0V0hC3AvYndf87fTTOOiPpyoh4WdVxmFnv6NvkDiDpecD2pBNGV0fEgxWHVAlJx5NmpjqbJSdluLayoMysUn2b3CW9F/g88AdS7f3VwDERcWqlgVVA0sUtVkdEvK70YMysJ/Rzcr8d2LHRDCPpucCfI2KzaiMzM6teP59QnU0awrRhPmlC4FGjxbDHATxMulr3rgpCMrMe0XfJvZDQ7geulHQuKantAVxVWWDVWK3FuknAZyQdHRFnlhyPmfWIvmuWkTToGOWN+SNHM0lrkS7u8nRqZqNU3yV3Gx5J1+WhXs1sFOrn8dxtAPmy88eqjsPMqtN3be62mKSbWHpUyLVIc2i+s/yIzKxXuFmmj0naqGlVAI9ExBNVxGNmvaNvm2UkTZO0RmF5TUmj6gKmiLin6e9eJ3Yzgz5O7sBWEfF4YyEiHgN8AtHMjP5O7mMkrdlYyN3/fA7BzIz+ToYnAH+WdFZe3hs4rsJ4zMx6Rl+fUJW0BWk2JgEzIuKWikMyM+sJfZfcJY2LiH/mZpilRMSjZcdkZtZr+jG5nx8Rb5Z0F0v28fbUcmZmWd8ldzMzG1rf9paRtNRM7q3WmZmNRn3XW0bSisDKwPjcFVJ50zhgvcoCMzPrIX2X3IH3Ax8hJfJrWJzc/wn8X1VBmZn1kr5tc5d0aEScVHUcZma9qG/b3IEHJa0GIOmzks6W5MkpzMzo7+T+uYiYL+mVwC7ANODbFcdkZtYT+jm5L8r/dwO+HRHnAstXGI+ZWc/o5+R+v6TvAm8Hfi1pBfr7+ZiZdUw/n1BdGdgVuCki7pC0LvDiiLiw4tDMzCrXt8m9QdLawIqN5Yi4t8JwzMx6Qt82Y0jaXdIdwF3Apfn/b6qNysysN/RtcgeOBXYA/hoRGwOvB/5UbUhmZr2hn5P7goh4hDQj05iIuBh4SdVBmZn1gn4cfqDhcUmrApcBp0uaCyysOCYzs57QtydUJa0C/Ic0tsz+wOrA6bk2b2Y2qvVtcjczs4H1XbOMpPmkGZgao0E2vp0aMzGNqyQwM7Me4pq7mVkN9WPNfUXgYOAFwI3AqRHhE6lmZgV9V3OX9DNgAXA58Ebgnog4rNqozMx6Sz8m95si4sX59nLAVRHhcdzNzAr68SKmBY0bbo4xM2utH2vui4AnGovASsCTuLeMmdmz+i65m5nZ0PqxWcbMzIbg5G5mVkNO7mZmNeTkbmZWQ07uZmY15ORuZlZD/x94kESkADw5awAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_df[annot_df[\"folds\"]==0][\"super_category\"].value_counts().head(10).plot(kind=\"bar\",title=\"Train annotations super category distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C1dlvNlED-n",
    "papermill": {
     "duration": 0.060367,
     "end_time": "2021-04-30T00:56:32.095373",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.035006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:32.231671Z",
     "iopub.status.busy": "2021-04-30T00:56:32.230882Z",
     "iopub.status.idle": "2021-04-30T00:56:32.233840Z",
     "shell.execute_reply": "2021-04-30T00:56:32.233401Z"
    },
    "id": "I1wuP7ZpED-o",
    "papermill": {
     "duration": 0.0783,
     "end_time": "2021-04-30T00:56:32.233941",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.155641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def register_dataset(config,fold):\n",
    "    train_dataset_name=f\"my_dataset_train_{fold}\"\n",
    "    test_dataset_name=f\"my_dataset_test_{fold}\"\n",
    "    train_dataset_file=f\"my_dataset_train_{fold}.json\"\n",
    "    test_dataset_file=f\"my_dataset_test_{fold}.json\"\n",
    "    \n",
    "    train_annot_df=annot_df[annot_df[\"folds\"]!=fold]\n",
    "    test_annot_df=annot_df[annot_df[\"folds\"]==fold]\n",
    "    train_annot_df=train_annot_df.drop([\"normal_category\",\"normal_category_id\"],axis=1)\n",
    "    test_annot_df=test_annot_df.drop([\"normal_category\",\"normal_category_id\"],axis=1)\n",
    "\n",
    "    train_images_df=images_df[images_df[\"id\"].apply(lambda i:True if i in list(train_annot_df[\"image_id\"].unique()) else False)]\n",
    "    test_images_df=images_df[images_df[\"id\"].apply(lambda i:True if i in list(test_annot_df[\"image_id\"].unique()) else False)]\n",
    "    \n",
    "    train_annot=annot.copy()\n",
    "    test_annot=annot.copy()\n",
    "    \n",
    "    train_annot[\"annotations\"]=train_annot_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    train_annot[\"images\"]=train_images_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    test_annot[\"annotations\"]=test_annot_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    test_annot[\"images\"]=test_images_df.reset_index(drop=True).to_dict(\"records\")\n",
    "    \n",
    "    json.dump(train_annot,open(train_dataset_file,\"w\"))\n",
    "    json.dump(test_annot,open(test_dataset_file,\"w\"))\n",
    "    \n",
    "    if train_dataset_name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(train_dataset_name)\n",
    "        MetadataCatalog.remove(train_dataset_name)\n",
    "    if test_dataset_name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(test_dataset_name)\n",
    "        MetadataCatalog.remove(test_dataset_name)\n",
    "        \n",
    "    register_coco_instances(train_dataset_name, {}, train_dataset_file, os.path.join(DATASET_PATH,\"data\"))\n",
    "    register_coco_instances(test_dataset_name, {}, test_dataset_file, os.path.join(DATASET_PATH,\"data\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3AeKe2eED-o",
    "papermill": {
     "duration": 0.059585,
     "end_time": "2021-04-30T00:56:32.353463",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.293878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess and augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:32.489813Z",
     "iopub.status.busy": "2021-04-30T00:56:32.488990Z",
     "iopub.status.idle": "2021-04-30T00:56:32.491845Z",
     "shell.execute_reply": "2021-04-30T00:56:32.491408Z"
    },
    "id": "tFNeqTcXED-p",
    "papermill": {
     "duration": 0.07851,
     "end_time": "2021-04-30T00:56:32.491941",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.413431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def get_train_transforms(config):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.1, sat_shift_limit= 0.1, \n",
    "                                     val_shift_limit=0.1, p=0.8),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.3, \n",
    "                                           contrast_limit=0.2, p=0.8),\n",
    "            ],p=0.7),\n",
    "            A.Rotate (limit=15, interpolation=1, border_mode=4, value=None, mask_value=None, p=0.8),\n",
    "            \n",
    "            \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomResizedCrop (config.preprocess.height, config.preprocess.width, scale=(0.8, 0.8), ratio=(0.75, 1.3333333333333333), interpolation=1, always_apply=False, p=0.1),\n",
    "            A.OneOf([\n",
    "            A.Resize(height=config.preprocess.height, width=config.preprocess.width, p=0.2),\n",
    "            A.LongestMaxSize(max_size=config.preprocess.longest_max_size, p=0.2),\n",
    "            A.SmallestMaxSize(max_size=config.preprocess.smallest_max_size, p=0.2),\n",
    "                \n",
    "            ], p=1),\n",
    "            A.CLAHE(clip_limit=[1,4],p=1),\n",
    "            \n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='coco',\n",
    "            min_area=0.5, \n",
    "            min_visibility=0.5,\n",
    "            label_fields=['category_id']\n",
    "        )\n",
    "    )\n",
    "\n",
    "@inject_config\n",
    "def get_valid_transforms(config):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.SmallestMaxSize(max_size=config.preprocess.smallest_max_size, p=1.0),\n",
    "            A.CLAHE(clip_limit=[3,3],p=1),   \n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='coco',\n",
    "            min_area=0.5, \n",
    "            min_visibility=0.5,\n",
    "            label_fields=['category_id']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_transforms(train=True):\n",
    "    if (train):\n",
    "        return get_train_transforms()\n",
    "    return get_valid_transforms()\n",
    "albu_transformations=get_transforms(train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHP92WtLGeOG",
    "papermill": {
     "duration": 0.059675,
     "end_time": "2021-04-30T00:56:32.612205",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.552530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Personal mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:32.755196Z",
     "iopub.status.busy": "2021-04-30T00:56:32.754418Z",
     "iopub.status.idle": "2021-04-30T00:56:32.758318Z",
     "shell.execute_reply": "2021-04-30T00:56:32.757838Z"
    },
    "id": "MbnJvmRmED-r",
    "papermill": {
     "duration": 0.086036,
     "end_time": "2021-04-30T00:56:32.758410",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.672374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PersonalMapper (detectron2.data.DatasetMapper):\n",
    "    \"\"\"\n",
    "    Define a detectron2 personal mapper in order to be able to use albumentation augmentations\n",
    "    \"\"\"\n",
    "    def __call__(self, dataset_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.\n",
    "\n",
    "        Returns:\n",
    "            dict: a format that builtin models in detectron2 accept\n",
    "        \"\"\"\n",
    "        dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "        # USER: Write your own image loading if it's not from a file\n",
    "        image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n",
    "        #utils.check_image_size(dataset_dict, image)\n",
    "\n",
    "        \n",
    "        \n",
    "        ##### ADDED PART\n",
    "\n",
    "        #print(\"dataset dict : \",dataset_dict)\n",
    "\n",
    "        annos = [\n",
    "            obj for obj in dataset_dict[\"annotations\"]\n",
    "        ]\n",
    "        annos_bbox = [\n",
    "            obj[\"bbox\"] for obj in dataset_dict[\"annotations\"]\n",
    "        ]\n",
    "        annos_categroy_id = [\n",
    "            obj[\"category_id\"] for obj in dataset_dict.pop(\"annotations\")\n",
    "        ]\n",
    "        \n",
    "        if albu_transformations is not None:\n",
    "            transform_list=get_transforms(self.is_train)\n",
    "            image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            transform_result=transform_list(image=image,bboxes=annos_bbox,category_id=annos_categroy_id)\n",
    "            image=cv2.cvtColor(transform_result[\"image\"], cv2.COLOR_RGB2BGR)\n",
    "            annos=[annos[i] for i in range(len(transform_result[\"bboxes\"]))]\n",
    "            for i in range(len(annos)):\n",
    "                annos[i][\"bbox\"]=list(transform_result[\"bboxes\"][i])\n",
    "                annos[i][\"category_id\"]=transform_result[\"category_id\"][i]\n",
    "        \n",
    "        dataset_dict[\"annotations\"]=annos\n",
    "        \n",
    "        \n",
    "        ##### ADDED PART\n",
    "        \n",
    "        # USER: Remove if you don't do semantic/panoptic segmentation.\n",
    "        if \"sem_seg_file_name\" in dataset_dict:\n",
    "            sem_seg_gt = utils.read_image(dataset_dict.pop(\"sem_seg_file_name\"), \"L\").squeeze(2)\n",
    "        else:\n",
    "            sem_seg_gt = None\n",
    "\n",
    "        aug_input = T.AugInput(image, sem_seg=sem_seg_gt)\n",
    "        transforms = self.augmentations(aug_input)\n",
    "        image, sem_seg_gt = aug_input.image, aug_input.sem_seg\n",
    "\n",
    "        image_shape = image.shape[:2]  # h, w\n",
    "        # Pytorch's dataloader is efficient on torch.Tensor due to shared-memory,\n",
    "        # but not efficient on large generic data structures due to the use of pickle & mp.Queue.\n",
    "        # Therefore it's important to use torch.Tensor.\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))\n",
    "        if sem_seg_gt is not None:\n",
    "            dataset_dict[\"sem_seg\"] = torch.as_tensor(sem_seg_gt.astype(\"long\"))\n",
    "\n",
    "        # USER: Remove if you don't use pre-computed proposals.\n",
    "        # Most users would not need this feature.\n",
    "        if self.proposal_topk is not None:\n",
    "            utils.transform_proposals(\n",
    "                dataset_dict, image_shape, transforms, proposal_topk=self.proposal_topk\n",
    "            )\n",
    "\n",
    "        if not self.is_train:\n",
    "            # USER: Modify this if you want to keep them for some reason.\n",
    "            dataset_dict.pop(\"annotations\", None)\n",
    "            dataset_dict.pop(\"sem_seg_file_name\", None)\n",
    "            return dataset_dict\n",
    "\n",
    "        if \"annotations\" in dataset_dict:\n",
    "            # USER: Modify this if you want to keep them for some reason.\n",
    "            for anno in dataset_dict[\"annotations\"]:\n",
    "                if not self.use_instance_mask:\n",
    "                    anno.pop(\"segmentation\", None)\n",
    "                if not self.use_keypoint:\n",
    "                    anno.pop(\"keypoints\", None)\n",
    "\n",
    "            # USER: Implement additional transformations if you have other types of data\n",
    "            annos = [\n",
    "                utils.transform_instance_annotations(\n",
    "                    obj, transforms, image_shape, keypoint_hflip_indices=self.keypoint_hflip_indices\n",
    "                )\n",
    "                for obj in dataset_dict.pop(\"annotations\")\n",
    "                if obj.get(\"iscrowd\", 0) == 0\n",
    "            ]\n",
    "            instances = utils.annotations_to_instances(\n",
    "                annos, image_shape, mask_format=self.instance_mask_format\n",
    "            )\n",
    "\n",
    "            # After transforms such as cropping are applied, the bounding box may no longer\n",
    "            # tightly bound the object. As an example, imagine a triangle object\n",
    "            # [(0,0), (2,0), (0,2)] cropped by a box [(1,0),(2,2)] (XYXY format). The tight\n",
    "            # bounding box of the cropped triangle should be [(1,0),(2,1)], which is not equal to\n",
    "            # the intersection of original bounding box and the cropping box.\n",
    "            if self.recompute_boxes:\n",
    "                instances.gt_boxes = instances.gt_masks.get_bounding_boxes()\n",
    "            dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "        return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uguNAheFED-v",
    "papermill": {
     "duration": 0.060412,
     "end_time": "2021-04-30T00:56:32.878952",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.818540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:33.012025Z",
     "iopub.status.busy": "2021-04-30T00:56:33.011259Z",
     "iopub.status.idle": "2021-04-30T00:56:33.015212Z",
     "shell.execute_reply": "2021-04-30T00:56:33.014763Z"
    },
    "id": "ENHtg1FBED-v",
    "papermill": {
     "duration": 0.075962,
     "end_time": "2021-04-30T00:56:33.015310",
     "exception": false,
     "start_time": "2021-04-30T00:56:32.939348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PersonalTrainer (detectron2.engine.defaults.DefaultTrainer):\n",
    "    \"\"\"\n",
    "    Personal trainer based on detectron2 DefaultTrainer to add some hooks and change data loaders\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg , config=c):\n",
    "        super().__init__(cfg)\n",
    "        self.metric=0\n",
    "        self.checkpointer.save_dir=MODELS_PATH\n",
    "\n",
    "        \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        def save_best_model():\n",
    "            \n",
    "            metric=self.test(self.cfg, self.model)[\"bbox\"][\"AP50\"]\n",
    "            if(metric>self.metric):\n",
    "                self.metric=metric\n",
    "                self.checkpointer.save(\"best_model\") # it will add .pth alone\n",
    "                \n",
    "        steps_per_epoch=annot_df.shape[0]//c.model[\"images_per_batch\"]\n",
    "        model_checkpointer=EvalHook(steps_per_epoch, save_best_model)\n",
    "        hooks.insert(-1,model_checkpointer)\n",
    "        return hooks\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        \n",
    "        #return build_detection_train_loader(cfg,mapper=DatasetMapper(cfg,is_train=True,))\n",
    "        return build_detection_train_loader(cfg,mapper=PersonalMapper(cfg,is_train=True,augmentations=[]))\n",
    "    @classmethod\n",
    "    def build_test_loader(cls, cfg, dataset_name):\n",
    "        \n",
    "        #return build_detection_test_loader( cfg,dataset_name,mapper=DatasetMapper(cfg,is_train=False,))\n",
    "        return build_detection_test_loader( cfg,dataset_name,mapper=PersonalMapper(cfg,is_train=False,augmentations=[]))\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        return COCOEvaluator(dataset_name, (\"bbox\",), False, output_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rBP7049ED-w",
    "papermill": {
     "duration": 0.060041,
     "end_time": "2021-04-30T00:56:33.137194",
     "exception": false,
     "start_time": "2021-04-30T00:56:33.077153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare config params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:33.271653Z",
     "iopub.status.busy": "2021-04-30T00:56:33.270826Z",
     "iopub.status.idle": "2021-04-30T00:56:33.273168Z",
     "shell.execute_reply": "2021-04-30T00:56:33.273631Z"
    },
    "id": "9ytbXLftED-w",
    "papermill": {
     "duration": 0.075989,
     "end_time": "2021-04-30T00:56:33.273756",
     "exception": false,
     "start_time": "2021-04-30T00:56:33.197767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@inject_config\n",
    "def get_config(config,fold=0):\n",
    "    \"\"\"\n",
    "    Detectron2 config\n",
    "    \"\"\"\n",
    "    steps_per_epoch=annot_df.shape[0]//config.model[\"images_per_batch\"]\n",
    "    train_dataset_name=f\"my_dataset_train_{fold}\"\n",
    "    test_dataset_name=f\"my_dataset_test_{fold}\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.MODEL.DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-Detection/{config.model['model_name']}.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
    "    cfg.DATASETS.TEST = (test_dataset_name,)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-Detection/{config.model['model_name']}.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = config.model[\"images_per_batch\"]\n",
    "    cfg.SOLVER.BASE_LR = config.model[\"base_lr\"]  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = steps_per_epoch*config.model[\"epochs\"]  # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "    cfg.SOLVER.STEPS = (steps_per_epoch*8,)\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = config.model[\"batchsize_per_image\"]   # faster, and good enough for this toy dataset (default: 512)\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = config.model[\"num_classes\"]  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "    cfg.TEST.EVAL_PERIOD=0\n",
    "    cfg.OUTPUT_DIR = LOGS_PATH\n",
    "    cfg.OUTPUT_DIR_BEST = LOGS_PATH\n",
    "    cfg.SOLVER.AMP.ENABLED = True\n",
    "    cfg.MODEL.WEIGHTS = \"../input/trash-detection-part-1/models/best_model.pth\"\n",
    "\n",
    "    cfg.SEED = config.general[\"seed\"]\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(cfg.OUTPUT_DIR_BEST, exist_ok=True)\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:33.401106Z",
     "iopub.status.busy": "2021-04-30T00:56:33.400284Z",
     "iopub.status.idle": "2021-04-30T00:56:33.416926Z",
     "shell.execute_reply": "2021-04-30T00:56:33.416465Z"
    },
    "id": "QTymd5RxED-w",
    "papermill": {
     "duration": 0.082069,
     "end_time": "2021-04-30T00:56:33.417019",
     "exception": false,
     "start_time": "2021-04-30T00:56:33.334950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg=get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqG_5mO6ED-w",
    "papermill": {
     "duration": 0.062129,
     "end_time": "2021-04-30T00:56:33.539477",
     "exception": false,
     "start_time": "2021-04-30T00:56:33.477348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:33.667095Z",
     "iopub.status.busy": "2021-04-30T00:56:33.666292Z",
     "iopub.status.idle": "2021-04-30T00:56:33.669092Z",
     "shell.execute_reply": "2021-04-30T00:56:33.668666Z"
    },
    "id": "t-dS-_KiED-w",
    "papermill": {
     "duration": 0.06886,
     "end_time": "2021-04-30T00:56:33.669184",
     "exception": false,
     "start_time": "2021-04-30T00:56:33.600324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    \"\"\"\n",
    "    train function that help train on the dataset and validate on a certain fold\n",
    "    \"\"\"\n",
    "    seed_all()\n",
    "    register_dataset(fold)\n",
    "    cfg=get_config(fold)\n",
    "    #trainer = DefaultTrainer(cfg)\n",
    "    trainer = PersonalTrainer(cfg) \n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.evaluator = COCOEvaluator(f\"my_dataset_test_{fold}\", (\"bbox\",), False, output_dir=None)\n",
    "    trainer.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T00:56:33.802643Z",
     "iopub.status.busy": "2021-04-30T00:56:33.801827Z",
     "iopub.status.idle": "2021-04-30T09:00:23.331162Z",
     "shell.execute_reply": "2021-04-30T09:00:23.331623Z"
    },
    "id": "9UNwptwrED-x",
    "outputId": "c6dddf10-ec92-4a7a-ff1d-5f456666468b",
    "papermill": {
     "duration": 29029.602285,
     "end_time": "2021-04-30T09:00:23.331816",
     "exception": false,
     "start_time": "2021-04-30T00:56:33.729531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/30 00:56:40 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=30, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=116, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/30 00:56:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 00:56:40 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 00:56:40 d2.data.datasets.coco]: \u001b[0mLoaded 1190 images in COCO format from my_dataset_train_0.json\n",
      "\u001b[32m[04/30 00:56:40 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1190 images left.\n",
      "\u001b[32m[04/30 00:56:40 d2.data.build]: \u001b[0mDistribution of instances among all 28 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|    Bottle     | 350          |    Carton     | 200          |  Bottle cap   | 231          |\n",
      "|      Can      | 218          |    Pop tab    | 79           |      Cup      | 153          |\n",
      "| Plastic bag.. | 678          | Styrofoam p.. | 88           | Other plastic | 218          |\n",
      "| Plastic con.. | 57           |     Paper     | 117          |      Lid      | 69           |\n",
      "|     Straw     | 128          |   Paper bag   | 20           | Broken glass  | 111          |\n",
      "| Plastic ute.. | 29           |   Glass jar   | 4            |  Food waste   | 6            |\n",
      "| Squeezable .. | 5            |     Shoe      | 5            | Aluminium f.. | 49           |\n",
      "| Unlabeled l.. | 412          | Blister pack  | 5            |    Battery    | 1            |\n",
      "| Rope & stri.. | 23           |   Cigarette   | 533          |  Scrap metal  | 14           |\n",
      "| Plastic glo.. | 3            |               |              |               |              |\n",
      "|     total     | 3806         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[04/30 00:56:40 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/30 00:56:40 d2.data.common]: \u001b[0mSerializing 1190 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 00:56:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.80 MiB\n",
      "\u001b[32m[04/30 00:56:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/30 00:57:48 d2.utils.events]: \u001b[0m eta: 7:42:49  iter: 19  total_loss: 0.1536  loss_cls: 0.08112  loss_box_reg: 0.0523  loss_rpn_cls: 0.008821  loss_rpn_loc: 0.01864  time: 2.6180  data_time: 0.1911  lr: 7.9924e-06  max_mem: 9676M\n",
      "\u001b[32m[04/30 00:58:42 d2.utils.events]: \u001b[0m eta: 7:39:37  iter: 39  total_loss: 0.1551  loss_cls: 0.07175  loss_box_reg: 0.04519  loss_rpn_cls: 0.00757  loss_rpn_loc: 0.03009  time: 2.6455  data_time: 0.0134  lr: 1.5984e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 00:59:35 d2.utils.events]: \u001b[0m eta: 7:38:34  iter: 59  total_loss: 0.1875  loss_cls: 0.09311  loss_box_reg: 0.05404  loss_rpn_cls: 0.00932  loss_rpn_loc: 0.02171  time: 2.6463  data_time: 0.0155  lr: 2.3976e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:00:28 d2.utils.events]: \u001b[0m eta: 7:37:50  iter: 79  total_loss: 0.1757  loss_cls: 0.0687  loss_box_reg: 0.06762  loss_rpn_cls: 0.005706  loss_rpn_loc: 0.03614  time: 2.6457  data_time: 0.0133  lr: 3.1968e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:01:19 d2.utils.events]: \u001b[0m eta: 7:36:51  iter: 99  total_loss: 0.1364  loss_cls: 0.06717  loss_box_reg: 0.04075  loss_rpn_cls: 0.003407  loss_rpn_loc: 0.009227  time: 2.6297  data_time: 0.0136  lr: 3.996e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:02:12 d2.utils.events]: \u001b[0m eta: 7:36:14  iter: 119  total_loss: 0.1812  loss_cls: 0.08696  loss_box_reg: 0.06411  loss_rpn_cls: 0.006494  loss_rpn_loc: 0.01708  time: 2.6355  data_time: 0.0137  lr: 4.7952e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:03:05 d2.utils.events]: \u001b[0m eta: 7:35:59  iter: 139  total_loss: 0.2023  loss_cls: 0.08907  loss_box_reg: 0.05688  loss_rpn_cls: 0.00796  loss_rpn_loc: 0.02142  time: 2.6332  data_time: 0.0145  lr: 5.5944e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:04:00 d2.utils.events]: \u001b[0m eta: 7:37:20  iter: 159  total_loss: 0.1999  loss_cls: 0.09552  loss_box_reg: 0.07244  loss_rpn_cls: 0.005755  loss_rpn_loc: 0.01807  time: 2.6522  data_time: 0.0174  lr: 6.3936e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:04:50 d2.utils.events]: \u001b[0m eta: 7:34:17  iter: 179  total_loss: 0.1579  loss_cls: 0.07316  loss_box_reg: 0.05246  loss_rpn_cls: 0.006679  loss_rpn_loc: 0.02372  time: 2.6346  data_time: 0.0137  lr: 7.1928e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:05:42 d2.utils.events]: \u001b[0m eta: 7:32:48  iter: 199  total_loss: 0.1408  loss_cls: 0.06843  loss_box_reg: 0.04928  loss_rpn_cls: 0.004246  loss_rpn_loc: 0.01192  time: 2.6275  data_time: 0.0135  lr: 7.992e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:06:33 d2.utils.events]: \u001b[0m eta: 7:32:00  iter: 219  total_loss: 0.1434  loss_cls: 0.06428  loss_box_reg: 0.05091  loss_rpn_cls: 0.005066  loss_rpn_loc: 0.01701  time: 2.6221  data_time: 0.0133  lr: 8.7912e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:07:25 d2.utils.events]: \u001b[0m eta: 7:31:09  iter: 239  total_loss: 0.1138  loss_cls: 0.05812  loss_box_reg: 0.04324  loss_rpn_cls: 0.003602  loss_rpn_loc: 0.01111  time: 2.6212  data_time: 0.0143  lr: 9.5904e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:08:17 d2.utils.events]: \u001b[0m eta: 7:30:07  iter: 259  total_loss: 0.1925  loss_cls: 0.08806  loss_box_reg: 0.0688  loss_rpn_cls: 0.007012  loss_rpn_loc: 0.01673  time: 2.6189  data_time: 0.0170  lr: 0.0001039  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:09:09 d2.utils.events]: \u001b[0m eta: 7:28:59  iter: 279  total_loss: 0.1852  loss_cls: 0.08386  loss_box_reg: 0.06541  loss_rpn_cls: 0.003611  loss_rpn_loc: 0.01401  time: 2.6163  data_time: 0.0149  lr: 0.00011189  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:10:00 d2.utils.events]: \u001b[0m eta: 7:27:49  iter: 299  total_loss: 0.1597  loss_cls: 0.06893  loss_box_reg: 0.04323  loss_rpn_cls: 0.004798  loss_rpn_loc: 0.01966  time: 2.6139  data_time: 0.0190  lr: 0.00011988  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:10:51 d2.utils.events]: \u001b[0m eta: 7:26:58  iter: 319  total_loss: 0.1604  loss_cls: 0.0626  loss_box_reg: 0.05083  loss_rpn_cls: 0.00411  loss_rpn_loc: 0.01158  time: 2.6092  data_time: 0.0330  lr: 0.00012787  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:11:47 d2.utils.events]: \u001b[0m eta: 7:26:47  iter: 339  total_loss: 0.1827  loss_cls: 0.08506  loss_box_reg: 0.06181  loss_rpn_cls: 0.007189  loss_rpn_loc: 0.02561  time: 2.6208  data_time: 0.0303  lr: 0.00013586  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:12:42 d2.utils.events]: \u001b[0m eta: 7:26:01  iter: 359  total_loss: 0.1665  loss_cls: 0.07026  loss_box_reg: 0.05782  loss_rpn_cls: 0.004907  loss_rpn_loc: 0.01522  time: 2.6269  data_time: 0.0318  lr: 0.00014386  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:13:33 d2.utils.events]: \u001b[0m eta: 7:25:08  iter: 379  total_loss: 0.2007  loss_cls: 0.0987  loss_box_reg: 0.06986  loss_rpn_cls: 0.008504  loss_rpn_loc: 0.01823  time: 2.6221  data_time: 0.0288  lr: 0.00015185  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:14:25 d2.utils.events]: \u001b[0m eta: 7:24:45  iter: 399  total_loss: 0.186  loss_cls: 0.08948  loss_box_reg: 0.06626  loss_rpn_cls: 0.004582  loss_rpn_loc: 0.01766  time: 2.6219  data_time: 0.0301  lr: 0.00015984  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:15:16 d2.utils.events]: \u001b[0m eta: 7:23:53  iter: 419  total_loss: 0.1477  loss_cls: 0.06547  loss_box_reg: 0.05825  loss_rpn_cls: 0.005501  loss_rpn_loc: 0.01241  time: 2.6182  data_time: 0.0293  lr: 0.00016783  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:16:10 d2.utils.events]: \u001b[0m eta: 7:24:33  iter: 439  total_loss: 0.1587  loss_cls: 0.08812  loss_box_reg: 0.05859  loss_rpn_cls: 0.004412  loss_rpn_loc: 0.01137  time: 2.6229  data_time: 0.0334  lr: 0.00017582  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:17:08 d2.utils.events]: \u001b[0m eta: 7:24:48  iter: 459  total_loss: 0.1631  loss_cls: 0.08009  loss_box_reg: 0.06164  loss_rpn_cls: 0.006742  loss_rpn_loc: 0.01659  time: 2.6333  data_time: 0.0305  lr: 0.00018382  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:18:00 d2.utils.events]: \u001b[0m eta: 7:23:33  iter: 479  total_loss: 0.1356  loss_cls: 0.0634  loss_box_reg: 0.04572  loss_rpn_cls: 0.005077  loss_rpn_loc: 0.01924  time: 2.6328  data_time: 0.0323  lr: 0.00019181  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:18:54 d2.utils.events]: \u001b[0m eta: 7:22:39  iter: 499  total_loss: 0.1447  loss_cls: 0.07278  loss_box_reg: 0.0468  loss_rpn_cls: 0.003594  loss_rpn_loc: 0.01136  time: 2.6342  data_time: 0.0281  lr: 0.0001998  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:19:48 d2.utils.events]: \u001b[0m eta: 7:21:47  iter: 519  total_loss: 0.1581  loss_cls: 0.07778  loss_box_reg: 0.0574  loss_rpn_cls: 0.006157  loss_rpn_loc: 0.02149  time: 2.6370  data_time: 0.0278  lr: 0.00020779  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:20:42 d2.utils.events]: \u001b[0m eta: 7:20:55  iter: 539  total_loss: 0.1499  loss_cls: 0.07681  loss_box_reg: 0.05461  loss_rpn_cls: 0.003508  loss_rpn_loc: 0.01323  time: 2.6398  data_time: 0.0295  lr: 0.00021578  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:21:35 d2.utils.events]: \u001b[0m eta: 7:20:01  iter: 559  total_loss: 0.1523  loss_cls: 0.07078  loss_box_reg: 0.05639  loss_rpn_cls: 0.005337  loss_rpn_loc: 0.01297  time: 2.6404  data_time: 0.0290  lr: 0.00022378  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:22:24 d2.utils.events]: \u001b[0m eta: 7:18:53  iter: 579  total_loss: 0.2236  loss_cls: 0.102  loss_box_reg: 0.08309  loss_rpn_cls: 0.005798  loss_rpn_loc: 0.02222  time: 2.6341  data_time: 0.0289  lr: 0.00023177  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:23:15 d2.utils.events]: \u001b[0m eta: 7:18:01  iter: 599  total_loss: 0.1559  loss_cls: 0.07795  loss_box_reg: 0.05339  loss_rpn_cls: 0.004551  loss_rpn_loc: 0.01631  time: 2.6314  data_time: 0.0284  lr: 0.00023976  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:24:09 d2.utils.events]: \u001b[0m eta: 7:17:20  iter: 619  total_loss: 0.1606  loss_cls: 0.07852  loss_box_reg: 0.05552  loss_rpn_cls: 0.006194  loss_rpn_loc: 0.01179  time: 2.6322  data_time: 0.0243  lr: 0.00024775  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:25:01 d2.utils.events]: \u001b[0m eta: 7:16:22  iter: 639  total_loss: 0.1561  loss_cls: 0.07671  loss_box_reg: 0.04756  loss_rpn_cls: 0.005535  loss_rpn_loc: 0.009398  time: 2.6312  data_time: 0.0265  lr: 0.00025574  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:25:53 d2.utils.events]: \u001b[0m eta: 7:15:30  iter: 659  total_loss: 0.1762  loss_cls: 0.07803  loss_box_reg: 0.05825  loss_rpn_cls: 0.004479  loss_rpn_loc: 0.01846  time: 2.6314  data_time: 0.0275  lr: 0.00026374  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:26:47 d2.utils.events]: \u001b[0m eta: 7:14:52  iter: 679  total_loss: 0.1833  loss_cls: 0.07043  loss_box_reg: 0.06576  loss_rpn_cls: 0.005646  loss_rpn_loc: 0.01871  time: 2.6323  data_time: 0.0317  lr: 0.00027173  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:27:38 d2.utils.events]: \u001b[0m eta: 7:14:02  iter: 699  total_loss: 0.1569  loss_cls: 0.06661  loss_box_reg: 0.05314  loss_rpn_cls: 0.003914  loss_rpn_loc: 0.01762  time: 2.6310  data_time: 0.0298  lr: 0.00027972  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:28:32 d2.utils.events]: \u001b[0m eta: 7:13:14  iter: 719  total_loss: 0.1747  loss_cls: 0.08679  loss_box_reg: 0.05763  loss_rpn_cls: 0.008647  loss_rpn_loc: 0.02283  time: 2.6323  data_time: 0.0359  lr: 0.00028771  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:29:21 d2.utils.events]: \u001b[0m eta: 7:12:17  iter: 739  total_loss: 0.1729  loss_cls: 0.08023  loss_box_reg: 0.05898  loss_rpn_cls: 0.004259  loss_rpn_loc: 0.02001  time: 2.6280  data_time: 0.0288  lr: 0.0002957  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:30:11 d2.utils.events]: \u001b[0m eta: 7:11:23  iter: 759  total_loss: 0.1681  loss_cls: 0.07316  loss_box_reg: 0.05841  loss_rpn_cls: 0.005882  loss_rpn_loc: 0.02128  time: 2.6245  data_time: 0.0318  lr: 0.0003037  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:31:05 d2.utils.events]: \u001b[0m eta: 7:10:35  iter: 779  total_loss: 0.1782  loss_cls: 0.07014  loss_box_reg: 0.05501  loss_rpn_cls: 0.005804  loss_rpn_loc: 0.02197  time: 2.6253  data_time: 0.0407  lr: 0.00031169  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:31:59 d2.utils.events]: \u001b[0m eta: 7:10:06  iter: 799  total_loss: 0.1982  loss_cls: 0.08823  loss_box_reg: 0.06636  loss_rpn_cls: 0.005409  loss_rpn_loc: 0.01615  time: 2.6278  data_time: 0.0257  lr: 0.00031968  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:32:51 d2.utils.events]: \u001b[0m eta: 7:08:55  iter: 819  total_loss: 0.1438  loss_cls: 0.06278  loss_box_reg: 0.05015  loss_rpn_cls: 0.005823  loss_rpn_loc: 0.01108  time: 2.6268  data_time: 0.0284  lr: 0.00032767  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:33:42 d2.utils.events]: \u001b[0m eta: 7:08:03  iter: 839  total_loss: 0.1919  loss_cls: 0.09619  loss_box_reg: 0.07035  loss_rpn_cls: 0.005958  loss_rpn_loc: 0.02598  time: 2.6250  data_time: 0.0264  lr: 0.00033566  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:34:34 d2.utils.events]: \u001b[0m eta: 7:07:08  iter: 859  total_loss: 0.1429  loss_cls: 0.06968  loss_box_reg: 0.05092  loss_rpn_cls: 0.006535  loss_rpn_loc: 0.01283  time: 2.6242  data_time: 0.0285  lr: 0.00034366  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:35:25 d2.utils.events]: \u001b[0m eta: 7:06:07  iter: 879  total_loss: 0.157  loss_cls: 0.07707  loss_box_reg: 0.05263  loss_rpn_cls: 0.007228  loss_rpn_loc: 0.01753  time: 2.6227  data_time: 0.0255  lr: 0.00035165  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:36:17 d2.utils.events]: \u001b[0m eta: 7:05:24  iter: 899  total_loss: 0.1566  loss_cls: 0.07874  loss_box_reg: 0.05928  loss_rpn_cls: 0.005973  loss_rpn_loc: 0.0215  time: 2.6227  data_time: 0.0307  lr: 0.00035964  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:37:10 d2.utils.events]: \u001b[0m eta: 7:04:32  iter: 919  total_loss: 0.1734  loss_cls: 0.06689  loss_box_reg: 0.05935  loss_rpn_cls: 0.004759  loss_rpn_loc: 0.01425  time: 2.6225  data_time: 0.0305  lr: 0.00036763  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:38:01 d2.utils.events]: \u001b[0m eta: 7:03:37  iter: 939  total_loss: 0.1568  loss_cls: 0.08244  loss_box_reg: 0.04909  loss_rpn_cls: 0.006899  loss_rpn_loc: 0.01926  time: 2.6214  data_time: 0.0310  lr: 0.00037562  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:38:53 d2.utils.events]: \u001b[0m eta: 7:02:39  iter: 959  total_loss: 0.1683  loss_cls: 0.08097  loss_box_reg: 0.06297  loss_rpn_cls: 0.005404  loss_rpn_loc: 0.0139  time: 2.6210  data_time: 0.0233  lr: 0.00038362  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:39:45 d2.utils.events]: \u001b[0m eta: 7:01:41  iter: 979  total_loss: 0.1357  loss_cls: 0.07018  loss_box_reg: 0.04795  loss_rpn_cls: 0.007691  loss_rpn_loc: 0.01161  time: 2.6207  data_time: 0.0308  lr: 0.00039161  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:40:38 d2.utils.events]: \u001b[0m eta: 7:00:50  iter: 999  total_loss: 0.1759  loss_cls: 0.07539  loss_box_reg: 0.06669  loss_rpn_cls: 0.004702  loss_rpn_loc: 0.02432  time: 2.6209  data_time: 0.0273  lr: 0.0003996  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:41:32 d2.utils.events]: \u001b[0m eta: 7:00:08  iter: 1019  total_loss: 0.1818  loss_cls: 0.08273  loss_box_reg: 0.06207  loss_rpn_cls: 0.005901  loss_rpn_loc: 0.02732  time: 2.6225  data_time: 0.0275  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:42:23 d2.utils.events]: \u001b[0m eta: 6:59:21  iter: 1039  total_loss: 0.1458  loss_cls: 0.06916  loss_box_reg: 0.05368  loss_rpn_cls: 0.004495  loss_rpn_loc: 0.0137  time: 2.6214  data_time: 0.0305  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:43:15 d2.utils.events]: \u001b[0m eta: 6:58:47  iter: 1059  total_loss: 0.1485  loss_cls: 0.06504  loss_box_reg: 0.05426  loss_rpn_cls: 0.005081  loss_rpn_loc: 0.01111  time: 2.6205  data_time: 0.0277  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:44:09 d2.utils.events]: \u001b[0m eta: 6:58:03  iter: 1079  total_loss: 0.1485  loss_cls: 0.05909  loss_box_reg: 0.0505  loss_rpn_cls: 0.003651  loss_rpn_loc: 0.01081  time: 2.6223  data_time: 0.0292  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:45:01 d2.utils.events]: \u001b[0m eta: 6:57:11  iter: 1099  total_loss: 0.1566  loss_cls: 0.07463  loss_box_reg: 0.05876  loss_rpn_cls: 0.004952  loss_rpn_loc: 0.01631  time: 2.6218  data_time: 0.0299  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:45:53 d2.utils.events]: \u001b[0m eta: 6:56:19  iter: 1119  total_loss: 0.1258  loss_cls: 0.05832  loss_box_reg: 0.04371  loss_rpn_cls: 0.005469  loss_rpn_loc: 0.01796  time: 2.6213  data_time: 0.0316  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:46:45 d2.utils.events]: \u001b[0m eta: 6:55:27  iter: 1139  total_loss: 0.1782  loss_cls: 0.08495  loss_box_reg: 0.0553  loss_rpn_cls: 0.008039  loss_rpn_loc: 0.01925  time: 2.6211  data_time: 0.0231  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:47:38 d2.utils.events]: \u001b[0m eta: 6:54:20  iter: 1159  total_loss: 0.214  loss_cls: 0.09036  loss_box_reg: 0.07298  loss_rpn_cls: 0.005485  loss_rpn_loc: 0.03366  time: 2.6211  data_time: 0.0351  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:48:29 d2.utils.events]: \u001b[0m eta: 6:53:49  iter: 1179  total_loss: 0.1306  loss_cls: 0.06052  loss_box_reg: 0.04534  loss_rpn_cls: 0.00655  loss_rpn_loc: 0.01811  time: 2.6200  data_time: 0.0279  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:49:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 01:49:06 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 01:49:06 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 01:49:06 d2.data.build]: \u001b[0mDistribution of instances among all 28 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|    Bottle     | 88           |    Carton     | 51           |  Bottle cap   | 58           |\n",
      "|      Can      | 55           |    Pop tab    | 20           |      Cup      | 39           |\n",
      "| Plastic bag.. | 170          | Styrofoam p.. | 23           | Other plastic | 55           |\n",
      "| Plastic con.. | 15           |     Paper     | 30           |      Lid      | 18           |\n",
      "|     Straw     | 33           |   Paper bag   | 6            | Broken glass  | 27           |\n",
      "| Plastic ute.. | 8            |   Glass jar   | 2            |  Food waste   | 2            |\n",
      "| Squeezable .. | 2            |     Shoe      | 2            | Aluminium f.. | 13           |\n",
      "| Unlabeled l.. | 104          | Blister pack  | 2            |    Battery    | 1            |\n",
      "| Rope & stri.. | 6            |   Cigarette   | 134          |  Scrap metal  | 6            |\n",
      "| Plastic glo.. | 1            |               |              |               |              |\n",
      "|     total     | 971          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[04/30 01:49:06 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 01:49:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 01:49:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 01:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1790 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 01:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2232 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/30 01:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2284 s / img. ETA=0:01:14\n",
      "\u001b[32m[04/30 01:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 65/310. 0.2145 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 01:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 80/310. 0.2082 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 01:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2025 s / img. ETA=0:01:02\n",
      "\u001b[32m[04/30 01:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 117/310. 0.1996 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/30 01:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 137/310. 0.1966 s / img. ETA=0:00:49\n",
      "\u001b[32m[04/30 01:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 159/310. 0.1947 s / img. ETA=0:00:41\n",
      "\u001b[32m[04/30 01:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 182/310. 0.1924 s / img. ETA=0:00:34\n",
      "\u001b[32m[04/30 01:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 206/310. 0.1905 s / img. ETA=0:00:27\n",
      "\u001b[32m[04/30 01:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 231/310. 0.1894 s / img. ETA=0:00:20\n",
      "\u001b[32m[04/30 01:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 254/310. 0.1880 s / img. ETA=0:00:14\n",
      "\u001b[32m[04/30 01:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 275/310. 0.1876 s / img. ETA=0:00:08\n",
      "\u001b[32m[04/30 01:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 299/310. 0.1876 s / img. ETA=0:00:02\n",
      "\u001b[32m[04/30 01:50:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:16.074450 (0.249424 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 01:50:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.188489 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 01:50:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 01:50:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 01:50:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 01:50:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[04/30 01:50:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 01:50:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.18 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      "\u001b[32m[04/30 01:50:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.570 | 24.055 | 18.293 | 2.903 | 15.607 | 18.339 |\n",
      "\u001b[32m[04/30 01:50:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 41.697 | Carton          | 29.784 | Bottle cap     | 30.708 |\n",
      "| Can                   | 33.182 | Pop tab         | 9.009  | Cup            | 28.397 |\n",
      "| Plastic bag & wrapper | 30.741 | Styrofoam piece | 13.016 | Other plastic  | 6.201  |\n",
      "| Plastic container     | 28.636 | Paper           | 10.183 | Lid            | 15.364 |\n",
      "| Straw                 | 20.546 | Paper bag       | 24.406 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 58.419 | Glass jar       | 10.099 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 19.604 |\n",
      "| Unlabeled litter      | 2.497  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 9.762  | Cigarette       | 13.717 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 01:50:25 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 01:50:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 01:50:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 01:50:25 d2.evaluation.testing]: \u001b[0mcopypaste: 15.5703,24.0553,18.2934,2.9032,15.6073,18.3387\n",
      "\u001b[32m[04/30 01:50:41 d2.utils.events]: \u001b[0m eta: 6:53:16  iter: 1199  total_loss: 0.1629  loss_cls: 0.07958  loss_box_reg: 0.06475  loss_rpn_cls: 0.006176  loss_rpn_loc: 0.02131  time: 2.6201  data_time: 0.0287  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:51:33 d2.utils.events]: \u001b[0m eta: 6:52:20  iter: 1219  total_loss: 0.1205  loss_cls: 0.05105  loss_box_reg: 0.04534  loss_rpn_cls: 0.004495  loss_rpn_loc: 0.009112  time: 2.6200  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:52:29 d2.utils.events]: \u001b[0m eta: 6:51:39  iter: 1239  total_loss: 0.1606  loss_cls: 0.07751  loss_box_reg: 0.06272  loss_rpn_cls: 0.004942  loss_rpn_loc: 0.01486  time: 2.6223  data_time: 0.0260  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:53:20 d2.utils.events]: \u001b[0m eta: 6:50:47  iter: 1259  total_loss: 0.2482  loss_cls: 0.1099  loss_box_reg: 0.07311  loss_rpn_cls: 0.006453  loss_rpn_loc: 0.03118  time: 2.6215  data_time: 0.0333  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:54:13 d2.utils.events]: \u001b[0m eta: 6:50:15  iter: 1279  total_loss: 0.157  loss_cls: 0.06805  loss_box_reg: 0.04859  loss_rpn_cls: 0.005632  loss_rpn_loc: 0.01921  time: 2.6218  data_time: 0.0313  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:55:04 d2.utils.events]: \u001b[0m eta: 6:49:33  iter: 1299  total_loss: 0.1817  loss_cls: 0.07336  loss_box_reg: 0.06056  loss_rpn_cls: 0.004672  loss_rpn_loc: 0.02285  time: 2.6205  data_time: 0.0312  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:55:57 d2.utils.events]: \u001b[0m eta: 6:48:41  iter: 1319  total_loss: 0.1228  loss_cls: 0.06011  loss_box_reg: 0.03978  loss_rpn_cls: 0.006794  loss_rpn_loc: 0.01704  time: 2.6214  data_time: 0.0266  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:56:52 d2.utils.events]: \u001b[0m eta: 6:47:37  iter: 1339  total_loss: 0.1656  loss_cls: 0.06664  loss_box_reg: 0.052  loss_rpn_cls: 0.005362  loss_rpn_loc: 0.02854  time: 2.6230  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:57:43 d2.utils.events]: \u001b[0m eta: 6:46:34  iter: 1359  total_loss: 0.1525  loss_cls: 0.07387  loss_box_reg: 0.05938  loss_rpn_cls: 0.004696  loss_rpn_loc: 0.01277  time: 2.6222  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:58:35 d2.utils.events]: \u001b[0m eta: 6:45:42  iter: 1379  total_loss: 0.1781  loss_cls: 0.0996  loss_box_reg: 0.06875  loss_rpn_cls: 0.004307  loss_rpn_loc: 0.01384  time: 2.6215  data_time: 0.0269  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 01:59:28 d2.utils.events]: \u001b[0m eta: 6:44:39  iter: 1399  total_loss: 0.1655  loss_cls: 0.08356  loss_box_reg: 0.05876  loss_rpn_cls: 0.004643  loss_rpn_loc: 0.01183  time: 2.6217  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:00:19 d2.utils.events]: \u001b[0m eta: 6:43:39  iter: 1419  total_loss: 0.1795  loss_cls: 0.07315  loss_box_reg: 0.05881  loss_rpn_cls: 0.003175  loss_rpn_loc: 0.01803  time: 2.6211  data_time: 0.0370  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:01:15 d2.utils.events]: \u001b[0m eta: 6:42:43  iter: 1439  total_loss: 0.1309  loss_cls: 0.06124  loss_box_reg: 0.04424  loss_rpn_cls: 0.004349  loss_rpn_loc: 0.01566  time: 2.6231  data_time: 0.0310  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:02:10 d2.utils.events]: \u001b[0m eta: 6:41:23  iter: 1459  total_loss: 0.162  loss_cls: 0.08241  loss_box_reg: 0.06689  loss_rpn_cls: 0.002924  loss_rpn_loc: 0.0143  time: 2.6252  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:03:02 d2.utils.events]: \u001b[0m eta: 6:40:39  iter: 1479  total_loss: 0.187  loss_cls: 0.09299  loss_box_reg: 0.06653  loss_rpn_cls: 0.005773  loss_rpn_loc: 0.0281  time: 2.6247  data_time: 0.0306  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:03:58 d2.utils.events]: \u001b[0m eta: 6:39:58  iter: 1499  total_loss: 0.1451  loss_cls: 0.07009  loss_box_reg: 0.04972  loss_rpn_cls: 0.006799  loss_rpn_loc: 0.01542  time: 2.6269  data_time: 0.0306  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:04:51 d2.utils.events]: \u001b[0m eta: 6:39:06  iter: 1519  total_loss: 0.2015  loss_cls: 0.09236  loss_box_reg: 0.07001  loss_rpn_cls: 0.006608  loss_rpn_loc: 0.01793  time: 2.6274  data_time: 0.0328  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:05:45 d2.utils.events]: \u001b[0m eta: 6:38:23  iter: 1539  total_loss: 0.1911  loss_cls: 0.08185  loss_box_reg: 0.06426  loss_rpn_cls: 0.005417  loss_rpn_loc: 0.01747  time: 2.6283  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:06:36 d2.utils.events]: \u001b[0m eta: 6:37:27  iter: 1559  total_loss: 0.1769  loss_cls: 0.09561  loss_box_reg: 0.05965  loss_rpn_cls: 0.004949  loss_rpn_loc: 0.01373  time: 2.6270  data_time: 0.0299  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:07:27 d2.utils.events]: \u001b[0m eta: 6:36:39  iter: 1579  total_loss: 0.1718  loss_cls: 0.0771  loss_box_reg: 0.05633  loss_rpn_cls: 0.006197  loss_rpn_loc: 0.03524  time: 2.6261  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:08:18 d2.utils.events]: \u001b[0m eta: 6:35:47  iter: 1599  total_loss: 0.1389  loss_cls: 0.06748  loss_box_reg: 0.05515  loss_rpn_cls: 0.004566  loss_rpn_loc: 0.01541  time: 2.6250  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:09:08 d2.utils.events]: \u001b[0m eta: 6:34:43  iter: 1619  total_loss: 0.1661  loss_cls: 0.07799  loss_box_reg: 0.06768  loss_rpn_cls: 0.004167  loss_rpn_loc: 0.0158  time: 2.6239  data_time: 0.0260  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:10:02 d2.utils.events]: \u001b[0m eta: 6:33:58  iter: 1639  total_loss: 0.1915  loss_cls: 0.08968  loss_box_reg: 0.06208  loss_rpn_cls: 0.008811  loss_rpn_loc: 0.02202  time: 2.6248  data_time: 0.0299  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:10:56 d2.utils.events]: \u001b[0m eta: 6:33:06  iter: 1659  total_loss: 0.1934  loss_cls: 0.07857  loss_box_reg: 0.06029  loss_rpn_cls: 0.005561  loss_rpn_loc: 0.02935  time: 2.6253  data_time: 0.0331  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:11:48 d2.utils.events]: \u001b[0m eta: 6:32:03  iter: 1679  total_loss: 0.1503  loss_cls: 0.06926  loss_box_reg: 0.04889  loss_rpn_cls: 0.005256  loss_rpn_loc: 0.01684  time: 2.6254  data_time: 0.0289  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:12:42 d2.utils.events]: \u001b[0m eta: 6:30:55  iter: 1699  total_loss: 0.1496  loss_cls: 0.06861  loss_box_reg: 0.05648  loss_rpn_cls: 0.00494  loss_rpn_loc: 0.01765  time: 2.6262  data_time: 0.0263  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:13:36 d2.utils.events]: \u001b[0m eta: 6:29:57  iter: 1719  total_loss: 0.1786  loss_cls: 0.0704  loss_box_reg: 0.05624  loss_rpn_cls: 0.006784  loss_rpn_loc: 0.02014  time: 2.6269  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:14:26 d2.utils.events]: \u001b[0m eta: 6:29:09  iter: 1739  total_loss: 0.1693  loss_cls: 0.08089  loss_box_reg: 0.05982  loss_rpn_cls: 0.005478  loss_rpn_loc: 0.02473  time: 2.6252  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:15:18 d2.utils.events]: \u001b[0m eta: 6:28:17  iter: 1759  total_loss: 0.1655  loss_cls: 0.08441  loss_box_reg: 0.06593  loss_rpn_cls: 0.003638  loss_rpn_loc: 0.0187  time: 2.6251  data_time: 0.0301  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:16:10 d2.utils.events]: \u001b[0m eta: 6:27:20  iter: 1779  total_loss: 0.1154  loss_cls: 0.05651  loss_box_reg: 0.04937  loss_rpn_cls: 0.002088  loss_rpn_loc: 0.01054  time: 2.6246  data_time: 0.0304  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:17:02 d2.utils.events]: \u001b[0m eta: 6:26:25  iter: 1799  total_loss: 0.1412  loss_cls: 0.05871  loss_box_reg: 0.04006  loss_rpn_cls: 0.003228  loss_rpn_loc: 0.01206  time: 2.6247  data_time: 0.0301  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:17:53 d2.utils.events]: \u001b[0m eta: 6:25:36  iter: 1819  total_loss: 0.1289  loss_cls: 0.05297  loss_box_reg: 0.03744  loss_rpn_cls: 0.003669  loss_rpn_loc: 0.02014  time: 2.6240  data_time: 0.0272  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:18:47 d2.utils.events]: \u001b[0m eta: 6:24:44  iter: 1839  total_loss: 0.1743  loss_cls: 0.08005  loss_box_reg: 0.0522  loss_rpn_cls: 0.003408  loss_rpn_loc: 0.03094  time: 2.6246  data_time: 0.0502  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:19:38 d2.utils.events]: \u001b[0m eta: 6:23:58  iter: 1859  total_loss: 0.1787  loss_cls: 0.08467  loss_box_reg: 0.05661  loss_rpn_cls: 0.005948  loss_rpn_loc: 0.01968  time: 2.6238  data_time: 0.0258  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:20:32 d2.utils.events]: \u001b[0m eta: 6:23:19  iter: 1879  total_loss: 0.1698  loss_cls: 0.08189  loss_box_reg: 0.06007  loss_rpn_cls: 0.006961  loss_rpn_loc: 0.01562  time: 2.6245  data_time: 0.0225  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:21:25 d2.utils.events]: \u001b[0m eta: 6:22:25  iter: 1899  total_loss: 0.1516  loss_cls: 0.06376  loss_box_reg: 0.05085  loss_rpn_cls: 0.006106  loss_rpn_loc: 0.01651  time: 2.6247  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:22:19 d2.utils.events]: \u001b[0m eta: 6:21:40  iter: 1919  total_loss: 0.1313  loss_cls: 0.06407  loss_box_reg: 0.05405  loss_rpn_cls: 0.002573  loss_rpn_loc: 0.009715  time: 2.6254  data_time: 0.0287  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:23:11 d2.utils.events]: \u001b[0m eta: 6:21:05  iter: 1939  total_loss: 0.1376  loss_cls: 0.07147  loss_box_reg: 0.05199  loss_rpn_cls: 0.002821  loss_rpn_loc: 0.01487  time: 2.6254  data_time: 0.0267  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:24:07 d2.utils.events]: \u001b[0m eta: 6:20:19  iter: 1959  total_loss: 0.1937  loss_cls: 0.09853  loss_box_reg: 0.06232  loss_rpn_cls: 0.006248  loss_rpn_loc: 0.01617  time: 2.6268  data_time: 0.0279  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:24:59 d2.utils.events]: \u001b[0m eta: 6:19:37  iter: 1979  total_loss: 0.2201  loss_cls: 0.1122  loss_box_reg: 0.08008  loss_rpn_cls: 0.006539  loss_rpn_loc: 0.03033  time: 2.6269  data_time: 0.0261  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:25:49 d2.utils.events]: \u001b[0m eta: 6:18:43  iter: 1999  total_loss: 0.1747  loss_cls: 0.07547  loss_box_reg: 0.06117  loss_rpn_cls: 0.00708  loss_rpn_loc: 0.02096  time: 2.6254  data_time: 0.0282  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:26:41 d2.utils.events]: \u001b[0m eta: 6:17:51  iter: 2019  total_loss: 0.1876  loss_cls: 0.1026  loss_box_reg: 0.0693  loss_rpn_cls: 0.006307  loss_rpn_loc: 0.02903  time: 2.6254  data_time: 0.0250  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:27:35 d2.utils.events]: \u001b[0m eta: 6:17:12  iter: 2039  total_loss: 0.1891  loss_cls: 0.08534  loss_box_reg: 0.05964  loss_rpn_cls: 0.005397  loss_rpn_loc: 0.02986  time: 2.6261  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:28:27 d2.utils.events]: \u001b[0m eta: 6:16:08  iter: 2059  total_loss: 0.2068  loss_cls: 0.08646  loss_box_reg: 0.06201  loss_rpn_cls: 0.005847  loss_rpn_loc: 0.01813  time: 2.6257  data_time: 0.0303  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:29:21 d2.utils.events]: \u001b[0m eta: 6:15:07  iter: 2079  total_loss: 0.1525  loss_cls: 0.0656  loss_box_reg: 0.05912  loss_rpn_cls: 0.004781  loss_rpn_loc: 0.01639  time: 2.6262  data_time: 0.0305  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:30:14 d2.utils.events]: \u001b[0m eta: 6:14:36  iter: 2099  total_loss: 0.1486  loss_cls: 0.06483  loss_box_reg: 0.0468  loss_rpn_cls: 0.004275  loss_rpn_loc: 0.01067  time: 2.6267  data_time: 0.0263  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:31:05 d2.utils.events]: \u001b[0m eta: 6:13:40  iter: 2119  total_loss: 0.1443  loss_cls: 0.06721  loss_box_reg: 0.05535  loss_rpn_cls: 0.004605  loss_rpn_loc: 0.01414  time: 2.6261  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:31:56 d2.utils.events]: \u001b[0m eta: 6:12:48  iter: 2139  total_loss: 0.1345  loss_cls: 0.07012  loss_box_reg: 0.05124  loss_rpn_cls: 0.004237  loss_rpn_loc: 0.01437  time: 2.6254  data_time: 0.0243  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:32:50 d2.utils.events]: \u001b[0m eta: 6:11:56  iter: 2159  total_loss: 0.1899  loss_cls: 0.08902  loss_box_reg: 0.07197  loss_rpn_cls: 0.004557  loss_rpn_loc: 0.02393  time: 2.6258  data_time: 0.0829  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:33:41 d2.utils.events]: \u001b[0m eta: 6:10:41  iter: 2179  total_loss: 0.1714  loss_cls: 0.08471  loss_box_reg: 0.06888  loss_rpn_cls: 0.005691  loss_rpn_loc: 0.02352  time: 2.6252  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:34:33 d2.utils.events]: \u001b[0m eta: 6:09:43  iter: 2199  total_loss: 0.2148  loss_cls: 0.08781  loss_box_reg: 0.07447  loss_rpn_cls: 0.00472  loss_rpn_loc: 0.03964  time: 2.6247  data_time: 0.0239  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:35:23 d2.utils.events]: \u001b[0m eta: 6:08:45  iter: 2219  total_loss: 0.1942  loss_cls: 0.08299  loss_box_reg: 0.05259  loss_rpn_cls: 0.003635  loss_rpn_loc: 0.01388  time: 2.6238  data_time: 0.0275  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:36:15 d2.utils.events]: \u001b[0m eta: 6:07:35  iter: 2239  total_loss: 0.1291  loss_cls: 0.06274  loss_box_reg: 0.04154  loss_rpn_cls: 0.003988  loss_rpn_loc: 0.009104  time: 2.6234  data_time: 0.0242  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:37:09 d2.utils.events]: \u001b[0m eta: 6:07:07  iter: 2259  total_loss: 0.2  loss_cls: 0.08253  loss_box_reg: 0.06999  loss_rpn_cls: 0.00556  loss_rpn_loc: 0.01664  time: 2.6241  data_time: 0.0340  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:37:59 d2.utils.events]: \u001b[0m eta: 6:06:12  iter: 2279  total_loss: 0.1512  loss_cls: 0.07997  loss_box_reg: 0.04935  loss_rpn_cls: 0.004373  loss_rpn_loc: 0.01444  time: 2.6233  data_time: 0.0228  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:38:50 d2.utils.events]: \u001b[0m eta: 6:05:14  iter: 2299  total_loss: 0.1667  loss_cls: 0.08925  loss_box_reg: 0.06267  loss_rpn_cls: 0.00618  loss_rpn_loc: 0.01684  time: 2.6223  data_time: 0.0324  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:39:40 d2.utils.events]: \u001b[0m eta: 6:04:16  iter: 2319  total_loss: 0.1661  loss_cls: 0.06866  loss_box_reg: 0.05802  loss_rpn_cls: 0.003027  loss_rpn_loc: 0.01629  time: 2.6214  data_time: 0.0349  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:40:33 d2.utils.events]: \u001b[0m eta: 6:03:34  iter: 2339  total_loss: 0.1397  loss_cls: 0.05743  loss_box_reg: 0.04846  loss_rpn_cls: 0.003679  loss_rpn_loc: 0.01599  time: 2.6218  data_time: 0.0329  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:41:29 d2.utils.events]: \u001b[0m eta: 6:03:07  iter: 2359  total_loss: 0.1885  loss_cls: 0.06667  loss_box_reg: 0.0503  loss_rpn_cls: 0.004994  loss_rpn_loc: 0.0321  time: 2.6232  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:42:21 d2.utils.events]: \u001b[0m eta: 6:02:24  iter: 2379  total_loss: 0.1613  loss_cls: 0.07783  loss_box_reg: 0.04628  loss_rpn_cls: 0.003797  loss_rpn_loc: 0.01451  time: 2.6231  data_time: 0.0244  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:42:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 02:42:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 02:42:41 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 02:42:41 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 02:42:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 02:42:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 02:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1766 s / img. ETA=0:00:54\n",
      "\u001b[32m[04/30 02:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2242 s / img. ETA=0:01:04\n",
      "\u001b[32m[04/30 02:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 49/310. 0.2215 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/30 02:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 66/310. 0.2127 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/30 02:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 81/310. 0.2117 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 02:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 99/310. 0.2053 s / img. ETA=0:01:00\n",
      "\u001b[32m[04/30 02:43:16 d2.evaluation.evaluator]: \u001b[0mInference done 116/310. 0.2011 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/30 02:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 139/310. 0.1967 s / img. ETA=0:00:47\n",
      "\u001b[32m[04/30 02:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 162/310. 0.1942 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/30 02:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 188/310. 0.1919 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/30 02:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 210/310. 0.1920 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 02:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 235/310. 0.1909 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 02:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 257/310. 0.1900 s / img. ETA=0:00:13\n",
      "\u001b[32m[04/30 02:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 280/310. 0.1887 s / img. ETA=0:00:07\n",
      "\u001b[32m[04/30 02:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 306/310. 0.1887 s / img. ETA=0:00:00\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.034526 (0.242736 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.189246 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.122 | 25.587 | 21.153 | 3.745 | 15.642 | 20.093 |\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 43.160 | Carton          | 31.595 | Bottle cap     | 29.309 |\n",
      "| Can                   | 36.682 | Pop tab         | 8.707  | Cup            | 30.131 |\n",
      "| Plastic bag & wrapper | 30.730 | Styrofoam piece | 16.845 | Other plastic  | 6.774  |\n",
      "| Plastic container     | 27.748 | Paper           | 10.452 | Lid            | 17.555 |\n",
      "| Straw                 | 21.100 | Paper bag       | 24.125 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 57.614 | Glass jar       | 30.297 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 23.267 |\n",
      "| Unlabeled litter      | 2.199  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 16.832 | Cigarette       | 14.304 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 02:43:58 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 02:43:58 d2.evaluation.testing]: \u001b[0mcopypaste: 17.1224,25.5873,21.1530,3.7449,15.6417,20.0931\n",
      "\u001b[32m[04/30 02:44:31 d2.utils.events]: \u001b[0m eta: 6:01:10  iter: 2399  total_loss: 0.1546  loss_cls: 0.06601  loss_box_reg: 0.05327  loss_rpn_cls: 0.005193  loss_rpn_loc: 0.01668  time: 2.6223  data_time: 0.0324  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:45:23 d2.utils.events]: \u001b[0m eta: 6:00:31  iter: 2419  total_loss: 0.2097  loss_cls: 0.09073  loss_box_reg: 0.07065  loss_rpn_cls: 0.00284  loss_rpn_loc: 0.01597  time: 2.6222  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:46:17 d2.utils.events]: \u001b[0m eta: 5:59:06  iter: 2439  total_loss: 0.1254  loss_cls: 0.06005  loss_box_reg: 0.04801  loss_rpn_cls: 0.003218  loss_rpn_loc: 0.0152  time: 2.6227  data_time: 0.0304  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:47:11 d2.utils.events]: \u001b[0m eta: 5:58:09  iter: 2459  total_loss: 0.1609  loss_cls: 0.07508  loss_box_reg: 0.0557  loss_rpn_cls: 0.006772  loss_rpn_loc: 0.01572  time: 2.6234  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:48:01 d2.utils.events]: \u001b[0m eta: 5:57:10  iter: 2479  total_loss: 0.1323  loss_cls: 0.06298  loss_box_reg: 0.04811  loss_rpn_cls: 0.005421  loss_rpn_loc: 0.01301  time: 2.6226  data_time: 0.1022  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:48:51 d2.utils.events]: \u001b[0m eta: 5:56:10  iter: 2499  total_loss: 0.1556  loss_cls: 0.05537  loss_box_reg: 0.04868  loss_rpn_cls: 0.003358  loss_rpn_loc: 0.01254  time: 2.6216  data_time: 0.0361  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:49:46 d2.utils.events]: \u001b[0m eta: 5:55:16  iter: 2519  total_loss: 0.1795  loss_cls: 0.09084  loss_box_reg: 0.06586  loss_rpn_cls: 0.006047  loss_rpn_loc: 0.02221  time: 2.6225  data_time: 0.0278  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:50:38 d2.utils.events]: \u001b[0m eta: 5:54:22  iter: 2539  total_loss: 0.1906  loss_cls: 0.06981  loss_box_reg: 0.0578  loss_rpn_cls: 0.00372  loss_rpn_loc: 0.02002  time: 2.6225  data_time: 0.0336  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:51:29 d2.utils.events]: \u001b[0m eta: 5:53:30  iter: 2559  total_loss: 0.1506  loss_cls: 0.07485  loss_box_reg: 0.05176  loss_rpn_cls: 0.003757  loss_rpn_loc: 0.01467  time: 2.6219  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:52:18 d2.utils.events]: \u001b[0m eta: 5:52:38  iter: 2579  total_loss: 0.1537  loss_cls: 0.06169  loss_box_reg: 0.05137  loss_rpn_cls: 0.005297  loss_rpn_loc: 0.0235  time: 2.6204  data_time: 0.0241  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:53:08 d2.utils.events]: \u001b[0m eta: 5:51:34  iter: 2599  total_loss: 0.1486  loss_cls: 0.06428  loss_box_reg: 0.05501  loss_rpn_cls: 0.004286  loss_rpn_loc: 0.01714  time: 2.6193  data_time: 0.0244  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:53:56 d2.utils.events]: \u001b[0m eta: 5:50:49  iter: 2619  total_loss: 0.1513  loss_cls: 0.05727  loss_box_reg: 0.05298  loss_rpn_cls: 0.003873  loss_rpn_loc: 0.01609  time: 2.6179  data_time: 0.0303  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:54:49 d2.utils.events]: \u001b[0m eta: 5:49:46  iter: 2639  total_loss: 0.1713  loss_cls: 0.09227  loss_box_reg: 0.06389  loss_rpn_cls: 0.004377  loss_rpn_loc: 0.0184  time: 2.6179  data_time: 0.0281  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:55:42 d2.utils.events]: \u001b[0m eta: 5:48:57  iter: 2659  total_loss: 0.2053  loss_cls: 0.09365  loss_box_reg: 0.07317  loss_rpn_cls: 0.004987  loss_rpn_loc: 0.03173  time: 2.6184  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:56:38 d2.utils.events]: \u001b[0m eta: 5:48:19  iter: 2679  total_loss: 0.1739  loss_cls: 0.08292  loss_box_reg: 0.06111  loss_rpn_cls: 0.004991  loss_rpn_loc: 0.02202  time: 2.6197  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:57:33 d2.utils.events]: \u001b[0m eta: 5:47:37  iter: 2699  total_loss: 0.1855  loss_cls: 0.09443  loss_box_reg: 0.06562  loss_rpn_cls: 0.004148  loss_rpn_loc: 0.01779  time: 2.6204  data_time: 0.0278  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:58:26 d2.utils.events]: \u001b[0m eta: 5:46:45  iter: 2719  total_loss: 0.1544  loss_cls: 0.07211  loss_box_reg: 0.06061  loss_rpn_cls: 0.006834  loss_rpn_loc: 0.01162  time: 2.6206  data_time: 0.0282  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 02:59:21 d2.utils.events]: \u001b[0m eta: 5:46:02  iter: 2739  total_loss: 0.1954  loss_cls: 0.08549  loss_box_reg: 0.08152  loss_rpn_cls: 0.003821  loss_rpn_loc: 0.0185  time: 2.6216  data_time: 0.0238  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:00:14 d2.utils.events]: \u001b[0m eta: 5:45:10  iter: 2759  total_loss: 0.1106  loss_cls: 0.04998  loss_box_reg: 0.03852  loss_rpn_cls: 0.002669  loss_rpn_loc: 0.01723  time: 2.6218  data_time: 0.0288  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:01:05 d2.utils.events]: \u001b[0m eta: 5:44:15  iter: 2779  total_loss: 0.1428  loss_cls: 0.06089  loss_box_reg: 0.05039  loss_rpn_cls: 0.003557  loss_rpn_loc: 0.01438  time: 2.6214  data_time: 0.0321  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:01:57 d2.utils.events]: \u001b[0m eta: 5:43:16  iter: 2799  total_loss: 0.1404  loss_cls: 0.06943  loss_box_reg: 0.05235  loss_rpn_cls: 0.004349  loss_rpn_loc: 0.01145  time: 2.6212  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:02:49 d2.utils.events]: \u001b[0m eta: 5:42:26  iter: 2819  total_loss: 0.1263  loss_cls: 0.05912  loss_box_reg: 0.04637  loss_rpn_cls: 0.005771  loss_rpn_loc: 0.01572  time: 2.6211  data_time: 0.0306  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:03:42 d2.utils.events]: \u001b[0m eta: 5:41:34  iter: 2839  total_loss: 0.1438  loss_cls: 0.06014  loss_box_reg: 0.05559  loss_rpn_cls: 0.002518  loss_rpn_loc: 0.01432  time: 2.6212  data_time: 0.0303  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:04:33 d2.utils.events]: \u001b[0m eta: 5:40:39  iter: 2859  total_loss: 0.165  loss_cls: 0.06863  loss_box_reg: 0.05397  loss_rpn_cls: 0.005915  loss_rpn_loc: 0.03135  time: 2.6208  data_time: 0.0243  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:05:23 d2.utils.events]: \u001b[0m eta: 5:39:42  iter: 2879  total_loss: 0.163  loss_cls: 0.07012  loss_box_reg: 0.0532  loss_rpn_cls: 0.003017  loss_rpn_loc: 0.01641  time: 2.6200  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:06:15 d2.utils.events]: \u001b[0m eta: 5:38:48  iter: 2899  total_loss: 0.1815  loss_cls: 0.07595  loss_box_reg: 0.07093  loss_rpn_cls: 0.004884  loss_rpn_loc: 0.02826  time: 2.6198  data_time: 0.0269  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:07:07 d2.utils.events]: \u001b[0m eta: 5:37:55  iter: 2919  total_loss: 0.2517  loss_cls: 0.1075  loss_box_reg: 0.0841  loss_rpn_cls: 0.006801  loss_rpn_loc: 0.04031  time: 2.6197  data_time: 0.0293  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:08:02 d2.utils.events]: \u001b[0m eta: 5:37:04  iter: 2939  total_loss: 0.1536  loss_cls: 0.0719  loss_box_reg: 0.06924  loss_rpn_cls: 0.003738  loss_rpn_loc: 0.01562  time: 2.6206  data_time: 0.0281  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:08:54 d2.utils.events]: \u001b[0m eta: 5:36:10  iter: 2959  total_loss: 0.1553  loss_cls: 0.05823  loss_box_reg: 0.0539  loss_rpn_cls: 0.005024  loss_rpn_loc: 0.01964  time: 2.6204  data_time: 0.0283  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:09:46 d2.utils.events]: \u001b[0m eta: 5:35:13  iter: 2979  total_loss: 0.1583  loss_cls: 0.07358  loss_box_reg: 0.05643  loss_rpn_cls: 0.005512  loss_rpn_loc: 0.02113  time: 2.6202  data_time: 0.0278  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:10:39 d2.utils.events]: \u001b[0m eta: 5:34:17  iter: 2999  total_loss: 0.1539  loss_cls: 0.06546  loss_box_reg: 0.06083  loss_rpn_cls: 0.008639  loss_rpn_loc: 0.01641  time: 2.6205  data_time: 0.0251  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:11:31 d2.utils.events]: \u001b[0m eta: 5:33:09  iter: 3019  total_loss: 0.1941  loss_cls: 0.0837  loss_box_reg: 0.06933  loss_rpn_cls: 0.006741  loss_rpn_loc: 0.01794  time: 2.6204  data_time: 0.0271  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:12:29 d2.utils.events]: \u001b[0m eta: 5:32:33  iter: 3039  total_loss: 0.1754  loss_cls: 0.0757  loss_box_reg: 0.05812  loss_rpn_cls: 0.003496  loss_rpn_loc: 0.01745  time: 2.6222  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:13:21 d2.utils.events]: \u001b[0m eta: 5:31:41  iter: 3059  total_loss: 0.1547  loss_cls: 0.07145  loss_box_reg: 0.05081  loss_rpn_cls: 0.00748  loss_rpn_loc: 0.01284  time: 2.6220  data_time: 0.0288  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:14:12 d2.utils.events]: \u001b[0m eta: 5:30:24  iter: 3079  total_loss: 0.1997  loss_cls: 0.07787  loss_box_reg: 0.06425  loss_rpn_cls: 0.004276  loss_rpn_loc: 0.02531  time: 2.6216  data_time: 0.0253  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:15:05 d2.utils.events]: \u001b[0m eta: 5:29:25  iter: 3099  total_loss: 0.1459  loss_cls: 0.05751  loss_box_reg: 0.04745  loss_rpn_cls: 0.004867  loss_rpn_loc: 0.01747  time: 2.6216  data_time: 0.0238  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:15:56 d2.utils.events]: \u001b[0m eta: 5:28:33  iter: 3119  total_loss: 0.1966  loss_cls: 0.07553  loss_box_reg: 0.06902  loss_rpn_cls: 0.005072  loss_rpn_loc: 0.03015  time: 2.6211  data_time: 0.0550  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:16:45 d2.utils.events]: \u001b[0m eta: 5:27:29  iter: 3139  total_loss: 0.1306  loss_cls: 0.06024  loss_box_reg: 0.05227  loss_rpn_cls: 0.002994  loss_rpn_loc: 0.01185  time: 2.6202  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:17:36 d2.utils.events]: \u001b[0m eta: 5:26:35  iter: 3159  total_loss: 0.1346  loss_cls: 0.06438  loss_box_reg: 0.05777  loss_rpn_cls: 0.002958  loss_rpn_loc: 0.01367  time: 2.6197  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:18:30 d2.utils.events]: \u001b[0m eta: 5:25:50  iter: 3179  total_loss: 0.1755  loss_cls: 0.08484  loss_box_reg: 0.06041  loss_rpn_cls: 0.004435  loss_rpn_loc: 0.01914  time: 2.6200  data_time: 0.0241  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:19:23 d2.utils.events]: \u001b[0m eta: 5:25:02  iter: 3199  total_loss: 0.1644  loss_cls: 0.07929  loss_box_reg: 0.05872  loss_rpn_cls: 0.003956  loss_rpn_loc: 0.01442  time: 2.6202  data_time: 0.0333  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:20:17 d2.utils.events]: \u001b[0m eta: 5:24:58  iter: 3219  total_loss: 0.1997  loss_cls: 0.08577  loss_box_reg: 0.07218  loss_rpn_cls: 0.004655  loss_rpn_loc: 0.0249  time: 2.6207  data_time: 0.0308  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:21:09 d2.utils.events]: \u001b[0m eta: 5:24:11  iter: 3239  total_loss: 0.1855  loss_cls: 0.08254  loss_box_reg: 0.07265  loss_rpn_cls: 0.00508  loss_rpn_loc: 0.02292  time: 2.6205  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:22:01 d2.utils.events]: \u001b[0m eta: 5:23:08  iter: 3259  total_loss: 0.1694  loss_cls: 0.07049  loss_box_reg: 0.06562  loss_rpn_cls: 0.003566  loss_rpn_loc: 0.01516  time: 2.6205  data_time: 0.0320  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:22:52 d2.utils.events]: \u001b[0m eta: 5:22:00  iter: 3279  total_loss: 0.1457  loss_cls: 0.05967  loss_box_reg: 0.05158  loss_rpn_cls: 0.004155  loss_rpn_loc: 0.01638  time: 2.6200  data_time: 0.0647  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:23:44 d2.utils.events]: \u001b[0m eta: 5:21:08  iter: 3299  total_loss: 0.1713  loss_cls: 0.08304  loss_box_reg: 0.06005  loss_rpn_cls: 0.004545  loss_rpn_loc: 0.01307  time: 2.6200  data_time: 0.0278  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:24:36 d2.utils.events]: \u001b[0m eta: 5:20:36  iter: 3319  total_loss: 0.1493  loss_cls: 0.07324  loss_box_reg: 0.05985  loss_rpn_cls: 0.005673  loss_rpn_loc: 0.01199  time: 2.6199  data_time: 0.0240  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:25:27 d2.utils.events]: \u001b[0m eta: 5:19:14  iter: 3339  total_loss: 0.1412  loss_cls: 0.06922  loss_box_reg: 0.06068  loss_rpn_cls: 0.00637  loss_rpn_loc: 0.01397  time: 2.6195  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:26:17 d2.utils.events]: \u001b[0m eta: 5:18:02  iter: 3359  total_loss: 0.157  loss_cls: 0.07675  loss_box_reg: 0.05755  loss_rpn_cls: 0.003083  loss_rpn_loc: 0.01904  time: 2.6188  data_time: 0.0282  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:27:10 d2.utils.events]: \u001b[0m eta: 5:17:26  iter: 3379  total_loss: 0.1388  loss_cls: 0.06736  loss_box_reg: 0.05505  loss_rpn_cls: 0.005423  loss_rpn_loc: 0.01301  time: 2.6190  data_time: 0.0343  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:28:02 d2.utils.events]: \u001b[0m eta: 5:16:34  iter: 3399  total_loss: 0.1777  loss_cls: 0.06884  loss_box_reg: 0.07031  loss_rpn_cls: 0.004426  loss_rpn_loc: 0.02314  time: 2.6187  data_time: 0.0229  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:28:55 d2.utils.events]: \u001b[0m eta: 5:15:58  iter: 3419  total_loss: 0.1652  loss_cls: 0.06812  loss_box_reg: 0.05478  loss_rpn_cls: 0.003655  loss_rpn_loc: 0.01206  time: 2.6189  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:29:44 d2.utils.events]: \u001b[0m eta: 5:15:06  iter: 3439  total_loss: 0.173  loss_cls: 0.06717  loss_box_reg: 0.05492  loss_rpn_cls: 0.003663  loss_rpn_loc: 0.01293  time: 2.6179  data_time: 0.0348  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:30:36 d2.utils.events]: \u001b[0m eta: 5:14:14  iter: 3459  total_loss: 0.1525  loss_cls: 0.07712  loss_box_reg: 0.05469  loss_rpn_cls: 0.003934  loss_rpn_loc: 0.01428  time: 2.6178  data_time: 0.0313  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:31:29 d2.utils.events]: \u001b[0m eta: 5:13:44  iter: 3479  total_loss: 0.1574  loss_cls: 0.07457  loss_box_reg: 0.05831  loss_rpn_cls: 0.005274  loss_rpn_loc: 0.01263  time: 2.6178  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:32:19 d2.utils.events]: \u001b[0m eta: 5:12:52  iter: 3499  total_loss: 0.1354  loss_cls: 0.06139  loss_box_reg: 0.05169  loss_rpn_cls: 0.003421  loss_rpn_loc: 0.02009  time: 2.6174  data_time: 0.0318  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:33:14 d2.utils.events]: \u001b[0m eta: 5:12:23  iter: 3519  total_loss: 0.1557  loss_cls: 0.07813  loss_box_reg: 0.05064  loss_rpn_cls: 0.00449  loss_rpn_loc: 0.01637  time: 2.6181  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:34:09 d2.utils.events]: \u001b[0m eta: 5:11:42  iter: 3539  total_loss: 0.1548  loss_cls: 0.07794  loss_box_reg: 0.05733  loss_rpn_cls: 0.005578  loss_rpn_loc: 0.01683  time: 2.6187  data_time: 0.0266  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:34:59 d2.utils.events]: \u001b[0m eta: 5:10:40  iter: 3559  total_loss: 0.1409  loss_cls: 0.06756  loss_box_reg: 0.05253  loss_rpn_cls: 0.002624  loss_rpn_loc: 0.01387  time: 2.6182  data_time: 0.0300  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:35:53 d2.utils.events]: \u001b[0m eta: 5:09:59  iter: 3579  total_loss: 0.1373  loss_cls: 0.06192  loss_box_reg: 0.05259  loss_rpn_cls: 0.004153  loss_rpn_loc: 0.01255  time: 2.6187  data_time: 0.0310  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:35:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 03:35:59 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 03:35:59 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 03:35:59 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 03:35:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 03:35:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 03:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1867 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/30 03:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 31/310. 0.2259 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 03:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 49/310. 0.2260 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 03:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 63/310. 0.2184 s / img. ETA=0:01:11\n",
      "\u001b[32m[04/30 03:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2130 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 03:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2065 s / img. ETA=0:01:02\n",
      "\u001b[32m[04/30 03:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 118/310. 0.2018 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 03:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 141/310. 0.1985 s / img. ETA=0:00:47\n",
      "\u001b[32m[04/30 03:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 166/310. 0.1952 s / img. ETA=0:00:38\n",
      "\u001b[32m[04/30 03:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 189/310. 0.1941 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/30 03:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 215/310. 0.1927 s / img. ETA=0:00:24\n",
      "\u001b[32m[04/30 03:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1909 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/30 03:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 266/310. 0.1900 s / img. ETA=0:00:10\n",
      "\u001b[32m[04/30 03:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 288/310. 0.1900 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.303035 (0.243617 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.190362 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.643 | 23.693 | 18.360 | 3.061 | 16.870 | 18.832 |\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 39.755 | Carton          | 39.026 | Bottle cap     | 31.117 |\n",
      "| Can                   | 31.267 | Pop tab         | 9.632  | Cup            | 31.338 |\n",
      "| Plastic bag & wrapper | 33.588 | Styrofoam piece | 14.124 | Other plastic  | 6.931  |\n",
      "| Plastic container     | 24.590 | Paper           | 8.770  | Lid            | 14.017 |\n",
      "| Straw                 | 21.368 | Paper bag       | 15.149 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 54.321 | Glass jar       | 10.099 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 23.465 |\n",
      "| Unlabeled litter      | 2.101  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 13.746 | Cigarette       | 13.590 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 03:37:15 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 03:37:15 d2.evaluation.testing]: \u001b[0mcopypaste: 15.6426,23.6926,18.3595,3.0612,16.8701,18.8319\n",
      "\u001b[32m[04/30 03:38:01 d2.utils.events]: \u001b[0m eta: 5:09:08  iter: 3599  total_loss: 0.124  loss_cls: 0.06436  loss_box_reg: 0.04346  loss_rpn_cls: 0.003191  loss_rpn_loc: 0.01406  time: 2.6182  data_time: 0.0279  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:38:53 d2.utils.events]: \u001b[0m eta: 5:08:16  iter: 3619  total_loss: 0.1637  loss_cls: 0.07484  loss_box_reg: 0.05653  loss_rpn_cls: 0.004698  loss_rpn_loc: 0.01907  time: 2.6180  data_time: 0.0273  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:39:47 d2.utils.events]: \u001b[0m eta: 5:07:38  iter: 3639  total_loss: 0.1676  loss_cls: 0.06517  loss_box_reg: 0.0579  loss_rpn_cls: 0.004162  loss_rpn_loc: 0.0169  time: 2.6186  data_time: 0.0319  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:40:40 d2.utils.events]: \u001b[0m eta: 5:06:42  iter: 3659  total_loss: 0.2142  loss_cls: 0.1006  loss_box_reg: 0.07848  loss_rpn_cls: 0.00423  loss_rpn_loc: 0.02559  time: 2.6186  data_time: 0.0340  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:41:31 d2.utils.events]: \u001b[0m eta: 5:05:28  iter: 3679  total_loss: 0.1817  loss_cls: 0.0831  loss_box_reg: 0.06394  loss_rpn_cls: 0.005113  loss_rpn_loc: 0.01759  time: 2.6184  data_time: 0.0279  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:42:25 d2.utils.events]: \u001b[0m eta: 5:04:15  iter: 3699  total_loss: 0.1565  loss_cls: 0.07315  loss_box_reg: 0.0492  loss_rpn_cls: 0.003612  loss_rpn_loc: 0.02473  time: 2.6187  data_time: 0.0293  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:43:17 d2.utils.events]: \u001b[0m eta: 5:03:28  iter: 3719  total_loss: 0.1741  loss_cls: 0.06991  loss_box_reg: 0.05587  loss_rpn_cls: 0.004754  loss_rpn_loc: 0.01803  time: 2.6188  data_time: 0.0269  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:44:09 d2.utils.events]: \u001b[0m eta: 5:02:46  iter: 3739  total_loss: 0.1345  loss_cls: 0.05671  loss_box_reg: 0.04506  loss_rpn_cls: 0.003477  loss_rpn_loc: 0.01835  time: 2.6185  data_time: 0.0310  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:45:02 d2.utils.events]: \u001b[0m eta: 5:02:01  iter: 3759  total_loss: 0.179  loss_cls: 0.07821  loss_box_reg: 0.07016  loss_rpn_cls: 0.004055  loss_rpn_loc: 0.01757  time: 2.6188  data_time: 0.0264  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:45:52 d2.utils.events]: \u001b[0m eta: 5:01:09  iter: 3779  total_loss: 0.131  loss_cls: 0.0619  loss_box_reg: 0.05256  loss_rpn_cls: 0.003559  loss_rpn_loc: 0.01587  time: 2.6182  data_time: 0.0292  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:46:46 d2.utils.events]: \u001b[0m eta: 5:00:29  iter: 3799  total_loss: 0.1565  loss_cls: 0.06764  loss_box_reg: 0.0521  loss_rpn_cls: 0.003796  loss_rpn_loc: 0.01617  time: 2.6184  data_time: 0.0272  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:47:39 d2.utils.events]: \u001b[0m eta: 4:59:25  iter: 3819  total_loss: 0.23  loss_cls: 0.07311  loss_box_reg: 0.07277  loss_rpn_cls: 0.00664  loss_rpn_loc: 0.02454  time: 2.6187  data_time: 0.0278  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:48:31 d2.utils.events]: \u001b[0m eta: 4:58:33  iter: 3839  total_loss: 0.1617  loss_cls: 0.07846  loss_box_reg: 0.05667  loss_rpn_cls: 0.006802  loss_rpn_loc: 0.02302  time: 2.6186  data_time: 0.0289  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:49:22 d2.utils.events]: \u001b[0m eta: 4:57:27  iter: 3859  total_loss: 0.1444  loss_cls: 0.06024  loss_box_reg: 0.05322  loss_rpn_cls: 0.004467  loss_rpn_loc: 0.01276  time: 2.6183  data_time: 0.0259  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:50:14 d2.utils.events]: \u001b[0m eta: 4:56:28  iter: 3879  total_loss: 0.1651  loss_cls: 0.07337  loss_box_reg: 0.05523  loss_rpn_cls: 0.003842  loss_rpn_loc: 0.01648  time: 2.6180  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:51:06 d2.utils.events]: \u001b[0m eta: 4:55:43  iter: 3899  total_loss: 0.156  loss_cls: 0.06828  loss_box_reg: 0.05759  loss_rpn_cls: 0.004159  loss_rpn_loc: 0.01736  time: 2.6180  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:51:57 d2.utils.events]: \u001b[0m eta: 4:54:59  iter: 3919  total_loss: 0.1354  loss_cls: 0.05776  loss_box_reg: 0.04577  loss_rpn_cls: 0.002539  loss_rpn_loc: 0.01403  time: 2.6178  data_time: 0.0260  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:52:51 d2.utils.events]: \u001b[0m eta: 4:54:08  iter: 3939  total_loss: 0.1295  loss_cls: 0.05611  loss_box_reg: 0.04759  loss_rpn_cls: 0.003118  loss_rpn_loc: 0.01461  time: 2.6181  data_time: 0.0252  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:53:43 d2.utils.events]: \u001b[0m eta: 4:53:25  iter: 3959  total_loss: 0.1423  loss_cls: 0.06169  loss_box_reg: 0.06099  loss_rpn_cls: 0.002649  loss_rpn_loc: 0.01033  time: 2.6180  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:54:37 d2.utils.events]: \u001b[0m eta: 4:52:33  iter: 3979  total_loss: 0.1814  loss_cls: 0.07292  loss_box_reg: 0.06385  loss_rpn_cls: 0.004936  loss_rpn_loc: 0.02681  time: 2.6184  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:55:31 d2.utils.events]: \u001b[0m eta: 4:51:48  iter: 3999  total_loss: 0.1227  loss_cls: 0.04729  loss_box_reg: 0.04112  loss_rpn_cls: 0.004407  loss_rpn_loc: 0.008687  time: 2.6187  data_time: 0.0279  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:56:23 d2.utils.events]: \u001b[0m eta: 4:50:49  iter: 4019  total_loss: 0.2013  loss_cls: 0.08945  loss_box_reg: 0.06162  loss_rpn_cls: 0.006564  loss_rpn_loc: 0.02783  time: 2.6188  data_time: 0.0266  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:57:14 d2.utils.events]: \u001b[0m eta: 4:49:43  iter: 4039  total_loss: 0.1423  loss_cls: 0.06022  loss_box_reg: 0.0496  loss_rpn_cls: 0.0039  loss_rpn_loc: 0.0135  time: 2.6182  data_time: 0.0312  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:58:07 d2.utils.events]: \u001b[0m eta: 4:48:59  iter: 4059  total_loss: 0.1179  loss_cls: 0.05993  loss_box_reg: 0.04928  loss_rpn_cls: 0.003507  loss_rpn_loc: 0.012  time: 2.6186  data_time: 0.0305  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:58:58 d2.utils.events]: \u001b[0m eta: 4:48:03  iter: 4079  total_loss: 0.206  loss_cls: 0.08462  loss_box_reg: 0.07498  loss_rpn_cls: 0.005344  loss_rpn_loc: 0.02073  time: 2.6182  data_time: 0.0329  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 03:59:51 d2.utils.events]: \u001b[0m eta: 4:47:11  iter: 4099  total_loss: 0.1932  loss_cls: 0.08232  loss_box_reg: 0.05917  loss_rpn_cls: 0.004357  loss_rpn_loc: 0.02233  time: 2.6183  data_time: 0.0271  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:00:41 d2.utils.events]: \u001b[0m eta: 4:46:13  iter: 4119  total_loss: 0.1739  loss_cls: 0.09003  loss_box_reg: 0.06224  loss_rpn_cls: 0.004718  loss_rpn_loc: 0.02004  time: 2.6177  data_time: 0.0283  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:01:31 d2.utils.events]: \u001b[0m eta: 4:45:21  iter: 4139  total_loss: 0.1701  loss_cls: 0.0804  loss_box_reg: 0.06721  loss_rpn_cls: 0.005216  loss_rpn_loc: 0.01886  time: 2.6172  data_time: 0.0247  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:02:22 d2.utils.events]: \u001b[0m eta: 4:44:27  iter: 4159  total_loss: 0.1268  loss_cls: 0.0655  loss_box_reg: 0.0517  loss_rpn_cls: 0.003815  loss_rpn_loc: 0.02254  time: 2.6167  data_time: 0.0332  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:03:13 d2.utils.events]: \u001b[0m eta: 4:43:33  iter: 4179  total_loss: 0.1532  loss_cls: 0.07144  loss_box_reg: 0.06155  loss_rpn_cls: 0.002889  loss_rpn_loc: 0.01383  time: 2.6164  data_time: 0.0311  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:04:05 d2.utils.events]: \u001b[0m eta: 4:42:39  iter: 4199  total_loss: 0.1265  loss_cls: 0.06404  loss_box_reg: 0.04692  loss_rpn_cls: 0.003459  loss_rpn_loc: 0.009803  time: 2.6164  data_time: 0.0264  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:04:56 d2.utils.events]: \u001b[0m eta: 4:41:37  iter: 4219  total_loss: 0.1109  loss_cls: 0.05039  loss_box_reg: 0.04278  loss_rpn_cls: 0.005677  loss_rpn_loc: 0.01013  time: 2.6162  data_time: 0.0287  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:05:49 d2.utils.events]: \u001b[0m eta: 4:40:34  iter: 4239  total_loss: 0.1779  loss_cls: 0.07086  loss_box_reg: 0.05718  loss_rpn_cls: 0.003922  loss_rpn_loc: 0.01863  time: 2.6163  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:06:40 d2.utils.events]: \u001b[0m eta: 4:39:33  iter: 4259  total_loss: 0.1375  loss_cls: 0.06004  loss_box_reg: 0.05331  loss_rpn_cls: 0.004363  loss_rpn_loc: 0.01673  time: 2.6160  data_time: 0.0305  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:07:33 d2.utils.events]: \u001b[0m eta: 4:38:44  iter: 4279  total_loss: 0.1324  loss_cls: 0.06323  loss_box_reg: 0.04737  loss_rpn_cls: 0.003381  loss_rpn_loc: 0.01647  time: 2.6160  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:08:29 d2.utils.events]: \u001b[0m eta: 4:38:15  iter: 4299  total_loss: 0.1931  loss_cls: 0.08909  loss_box_reg: 0.07115  loss_rpn_cls: 0.006872  loss_rpn_loc: 0.02804  time: 2.6169  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:09:22 d2.utils.events]: \u001b[0m eta: 4:37:14  iter: 4319  total_loss: 0.1492  loss_cls: 0.06513  loss_box_reg: 0.05046  loss_rpn_cls: 0.005186  loss_rpn_loc: 0.0179  time: 2.6170  data_time: 0.0300  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:10:13 d2.utils.events]: \u001b[0m eta: 4:36:32  iter: 4339  total_loss: 0.1523  loss_cls: 0.07348  loss_box_reg: 0.05829  loss_rpn_cls: 0.004453  loss_rpn_loc: 0.01333  time: 2.6167  data_time: 0.0351  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:11:04 d2.utils.events]: \u001b[0m eta: 4:35:45  iter: 4359  total_loss: 0.1988  loss_cls: 0.08709  loss_box_reg: 0.06656  loss_rpn_cls: 0.006523  loss_rpn_loc: 0.02316  time: 2.6166  data_time: 0.0293  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:11:56 d2.utils.events]: \u001b[0m eta: 4:34:43  iter: 4379  total_loss: 0.1447  loss_cls: 0.07159  loss_box_reg: 0.04869  loss_rpn_cls: 0.00442  loss_rpn_loc: 0.01321  time: 2.6163  data_time: 0.0324  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:12:46 d2.utils.events]: \u001b[0m eta: 4:33:47  iter: 4399  total_loss: 0.113  loss_cls: 0.04298  loss_box_reg: 0.04044  loss_rpn_cls: 0.004301  loss_rpn_loc: 0.01397  time: 2.6158  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:13:40 d2.utils.events]: \u001b[0m eta: 4:32:52  iter: 4419  total_loss: 0.1911  loss_cls: 0.07631  loss_box_reg: 0.07027  loss_rpn_cls: 0.005036  loss_rpn_loc: 0.01974  time: 2.6162  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:14:34 d2.utils.events]: \u001b[0m eta: 4:32:17  iter: 4439  total_loss: 0.1251  loss_cls: 0.05707  loss_box_reg: 0.04061  loss_rpn_cls: 0.001896  loss_rpn_loc: 0.01079  time: 2.6165  data_time: 0.0279  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:15:27 d2.utils.events]: \u001b[0m eta: 4:31:27  iter: 4459  total_loss: 0.2118  loss_cls: 0.07835  loss_box_reg: 0.06695  loss_rpn_cls: 0.005115  loss_rpn_loc: 0.03422  time: 2.6167  data_time: 0.0277  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:16:17 d2.utils.events]: \u001b[0m eta: 4:30:21  iter: 4479  total_loss: 0.1488  loss_cls: 0.05925  loss_box_reg: 0.04828  loss_rpn_cls: 0.003775  loss_rpn_loc: 0.01135  time: 2.6163  data_time: 0.0348  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:17:11 d2.utils.events]: \u001b[0m eta: 4:29:41  iter: 4499  total_loss: 0.1812  loss_cls: 0.05802  loss_box_reg: 0.06085  loss_rpn_cls: 0.006448  loss_rpn_loc: 0.02756  time: 2.6166  data_time: 0.0298  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:18:05 d2.utils.events]: \u001b[0m eta: 4:28:43  iter: 4519  total_loss: 0.1717  loss_cls: 0.06721  loss_box_reg: 0.06056  loss_rpn_cls: 0.006737  loss_rpn_loc: 0.02361  time: 2.6168  data_time: 0.0304  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:19:00 d2.utils.events]: \u001b[0m eta: 4:27:35  iter: 4539  total_loss: 0.1408  loss_cls: 0.06097  loss_box_reg: 0.04772  loss_rpn_cls: 0.003425  loss_rpn_loc: 0.01522  time: 2.6175  data_time: 0.0294  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:19:52 d2.utils.events]: \u001b[0m eta: 4:26:54  iter: 4559  total_loss: 0.1251  loss_cls: 0.06087  loss_box_reg: 0.04936  loss_rpn_cls: 0.003616  loss_rpn_loc: 0.01804  time: 2.6174  data_time: 0.0302  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:20:47 d2.utils.events]: \u001b[0m eta: 4:26:08  iter: 4579  total_loss: 0.1804  loss_cls: 0.07184  loss_box_reg: 0.06475  loss_rpn_cls: 0.004612  loss_rpn_loc: 0.02098  time: 2.6180  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:21:39 d2.utils.events]: \u001b[0m eta: 4:25:24  iter: 4599  total_loss: 0.1878  loss_cls: 0.08831  loss_box_reg: 0.06834  loss_rpn_cls: 0.00487  loss_rpn_loc: 0.02329  time: 2.6179  data_time: 0.0254  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:22:30 d2.utils.events]: \u001b[0m eta: 4:24:31  iter: 4619  total_loss: 0.177  loss_cls: 0.08543  loss_box_reg: 0.0592  loss_rpn_cls: 0.004612  loss_rpn_loc: 0.0197  time: 2.6176  data_time: 0.0304  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:23:21 d2.utils.events]: \u001b[0m eta: 4:23:25  iter: 4639  total_loss: 0.1673  loss_cls: 0.07176  loss_box_reg: 0.06043  loss_rpn_cls: 0.005017  loss_rpn_loc: 0.01703  time: 2.6174  data_time: 0.0289  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:24:13 d2.utils.events]: \u001b[0m eta: 4:22:34  iter: 4659  total_loss: 0.1193  loss_cls: 0.05432  loss_box_reg: 0.04433  loss_rpn_cls: 0.002632  loss_rpn_loc: 0.0168  time: 2.6173  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:25:04 d2.utils.events]: \u001b[0m eta: 4:21:49  iter: 4679  total_loss: 0.1596  loss_cls: 0.07069  loss_box_reg: 0.06311  loss_rpn_cls: 0.003295  loss_rpn_loc: 0.0216  time: 2.6169  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:25:56 d2.utils.events]: \u001b[0m eta: 4:20:50  iter: 4699  total_loss: 0.136  loss_cls: 0.06386  loss_box_reg: 0.05301  loss_rpn_cls: 0.004305  loss_rpn_loc: 0.01049  time: 2.6168  data_time: 0.0281  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:26:46 d2.utils.events]: \u001b[0m eta: 4:19:52  iter: 4719  total_loss: 0.149  loss_cls: 0.07125  loss_box_reg: 0.05217  loss_rpn_cls: 0.002107  loss_rpn_loc: 0.01394  time: 2.6163  data_time: 0.0318  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:27:39 d2.utils.events]: \u001b[0m eta: 4:18:59  iter: 4739  total_loss: 0.149  loss_cls: 0.06836  loss_box_reg: 0.05672  loss_rpn_cls: 0.001839  loss_rpn_loc: 0.01333  time: 2.6165  data_time: 0.0328  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:28:32 d2.utils.events]: \u001b[0m eta: 4:18:09  iter: 4759  total_loss: 0.1392  loss_cls: 0.06456  loss_box_reg: 0.06114  loss_rpn_cls: 0.003514  loss_rpn_loc: 0.01538  time: 2.6166  data_time: 0.0323  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:29:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 04:29:15 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 04:29:15 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 04:29:15 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 04:29:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 04:29:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 04:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1724 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 04:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 31/310. 0.2285 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/30 04:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 50/310. 0.2250 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/30 04:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 63/310. 0.2192 s / img. ETA=0:01:11\n",
      "\u001b[32m[04/30 04:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2150 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 04:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2090 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/30 04:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 117/310. 0.2041 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 04:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 138/310. 0.1995 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/30 04:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 162/310. 0.1974 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/30 04:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 185/310. 0.1960 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/30 04:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 209/310. 0.1938 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 04:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 236/310. 0.1915 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 04:30:20 d2.evaluation.evaluator]: \u001b[0mInference done 257/310. 0.1904 s / img. ETA=0:00:13\n",
      "\u001b[32m[04/30 04:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 280/310. 0.1891 s / img. ETA=0:00:07\n",
      "\u001b[32m[04/30 04:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 305/310. 0.1895 s / img. ETA=0:00:01\n",
      "\u001b[32m[04/30 04:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.194621 (0.243261 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 04:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.190250 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 04:30:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 04:30:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 04:30:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.238 | 25.232 | 18.331 | 3.127 | 16.167 | 19.001 |\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 42.684 | Carton          | 34.429 | Bottle cap     | 32.357 |\n",
      "| Can                   | 30.546 | Pop tab         | 9.992  | Cup            | 33.462 |\n",
      "| Plastic bag & wrapper | 28.707 | Styrofoam piece | 13.850 | Other plastic  | 7.117  |\n",
      "| Plastic container     | 27.468 | Paper           | 12.319 | Lid            | 15.736 |\n",
      "| Straw                 | 19.645 | Paper bag       | 25.248 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 50.330 | Glass jar       | 10.099 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 24.455 |\n",
      "| Unlabeled litter      | 2.106  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 18.851 | Cigarette       | 15.275 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 04:30:32 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 04:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: 16.2384,25.2323,18.3310,3.1275,16.1673,19.0009\n",
      "\u001b[32m[04/30 04:30:43 d2.utils.events]: \u001b[0m eta: 4:17:19  iter: 4779  total_loss: 0.1631  loss_cls: 0.07733  loss_box_reg: 0.06531  loss_rpn_cls: 0.002869  loss_rpn_loc: 0.01766  time: 2.6170  data_time: 0.0330  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:31:34 d2.utils.events]: \u001b[0m eta: 4:16:18  iter: 4799  total_loss: 0.1629  loss_cls: 0.0838  loss_box_reg: 0.06516  loss_rpn_cls: 0.003141  loss_rpn_loc: 0.01597  time: 2.6169  data_time: 0.0292  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:32:28 d2.utils.events]: \u001b[0m eta: 4:15:33  iter: 4819  total_loss: 0.1777  loss_cls: 0.07861  loss_box_reg: 0.0534  loss_rpn_cls: 0.004198  loss_rpn_loc: 0.02231  time: 2.6171  data_time: 0.0341  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:33:20 d2.utils.events]: \u001b[0m eta: 4:14:40  iter: 4839  total_loss: 0.1412  loss_cls: 0.06183  loss_box_reg: 0.05257  loss_rpn_cls: 0.003115  loss_rpn_loc: 0.009769  time: 2.6171  data_time: 0.0238  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:34:11 d2.utils.events]: \u001b[0m eta: 4:13:45  iter: 4859  total_loss: 0.1752  loss_cls: 0.08064  loss_box_reg: 0.06262  loss_rpn_cls: 0.003225  loss_rpn_loc: 0.01941  time: 2.6168  data_time: 0.0256  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:35:02 d2.utils.events]: \u001b[0m eta: 4:12:59  iter: 4879  total_loss: 0.2079  loss_cls: 0.08192  loss_box_reg: 0.07471  loss_rpn_cls: 0.004846  loss_rpn_loc: 0.01832  time: 2.6165  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:35:55 d2.utils.events]: \u001b[0m eta: 4:12:05  iter: 4899  total_loss: 0.1376  loss_cls: 0.06313  loss_box_reg: 0.05398  loss_rpn_cls: 0.002247  loss_rpn_loc: 0.01898  time: 2.6167  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:36:48 d2.utils.events]: \u001b[0m eta: 4:11:15  iter: 4919  total_loss: 0.1546  loss_cls: 0.07547  loss_box_reg: 0.06118  loss_rpn_cls: 0.004022  loss_rpn_loc: 0.01734  time: 2.6167  data_time: 0.0281  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:37:40 d2.utils.events]: \u001b[0m eta: 4:10:13  iter: 4939  total_loss: 0.1674  loss_cls: 0.07387  loss_box_reg: 0.06773  loss_rpn_cls: 0.002053  loss_rpn_loc: 0.0155  time: 2.6166  data_time: 0.0308  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:38:29 d2.utils.events]: \u001b[0m eta: 4:09:04  iter: 4959  total_loss: 0.1324  loss_cls: 0.06055  loss_box_reg: 0.04771  loss_rpn_cls: 0.002114  loss_rpn_loc: 0.01006  time: 2.6160  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:39:21 d2.utils.events]: \u001b[0m eta: 4:08:01  iter: 4979  total_loss: 0.1139  loss_cls: 0.05646  loss_box_reg: 0.04451  loss_rpn_cls: 0.002746  loss_rpn_loc: 0.014  time: 2.6160  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:40:14 d2.utils.events]: \u001b[0m eta: 4:07:04  iter: 4999  total_loss: 0.1645  loss_cls: 0.065  loss_box_reg: 0.05348  loss_rpn_cls: 0.0028  loss_rpn_loc: 0.01841  time: 2.6158  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:41:07 d2.utils.events]: \u001b[0m eta: 4:06:37  iter: 5019  total_loss: 0.1711  loss_cls: 0.06762  loss_box_reg: 0.07088  loss_rpn_cls: 0.004031  loss_rpn_loc: 0.02276  time: 2.6159  data_time: 0.0240  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:41:58 d2.utils.events]: \u001b[0m eta: 4:05:45  iter: 5039  total_loss: 0.1525  loss_cls: 0.07371  loss_box_reg: 0.05559  loss_rpn_cls: 0.002823  loss_rpn_loc: 0.01915  time: 2.6157  data_time: 0.0256  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:42:50 d2.utils.events]: \u001b[0m eta: 4:04:46  iter: 5059  total_loss: 0.158  loss_cls: 0.07317  loss_box_reg: 0.05573  loss_rpn_cls: 0.004122  loss_rpn_loc: 0.01766  time: 2.6157  data_time: 0.0298  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:43:43 d2.utils.events]: \u001b[0m eta: 4:04:07  iter: 5079  total_loss: 0.1221  loss_cls: 0.05661  loss_box_reg: 0.04804  loss_rpn_cls: 0.003236  loss_rpn_loc: 0.01468  time: 2.6159  data_time: 0.0334  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:44:36 d2.utils.events]: \u001b[0m eta: 4:03:10  iter: 5099  total_loss: 0.163  loss_cls: 0.06679  loss_box_reg: 0.05314  loss_rpn_cls: 0.003543  loss_rpn_loc: 0.01727  time: 2.6159  data_time: 0.0313  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:45:29 d2.utils.events]: \u001b[0m eta: 4:02:24  iter: 5119  total_loss: 0.1493  loss_cls: 0.0703  loss_box_reg: 0.0579  loss_rpn_cls: 0.004545  loss_rpn_loc: 0.01228  time: 2.6160  data_time: 0.0302  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:46:20 d2.utils.events]: \u001b[0m eta: 4:01:39  iter: 5139  total_loss: 0.1288  loss_cls: 0.06166  loss_box_reg: 0.04548  loss_rpn_cls: 0.004638  loss_rpn_loc: 0.01403  time: 2.6157  data_time: 0.0317  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:47:14 d2.utils.events]: \u001b[0m eta: 4:00:54  iter: 5159  total_loss: 0.1989  loss_cls: 0.07614  loss_box_reg: 0.05929  loss_rpn_cls: 0.003977  loss_rpn_loc: 0.01832  time: 2.6162  data_time: 0.0308  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:48:06 d2.utils.events]: \u001b[0m eta: 4:00:02  iter: 5179  total_loss: 0.1381  loss_cls: 0.06318  loss_box_reg: 0.05075  loss_rpn_cls: 0.004481  loss_rpn_loc: 0.01913  time: 2.6160  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:48:55 d2.utils.events]: \u001b[0m eta: 3:59:10  iter: 5199  total_loss: 0.1835  loss_cls: 0.08058  loss_box_reg: 0.06094  loss_rpn_cls: 0.005035  loss_rpn_loc: 0.02147  time: 2.6155  data_time: 0.0305  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:49:47 d2.utils.events]: \u001b[0m eta: 3:58:17  iter: 5219  total_loss: 0.2096  loss_cls: 0.09974  loss_box_reg: 0.0771  loss_rpn_cls: 0.006094  loss_rpn_loc: 0.0203  time: 2.6153  data_time: 0.0273  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:50:38 d2.utils.events]: \u001b[0m eta: 3:57:22  iter: 5239  total_loss: 0.2019  loss_cls: 0.09959  loss_box_reg: 0.07272  loss_rpn_cls: 0.005932  loss_rpn_loc: 0.01712  time: 2.6150  data_time: 0.0239  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:51:30 d2.utils.events]: \u001b[0m eta: 3:56:35  iter: 5259  total_loss: 0.1413  loss_cls: 0.0637  loss_box_reg: 0.05351  loss_rpn_cls: 0.003184  loss_rpn_loc: 0.01565  time: 2.6150  data_time: 0.0298  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:52:22 d2.utils.events]: \u001b[0m eta: 3:55:45  iter: 5279  total_loss: 0.1146  loss_cls: 0.05257  loss_box_reg: 0.04796  loss_rpn_cls: 0.002652  loss_rpn_loc: 0.01283  time: 2.6150  data_time: 0.0292  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:53:13 d2.utils.events]: \u001b[0m eta: 3:54:50  iter: 5299  total_loss: 0.1814  loss_cls: 0.07519  loss_box_reg: 0.05739  loss_rpn_cls: 0.006448  loss_rpn_loc: 0.01372  time: 2.6146  data_time: 0.0527  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:54:05 d2.utils.events]: \u001b[0m eta: 3:54:02  iter: 5319  total_loss: 0.1638  loss_cls: 0.06431  loss_box_reg: 0.05205  loss_rpn_cls: 0.003374  loss_rpn_loc: 0.01742  time: 2.6146  data_time: 0.0292  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:54:56 d2.utils.events]: \u001b[0m eta: 3:53:09  iter: 5339  total_loss: 0.1653  loss_cls: 0.07598  loss_box_reg: 0.06048  loss_rpn_cls: 0.005442  loss_rpn_loc: 0.02478  time: 2.6144  data_time: 0.0298  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:55:51 d2.utils.events]: \u001b[0m eta: 3:52:17  iter: 5359  total_loss: 0.1785  loss_cls: 0.07783  loss_box_reg: 0.05801  loss_rpn_cls: 0.004116  loss_rpn_loc: 0.02309  time: 2.6150  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:56:45 d2.utils.events]: \u001b[0m eta: 3:51:43  iter: 5379  total_loss: 0.1471  loss_cls: 0.06639  loss_box_reg: 0.05606  loss_rpn_cls: 0.002589  loss_rpn_loc: 0.01357  time: 2.6153  data_time: 0.0239  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:57:37 d2.utils.events]: \u001b[0m eta: 3:50:54  iter: 5399  total_loss: 0.2335  loss_cls: 0.1076  loss_box_reg: 0.08835  loss_rpn_cls: 0.006748  loss_rpn_loc: 0.03598  time: 2.6151  data_time: 0.0272  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:58:28 d2.utils.events]: \u001b[0m eta: 3:50:02  iter: 5419  total_loss: 0.1768  loss_cls: 0.06917  loss_box_reg: 0.0696  loss_rpn_cls: 0.003405  loss_rpn_loc: 0.01602  time: 2.6149  data_time: 0.0287  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 04:59:21 d2.utils.events]: \u001b[0m eta: 3:49:05  iter: 5439  total_loss: 0.2006  loss_cls: 0.08154  loss_box_reg: 0.07185  loss_rpn_cls: 0.006909  loss_rpn_loc: 0.0266  time: 2.6150  data_time: 0.0286  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:00:13 d2.utils.events]: \u001b[0m eta: 3:48:12  iter: 5459  total_loss: 0.1309  loss_cls: 0.06435  loss_box_reg: 0.04709  loss_rpn_cls: 0.001583  loss_rpn_loc: 0.01159  time: 2.6150  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:01:04 d2.utils.events]: \u001b[0m eta: 3:47:21  iter: 5479  total_loss: 0.1489  loss_cls: 0.05854  loss_box_reg: 0.05532  loss_rpn_cls: 0.005254  loss_rpn_loc: 0.02384  time: 2.6147  data_time: 0.0321  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:01:53 d2.utils.events]: \u001b[0m eta: 3:46:14  iter: 5499  total_loss: 0.1205  loss_cls: 0.04659  loss_box_reg: 0.0482  loss_rpn_cls: 0.001845  loss_rpn_loc: 0.01079  time: 2.6142  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:02:46 d2.utils.events]: \u001b[0m eta: 3:45:18  iter: 5519  total_loss: 0.1105  loss_cls: 0.05046  loss_box_reg: 0.04295  loss_rpn_cls: 0.00249  loss_rpn_loc: 0.01278  time: 2.6142  data_time: 0.0288  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:03:37 d2.utils.events]: \u001b[0m eta: 3:44:22  iter: 5539  total_loss: 0.1469  loss_cls: 0.06606  loss_box_reg: 0.04857  loss_rpn_cls: 0.001922  loss_rpn_loc: 0.01093  time: 2.6140  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:04:31 d2.utils.events]: \u001b[0m eta: 3:43:30  iter: 5559  total_loss: 0.1602  loss_cls: 0.07093  loss_box_reg: 0.0601  loss_rpn_cls: 0.003417  loss_rpn_loc: 0.01492  time: 2.6143  data_time: 0.0287  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:05:24 d2.utils.events]: \u001b[0m eta: 3:42:33  iter: 5579  total_loss: 0.1612  loss_cls: 0.07111  loss_box_reg: 0.06402  loss_rpn_cls: 0.003542  loss_rpn_loc: 0.01996  time: 2.6145  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:06:18 d2.utils.events]: \u001b[0m eta: 3:41:51  iter: 5599  total_loss: 0.1181  loss_cls: 0.05153  loss_box_reg: 0.04772  loss_rpn_cls: 0.004129  loss_rpn_loc: 0.0105  time: 2.6147  data_time: 0.0251  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:07:11 d2.utils.events]: \u001b[0m eta: 3:41:16  iter: 5619  total_loss: 0.1327  loss_cls: 0.05785  loss_box_reg: 0.04381  loss_rpn_cls: 0.005252  loss_rpn_loc: 0.01373  time: 2.6149  data_time: 0.0298  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:08:06 d2.utils.events]: \u001b[0m eta: 3:40:29  iter: 5639  total_loss: 0.1803  loss_cls: 0.08518  loss_box_reg: 0.07713  loss_rpn_cls: 0.003802  loss_rpn_loc: 0.0198  time: 2.6153  data_time: 0.0269  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:08:57 d2.utils.events]: \u001b[0m eta: 3:39:35  iter: 5659  total_loss: 0.1532  loss_cls: 0.05859  loss_box_reg: 0.05734  loss_rpn_cls: 0.002584  loss_rpn_loc: 0.02253  time: 2.6151  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:09:49 d2.utils.events]: \u001b[0m eta: 3:38:47  iter: 5679  total_loss: 0.1601  loss_cls: 0.07085  loss_box_reg: 0.0648  loss_rpn_cls: 0.002603  loss_rpn_loc: 0.02305  time: 2.6151  data_time: 0.0316  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:10:43 d2.utils.events]: \u001b[0m eta: 3:38:06  iter: 5699  total_loss: 0.1831  loss_cls: 0.08678  loss_box_reg: 0.06306  loss_rpn_cls: 0.00278  loss_rpn_loc: 0.01538  time: 2.6153  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:11:36 d2.utils.events]: \u001b[0m eta: 3:37:25  iter: 5719  total_loss: 0.174  loss_cls: 0.06896  loss_box_reg: 0.06094  loss_rpn_cls: 0.002937  loss_rpn_loc: 0.02178  time: 2.6155  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:12:27 d2.utils.events]: \u001b[0m eta: 3:36:28  iter: 5739  total_loss: 0.1507  loss_cls: 0.07403  loss_box_reg: 0.06095  loss_rpn_cls: 0.004356  loss_rpn_loc: 0.01732  time: 2.6153  data_time: 0.0253  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:13:20 d2.utils.events]: \u001b[0m eta: 3:35:33  iter: 5759  total_loss: 0.1272  loss_cls: 0.05309  loss_box_reg: 0.05246  loss_rpn_cls: 0.001755  loss_rpn_loc: 0.01193  time: 2.6154  data_time: 0.0306  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:14:13 d2.utils.events]: \u001b[0m eta: 3:34:41  iter: 5779  total_loss: 0.2059  loss_cls: 0.08851  loss_box_reg: 0.06367  loss_rpn_cls: 0.004906  loss_rpn_loc: 0.02577  time: 2.6155  data_time: 0.0322  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:15:07 d2.utils.events]: \u001b[0m eta: 3:34:00  iter: 5799  total_loss: 0.107  loss_cls: 0.04882  loss_box_reg: 0.04018  loss_rpn_cls: 0.003621  loss_rpn_loc: 0.007555  time: 2.6158  data_time: 0.0298  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:16:00 d2.utils.events]: \u001b[0m eta: 3:33:08  iter: 5819  total_loss: 0.1602  loss_cls: 0.06274  loss_box_reg: 0.05611  loss_rpn_cls: 0.002607  loss_rpn_loc: 0.01447  time: 2.6159  data_time: 0.0278  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:16:54 d2.utils.events]: \u001b[0m eta: 3:32:17  iter: 5839  total_loss: 0.1095  loss_cls: 0.05804  loss_box_reg: 0.04866  loss_rpn_cls: 0.002003  loss_rpn_loc: 0.01137  time: 2.6162  data_time: 0.0279  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:17:47 d2.utils.events]: \u001b[0m eta: 3:31:25  iter: 5859  total_loss: 0.1913  loss_cls: 0.0929  loss_box_reg: 0.07237  loss_rpn_cls: 0.003184  loss_rpn_loc: 0.01767  time: 2.6163  data_time: 0.0301  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:18:41 d2.utils.events]: \u001b[0m eta: 3:30:39  iter: 5879  total_loss: 0.1483  loss_cls: 0.06348  loss_box_reg: 0.06578  loss_rpn_cls: 0.004056  loss_rpn_loc: 0.01253  time: 2.6166  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:19:35 d2.utils.events]: \u001b[0m eta: 3:29:49  iter: 5899  total_loss: 0.161  loss_cls: 0.07371  loss_box_reg: 0.06248  loss_rpn_cls: 0.003871  loss_rpn_loc: 0.02131  time: 2.6169  data_time: 0.0249  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:20:27 d2.utils.events]: \u001b[0m eta: 3:28:52  iter: 5919  total_loss: 0.1513  loss_cls: 0.07708  loss_box_reg: 0.05269  loss_rpn_cls: 0.00338  loss_rpn_loc: 0.01229  time: 2.6167  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:21:19 d2.utils.events]: \u001b[0m eta: 3:27:58  iter: 5939  total_loss: 0.123  loss_cls: 0.05276  loss_box_reg: 0.04811  loss_rpn_cls: 0.001843  loss_rpn_loc: 0.01194  time: 2.6167  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:22:09 d2.utils.events]: \u001b[0m eta: 3:27:05  iter: 5959  total_loss: 0.1655  loss_cls: 0.07027  loss_box_reg: 0.06074  loss_rpn_cls: 0.004436  loss_rpn_loc: 0.02453  time: 2.6163  data_time: 0.0251  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:22:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 05:22:34 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 05:22:34 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 05:22:34 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 05:22:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 05:22:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 05:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1890 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/30 05:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2296 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 05:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 48/310. 0.2313 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 05:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 63/310. 0.2201 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/30 05:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2153 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 05:23:04 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2078 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/30 05:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 117/310. 0.2034 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 05:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 140/310. 0.1990 s / img. ETA=0:00:47\n",
      "\u001b[32m[04/30 05:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 163/310. 0.1972 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/30 05:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 185/310. 0.1956 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/30 05:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 210/310. 0.1939 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 05:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 236/310. 0.1929 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 05:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 257/310. 0.1919 s / img. ETA=0:00:13\n",
      "\u001b[32m[04/30 05:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 280/310. 0.1905 s / img. ETA=0:00:07\n",
      "\u001b[32m[04/30 05:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 305/310. 0.1906 s / img. ETA=0:00:01\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.248123 (0.243436 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.191159 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.948 | 25.862 | 19.791 | 3.458 | 15.935 | 18.562 |\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 37.851 | Carton          | 32.345 | Bottle cap     | 25.030 |\n",
      "| Can                   | 33.574 | Pop tab         | 10.790 | Cup            | 31.309 |\n",
      "| Plastic bag & wrapper | 31.908 | Styrofoam piece | 14.224 | Other plastic  | 5.999  |\n",
      "| Plastic container     | 20.495 | Paper           | 12.427 | Lid            | 18.498 |\n",
      "| Straw                 | 18.488 | Paper bag       | 14.475 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 54.602 | Glass jar       | 30.297 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 10.099 | Aluminium foil | 18.416 |\n",
      "| Unlabeled litter      | 2.133  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 9.762  | Cigarette       | 13.826 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 05:23:51 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 05:23:51 d2.evaluation.testing]: \u001b[0mcopypaste: 15.9482,25.8624,19.7911,3.4575,15.9354,18.5618\n",
      "\u001b[32m[04/30 05:24:18 d2.utils.events]: \u001b[0m eta: 3:26:13  iter: 5979  total_loss: 0.1535  loss_cls: 0.07312  loss_box_reg: 0.06066  loss_rpn_cls: 0.003169  loss_rpn_loc: 0.01222  time: 2.6159  data_time: 0.0334  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:25:09 d2.utils.events]: \u001b[0m eta: 3:25:21  iter: 5999  total_loss: 0.1526  loss_cls: 0.07325  loss_box_reg: 0.06036  loss_rpn_cls: 0.003303  loss_rpn_loc: 0.01691  time: 2.6159  data_time: 0.0332  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:26:03 d2.utils.events]: \u001b[0m eta: 3:24:23  iter: 6019  total_loss: 0.1482  loss_cls: 0.05605  loss_box_reg: 0.04666  loss_rpn_cls: 0.003284  loss_rpn_loc: 0.02865  time: 2.6161  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:26:56 d2.utils.events]: \u001b[0m eta: 3:23:31  iter: 6039  total_loss: 0.1505  loss_cls: 0.06795  loss_box_reg: 0.05214  loss_rpn_cls: 0.003714  loss_rpn_loc: 0.01088  time: 2.6161  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:27:48 d2.utils.events]: \u001b[0m eta: 3:22:45  iter: 6059  total_loss: 0.1851  loss_cls: 0.08441  loss_box_reg: 0.0709  loss_rpn_cls: 0.002781  loss_rpn_loc: 0.02022  time: 2.6160  data_time: 0.0327  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:28:40 d2.utils.events]: \u001b[0m eta: 3:21:51  iter: 6079  total_loss: 0.1423  loss_cls: 0.062  loss_box_reg: 0.06209  loss_rpn_cls: 0.002911  loss_rpn_loc: 0.01196  time: 2.6161  data_time: 0.0281  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:29:32 d2.utils.events]: \u001b[0m eta: 3:21:01  iter: 6099  total_loss: 0.2066  loss_cls: 0.08852  loss_box_reg: 0.08268  loss_rpn_cls: 0.003106  loss_rpn_loc: 0.02771  time: 2.6160  data_time: 0.0328  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:30:27 d2.utils.events]: \u001b[0m eta: 3:20:13  iter: 6119  total_loss: 0.1369  loss_cls: 0.06743  loss_box_reg: 0.0481  loss_rpn_cls: 0.00345  loss_rpn_loc: 0.01345  time: 2.6164  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:31:21 d2.utils.events]: \u001b[0m eta: 3:19:21  iter: 6139  total_loss: 0.1505  loss_cls: 0.06772  loss_box_reg: 0.06002  loss_rpn_cls: 0.004964  loss_rpn_loc: 0.01471  time: 2.6167  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:32:14 d2.utils.events]: \u001b[0m eta: 3:18:26  iter: 6159  total_loss: 0.1653  loss_cls: 0.06251  loss_box_reg: 0.05639  loss_rpn_cls: 0.00388  loss_rpn_loc: 0.01286  time: 2.6168  data_time: 0.0260  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:33:05 d2.utils.events]: \u001b[0m eta: 3:17:37  iter: 6179  total_loss: 0.1248  loss_cls: 0.06033  loss_box_reg: 0.04898  loss_rpn_cls: 0.003225  loss_rpn_loc: 0.009977  time: 2.6166  data_time: 0.0306  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:33:54 d2.utils.events]: \u001b[0m eta: 3:16:41  iter: 6199  total_loss: 0.1379  loss_cls: 0.06527  loss_box_reg: 0.04606  loss_rpn_cls: 0.004373  loss_rpn_loc: 0.01853  time: 2.6161  data_time: 0.0283  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:34:47 d2.utils.events]: \u001b[0m eta: 3:15:51  iter: 6219  total_loss: 0.1897  loss_cls: 0.0663  loss_box_reg: 0.05521  loss_rpn_cls: 0.00459  loss_rpn_loc: 0.01954  time: 2.6161  data_time: 0.0260  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:35:40 d2.utils.events]: \u001b[0m eta: 3:15:08  iter: 6239  total_loss: 0.1488  loss_cls: 0.06645  loss_box_reg: 0.05086  loss_rpn_cls: 0.002734  loss_rpn_loc: 0.01622  time: 2.6162  data_time: 0.0357  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:36:31 d2.utils.events]: \u001b[0m eta: 3:14:16  iter: 6259  total_loss: 0.1469  loss_cls: 0.0645  loss_box_reg: 0.05077  loss_rpn_cls: 0.00385  loss_rpn_loc: 0.0172  time: 2.6161  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:37:24 d2.utils.events]: \u001b[0m eta: 3:13:22  iter: 6279  total_loss: 0.163  loss_cls: 0.06826  loss_box_reg: 0.05793  loss_rpn_cls: 0.003206  loss_rpn_loc: 0.01357  time: 2.6161  data_time: 0.0261  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:38:16 d2.utils.events]: \u001b[0m eta: 3:12:34  iter: 6299  total_loss: 0.1521  loss_cls: 0.06641  loss_box_reg: 0.05367  loss_rpn_cls: 0.002978  loss_rpn_loc: 0.01167  time: 2.6161  data_time: 0.0270  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:39:09 d2.utils.events]: \u001b[0m eta: 3:11:44  iter: 6319  total_loss: 0.1425  loss_cls: 0.05469  loss_box_reg: 0.0455  loss_rpn_cls: 0.003089  loss_rpn_loc: 0.01804  time: 2.6161  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:39:59 d2.utils.events]: \u001b[0m eta: 3:10:50  iter: 6339  total_loss: 0.1428  loss_cls: 0.0688  loss_box_reg: 0.05644  loss_rpn_cls: 0.00543  loss_rpn_loc: 0.00857  time: 2.6158  data_time: 0.0302  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:40:50 d2.utils.events]: \u001b[0m eta: 3:10:00  iter: 6359  total_loss: 0.1235  loss_cls: 0.06668  loss_box_reg: 0.04993  loss_rpn_cls: 0.004239  loss_rpn_loc: 0.02375  time: 2.6157  data_time: 0.0324  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:41:43 d2.utils.events]: \u001b[0m eta: 3:08:57  iter: 6379  total_loss: 0.1859  loss_cls: 0.07909  loss_box_reg: 0.06266  loss_rpn_cls: 0.004676  loss_rpn_loc: 0.02669  time: 2.6157  data_time: 0.0328  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:42:36 d2.utils.events]: \u001b[0m eta: 3:08:10  iter: 6399  total_loss: 0.1496  loss_cls: 0.06558  loss_box_reg: 0.05118  loss_rpn_cls: 0.001825  loss_rpn_loc: 0.01323  time: 2.6159  data_time: 0.0315  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:43:27 d2.utils.events]: \u001b[0m eta: 3:07:17  iter: 6419  total_loss: 0.1465  loss_cls: 0.07079  loss_box_reg: 0.05459  loss_rpn_cls: 0.002754  loss_rpn_loc: 0.02379  time: 2.6157  data_time: 0.0333  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:44:19 d2.utils.events]: \u001b[0m eta: 3:06:25  iter: 6439  total_loss: 0.1276  loss_cls: 0.05642  loss_box_reg: 0.05549  loss_rpn_cls: 0.003818  loss_rpn_loc: 0.02117  time: 2.6156  data_time: 0.0380  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:45:12 d2.utils.events]: \u001b[0m eta: 3:05:26  iter: 6459  total_loss: 0.1293  loss_cls: 0.05433  loss_box_reg: 0.04792  loss_rpn_cls: 0.002561  loss_rpn_loc: 0.01258  time: 2.6157  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:46:04 d2.utils.events]: \u001b[0m eta: 3:04:37  iter: 6479  total_loss: 0.2199  loss_cls: 0.07732  loss_box_reg: 0.08278  loss_rpn_cls: 0.004422  loss_rpn_loc: 0.02678  time: 2.6157  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:46:56 d2.utils.events]: \u001b[0m eta: 3:03:52  iter: 6499  total_loss: 0.1526  loss_cls: 0.05802  loss_box_reg: 0.0559  loss_rpn_cls: 0.003637  loss_rpn_loc: 0.01264  time: 2.6156  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:47:48 d2.utils.events]: \u001b[0m eta: 3:03:00  iter: 6519  total_loss: 0.1595  loss_cls: 0.06133  loss_box_reg: 0.05369  loss_rpn_cls: 0.004045  loss_rpn_loc: 0.0134  time: 2.6156  data_time: 0.0273  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:48:43 d2.utils.events]: \u001b[0m eta: 3:02:11  iter: 6539  total_loss: 0.1599  loss_cls: 0.0706  loss_box_reg: 0.06242  loss_rpn_cls: 0.003168  loss_rpn_loc: 0.01309  time: 2.6160  data_time: 0.0275  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:49:40 d2.utils.events]: \u001b[0m eta: 3:01:19  iter: 6559  total_loss: 0.1527  loss_cls: 0.06185  loss_box_reg: 0.0587  loss_rpn_cls: 0.001524  loss_rpn_loc: 0.01446  time: 2.6166  data_time: 0.0261  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:50:32 d2.utils.events]: \u001b[0m eta: 3:00:24  iter: 6579  total_loss: 0.184  loss_cls: 0.07674  loss_box_reg: 0.07116  loss_rpn_cls: 0.003721  loss_rpn_loc: 0.0183  time: 2.6165  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:51:23 d2.utils.events]: \u001b[0m eta: 2:59:30  iter: 6599  total_loss: 0.1675  loss_cls: 0.07589  loss_box_reg: 0.06591  loss_rpn_cls: 0.004775  loss_rpn_loc: 0.02092  time: 2.6163  data_time: 0.0293  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:52:16 d2.utils.events]: \u001b[0m eta: 2:58:30  iter: 6619  total_loss: 0.176  loss_cls: 0.08033  loss_box_reg: 0.0596  loss_rpn_cls: 0.002321  loss_rpn_loc: 0.01699  time: 2.6164  data_time: 0.0282  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:53:06 d2.utils.events]: \u001b[0m eta: 2:57:34  iter: 6639  total_loss: 0.1153  loss_cls: 0.04467  loss_box_reg: 0.05456  loss_rpn_cls: 0.003069  loss_rpn_loc: 0.01021  time: 2.6162  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:53:59 d2.utils.events]: \u001b[0m eta: 2:56:47  iter: 6659  total_loss: 0.1479  loss_cls: 0.06636  loss_box_reg: 0.05166  loss_rpn_cls: 0.002342  loss_rpn_loc: 0.0133  time: 2.6162  data_time: 0.0464  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:54:51 d2.utils.events]: \u001b[0m eta: 2:55:50  iter: 6679  total_loss: 0.1967  loss_cls: 0.07945  loss_box_reg: 0.07096  loss_rpn_cls: 0.00349  loss_rpn_loc: 0.01989  time: 2.6162  data_time: 0.0321  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:55:44 d2.utils.events]: \u001b[0m eta: 2:54:53  iter: 6699  total_loss: 0.1324  loss_cls: 0.06245  loss_box_reg: 0.04932  loss_rpn_cls: 0.004564  loss_rpn_loc: 0.009102  time: 2.6163  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:56:36 d2.utils.events]: \u001b[0m eta: 2:53:58  iter: 6719  total_loss: 0.1161  loss_cls: 0.05063  loss_box_reg: 0.04806  loss_rpn_cls: 0.003439  loss_rpn_loc: 0.01253  time: 2.6162  data_time: 0.0266  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:57:27 d2.utils.events]: \u001b[0m eta: 2:53:12  iter: 6739  total_loss: 0.1553  loss_cls: 0.06713  loss_box_reg: 0.05465  loss_rpn_cls: 0.0036  loss_rpn_loc: 0.0157  time: 2.6161  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:58:21 d2.utils.events]: \u001b[0m eta: 2:52:17  iter: 6759  total_loss: 0.134  loss_cls: 0.06705  loss_box_reg: 0.04803  loss_rpn_cls: 0.004095  loss_rpn_loc: 0.01135  time: 2.6163  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 05:59:11 d2.utils.events]: \u001b[0m eta: 2:51:24  iter: 6779  total_loss: 0.1872  loss_cls: 0.07979  loss_box_reg: 0.06911  loss_rpn_cls: 0.004178  loss_rpn_loc: 0.02111  time: 2.6159  data_time: 0.0283  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:00:02 d2.utils.events]: \u001b[0m eta: 2:50:31  iter: 6799  total_loss: 0.1486  loss_cls: 0.06127  loss_box_reg: 0.05291  loss_rpn_cls: 0.006096  loss_rpn_loc: 0.01599  time: 2.6157  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:00:54 d2.utils.events]: \u001b[0m eta: 2:49:38  iter: 6819  total_loss: 0.1535  loss_cls: 0.07093  loss_box_reg: 0.06197  loss_rpn_cls: 0.005766  loss_rpn_loc: 0.02156  time: 2.6157  data_time: 0.0286  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:01:50 d2.utils.events]: \u001b[0m eta: 2:48:47  iter: 6839  total_loss: 0.1532  loss_cls: 0.06994  loss_box_reg: 0.05699  loss_rpn_cls: 0.004027  loss_rpn_loc: 0.01393  time: 2.6162  data_time: 0.0271  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:02:43 d2.utils.events]: \u001b[0m eta: 2:47:52  iter: 6859  total_loss: 0.1081  loss_cls: 0.05054  loss_box_reg: 0.04392  loss_rpn_cls: 0.003409  loss_rpn_loc: 0.0106  time: 2.6163  data_time: 0.0267  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:03:33 d2.utils.events]: \u001b[0m eta: 2:46:56  iter: 6879  total_loss: 0.1698  loss_cls: 0.06939  loss_box_reg: 0.06813  loss_rpn_cls: 0.005193  loss_rpn_loc: 0.0161  time: 2.6160  data_time: 0.0269  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:04:23 d2.utils.events]: \u001b[0m eta: 2:45:59  iter: 6899  total_loss: 0.1495  loss_cls: 0.06546  loss_box_reg: 0.05337  loss_rpn_cls: 0.002902  loss_rpn_loc: 0.01925  time: 2.6157  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:05:17 d2.utils.events]: \u001b[0m eta: 2:45:11  iter: 6919  total_loss: 0.1594  loss_cls: 0.07662  loss_box_reg: 0.06453  loss_rpn_cls: 0.002833  loss_rpn_loc: 0.01169  time: 2.6159  data_time: 0.0260  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:06:10 d2.utils.events]: \u001b[0m eta: 2:44:25  iter: 6939  total_loss: 0.1875  loss_cls: 0.07543  loss_box_reg: 0.07117  loss_rpn_cls: 0.003221  loss_rpn_loc: 0.01807  time: 2.6159  data_time: 0.0271  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:07:04 d2.utils.events]: \u001b[0m eta: 2:43:38  iter: 6959  total_loss: 0.1407  loss_cls: 0.06696  loss_box_reg: 0.05619  loss_rpn_cls: 0.002923  loss_rpn_loc: 0.01013  time: 2.6162  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:07:57 d2.utils.events]: \u001b[0m eta: 2:42:50  iter: 6979  total_loss: 0.1402  loss_cls: 0.06848  loss_box_reg: 0.05275  loss_rpn_cls: 0.003127  loss_rpn_loc: 0.01941  time: 2.6163  data_time: 0.0255  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:08:50 d2.utils.events]: \u001b[0m eta: 2:42:02  iter: 6999  total_loss: 0.1756  loss_cls: 0.07756  loss_box_reg: 0.05521  loss_rpn_cls: 0.003874  loss_rpn_loc: 0.03283  time: 2.6163  data_time: 0.0246  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:09:46 d2.utils.events]: \u001b[0m eta: 2:41:20  iter: 7019  total_loss: 0.1633  loss_cls: 0.07292  loss_box_reg: 0.06033  loss_rpn_cls: 0.003681  loss_rpn_loc: 0.0167  time: 2.6169  data_time: 0.0316  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:10:40 d2.utils.events]: \u001b[0m eta: 2:40:28  iter: 7039  total_loss: 0.1078  loss_cls: 0.04813  loss_box_reg: 0.04331  loss_rpn_cls: 0.003652  loss_rpn_loc: 0.01537  time: 2.6171  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:11:34 d2.utils.events]: \u001b[0m eta: 2:39:36  iter: 7059  total_loss: 0.152  loss_cls: 0.06536  loss_box_reg: 0.05118  loss_rpn_cls: 0.00427  loss_rpn_loc: 0.02093  time: 2.6173  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:12:25 d2.utils.events]: \u001b[0m eta: 2:38:36  iter: 7079  total_loss: 0.1862  loss_cls: 0.08139  loss_box_reg: 0.07297  loss_rpn_cls: 0.00414  loss_rpn_loc: 0.02155  time: 2.6171  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:13:18 d2.utils.events]: \u001b[0m eta: 2:37:51  iter: 7099  total_loss: 0.1715  loss_cls: 0.07191  loss_box_reg: 0.05917  loss_rpn_cls: 0.003907  loss_rpn_loc: 0.01624  time: 2.6173  data_time: 0.0318  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:14:07 d2.utils.events]: \u001b[0m eta: 2:36:46  iter: 7119  total_loss: 0.1627  loss_cls: 0.07158  loss_box_reg: 0.06404  loss_rpn_cls: 0.002884  loss_rpn_loc: 0.01798  time: 2.6168  data_time: 0.0304  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:15:00 d2.utils.events]: \u001b[0m eta: 2:35:54  iter: 7139  total_loss: 0.147  loss_cls: 0.06947  loss_box_reg: 0.05422  loss_rpn_cls: 0.004366  loss_rpn_loc: 0.01221  time: 2.6169  data_time: 0.0256  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:15:53 d2.utils.events]: \u001b[0m eta: 2:35:05  iter: 7159  total_loss: 0.1523  loss_cls: 0.06425  loss_box_reg: 0.04769  loss_rpn_cls: 0.005341  loss_rpn_loc: 0.02461  time: 2.6169  data_time: 0.0331  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:16:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 06:16:04 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 06:16:04 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 06:16:04 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 06:16:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 06:16:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 06:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1762 s / img. ETA=0:00:54\n",
      "\u001b[32m[04/30 06:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2208 s / img. ETA=0:01:03\n",
      "\u001b[32m[04/30 06:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 47/310. 0.2260 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/30 06:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 64/310. 0.2151 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 06:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2108 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 06:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2047 s / img. ETA=0:01:02\n",
      "\u001b[32m[04/30 06:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 116/310. 0.2011 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/30 06:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 138/310. 0.1965 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/30 06:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 164/310. 0.1951 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/30 06:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 187/310. 0.1936 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/30 06:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 212/310. 0.1912 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 06:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 236/310. 0.1901 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 06:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 260/310. 0.1886 s / img. ETA=0:00:12\n",
      "\u001b[32m[04/30 06:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 282/310. 0.1877 s / img. ETA=0:00:06\n",
      "\u001b[32m[04/30 06:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 307/310. 0.1883 s / img. ETA=0:00:00\n",
      "\u001b[32m[04/30 06:17:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.110868 (0.242986 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 06:17:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.188681 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 06:17:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 06:17:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 06:17:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.56 seconds.\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.14 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.758 | 24.744 | 20.220 | 2.695 | 16.203 | 19.495 |\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 42.619 | Carton          | 34.496 | Bottle cap     | 28.728 |\n",
      "| Can                   | 34.121 | Pop tab         | 8.122  | Cup            | 34.740 |\n",
      "| Plastic bag & wrapper | 31.173 | Styrofoam piece | 13.900 | Other plastic  | 6.291  |\n",
      "| Plastic container     | 26.068 | Paper           | 11.003 | Lid            | 17.885 |\n",
      "| Straw                 | 18.102 | Paper bag       | 20.198 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 59.716 | Glass jar       | 35.347 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 20.396 |\n",
      "| Unlabeled litter      | 1.943  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 9.257  | Cigarette       | 15.115 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n",
      "\u001b[32m[04/30 06:17:21 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 06:17:21 d2.evaluation.testing]: \u001b[0mcopypaste: 16.7579,24.7437,20.2201,2.6949,16.2032,19.4954\n",
      "\u001b[32m[04/30 06:18:02 d2.utils.events]: \u001b[0m eta: 2:34:13  iter: 7179  total_loss: 0.1564  loss_cls: 0.05842  loss_box_reg: 0.05339  loss_rpn_cls: 0.004251  loss_rpn_loc: 0.02171  time: 2.6170  data_time: 0.0283  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:18:58 d2.utils.events]: \u001b[0m eta: 2:33:25  iter: 7199  total_loss: 0.1483  loss_cls: 0.05722  loss_box_reg: 0.04742  loss_rpn_cls: 0.002522  loss_rpn_loc: 0.01487  time: 2.6174  data_time: 0.0252  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:19:48 d2.utils.events]: \u001b[0m eta: 2:32:32  iter: 7219  total_loss: 0.123  loss_cls: 0.04757  loss_box_reg: 0.04543  loss_rpn_cls: 0.001531  loss_rpn_loc: 0.007985  time: 2.6171  data_time: 0.0271  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:20:40 d2.utils.events]: \u001b[0m eta: 2:31:33  iter: 7239  total_loss: 0.138  loss_cls: 0.05059  loss_box_reg: 0.0508  loss_rpn_cls: 0.003111  loss_rpn_loc: 0.01945  time: 2.6171  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:21:34 d2.utils.events]: \u001b[0m eta: 2:30:46  iter: 7259  total_loss: 0.1411  loss_cls: 0.06962  loss_box_reg: 0.05697  loss_rpn_cls: 0.004435  loss_rpn_loc: 0.009406  time: 2.6172  data_time: 0.0315  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:22:25 d2.utils.events]: \u001b[0m eta: 2:29:54  iter: 7279  total_loss: 0.1531  loss_cls: 0.07206  loss_box_reg: 0.05605  loss_rpn_cls: 0.003089  loss_rpn_loc: 0.01531  time: 2.6171  data_time: 0.0283  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:23:17 d2.utils.events]: \u001b[0m eta: 2:28:57  iter: 7299  total_loss: 0.1538  loss_cls: 0.06162  loss_box_reg: 0.05346  loss_rpn_cls: 0.003917  loss_rpn_loc: 0.01735  time: 2.6170  data_time: 0.0259  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:24:07 d2.utils.events]: \u001b[0m eta: 2:27:59  iter: 7319  total_loss: 0.1509  loss_cls: 0.06782  loss_box_reg: 0.05461  loss_rpn_cls: 0.003119  loss_rpn_loc: 0.01395  time: 2.6167  data_time: 0.0278  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:24:59 d2.utils.events]: \u001b[0m eta: 2:27:11  iter: 7339  total_loss: 0.154  loss_cls: 0.065  loss_box_reg: 0.06659  loss_rpn_cls: 0.004257  loss_rpn_loc: 0.0185  time: 2.6167  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:25:50 d2.utils.events]: \u001b[0m eta: 2:26:11  iter: 7359  total_loss: 0.1422  loss_cls: 0.06469  loss_box_reg: 0.04952  loss_rpn_cls: 0.004432  loss_rpn_loc: 0.01815  time: 2.6164  data_time: 0.0305  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:26:42 d2.utils.events]: \u001b[0m eta: 2:25:21  iter: 7379  total_loss: 0.1617  loss_cls: 0.05852  loss_box_reg: 0.06204  loss_rpn_cls: 0.003451  loss_rpn_loc: 0.01691  time: 2.6165  data_time: 0.0264  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:27:33 d2.utils.events]: \u001b[0m eta: 2:24:24  iter: 7399  total_loss: 0.1532  loss_cls: 0.07236  loss_box_reg: 0.05622  loss_rpn_cls: 0.004808  loss_rpn_loc: 0.02273  time: 2.6162  data_time: 0.0330  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:28:24 d2.utils.events]: \u001b[0m eta: 2:23:34  iter: 7419  total_loss: 0.1855  loss_cls: 0.07709  loss_box_reg: 0.07169  loss_rpn_cls: 0.004302  loss_rpn_loc: 0.01943  time: 2.6161  data_time: 0.0308  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:29:16 d2.utils.events]: \u001b[0m eta: 2:22:42  iter: 7439  total_loss: 0.1102  loss_cls: 0.05327  loss_box_reg: 0.0414  loss_rpn_cls: 0.002984  loss_rpn_loc: 0.01472  time: 2.6160  data_time: 0.0258  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:30:08 d2.utils.events]: \u001b[0m eta: 2:21:50  iter: 7459  total_loss: 0.1539  loss_cls: 0.06903  loss_box_reg: 0.06434  loss_rpn_cls: 0.00258  loss_rpn_loc: 0.01206  time: 2.6160  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:31:03 d2.utils.events]: \u001b[0m eta: 2:21:01  iter: 7479  total_loss: 0.1386  loss_cls: 0.06798  loss_box_reg: 0.06131  loss_rpn_cls: 0.002678  loss_rpn_loc: 0.01709  time: 2.6163  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:31:58 d2.utils.events]: \u001b[0m eta: 2:20:09  iter: 7499  total_loss: 0.1314  loss_cls: 0.05199  loss_box_reg: 0.04645  loss_rpn_cls: 0.002439  loss_rpn_loc: 0.02848  time: 2.6166  data_time: 0.0280  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:32:52 d2.utils.events]: \u001b[0m eta: 2:19:18  iter: 7519  total_loss: 0.1733  loss_cls: 0.07413  loss_box_reg: 0.05913  loss_rpn_cls: 0.004666  loss_rpn_loc: 0.02294  time: 2.6169  data_time: 0.0299  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:33:43 d2.utils.events]: \u001b[0m eta: 2:18:21  iter: 7539  total_loss: 0.1392  loss_cls: 0.06251  loss_box_reg: 0.05937  loss_rpn_cls: 0.002791  loss_rpn_loc: 0.01133  time: 2.6167  data_time: 0.0326  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:34:36 d2.utils.events]: \u001b[0m eta: 2:17:26  iter: 7559  total_loss: 0.1387  loss_cls: 0.06966  loss_box_reg: 0.05627  loss_rpn_cls: 0.003516  loss_rpn_loc: 0.02127  time: 2.6167  data_time: 0.0240  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:35:29 d2.utils.events]: \u001b[0m eta: 2:16:40  iter: 7579  total_loss: 0.1693  loss_cls: 0.07524  loss_box_reg: 0.06134  loss_rpn_cls: 0.003251  loss_rpn_loc: 0.02355  time: 2.6169  data_time: 0.0329  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:36:19 d2.utils.events]: \u001b[0m eta: 2:15:48  iter: 7599  total_loss: 0.1595  loss_cls: 0.0746  loss_box_reg: 0.0657  loss_rpn_cls: 0.004395  loss_rpn_loc: 0.01434  time: 2.6165  data_time: 0.0337  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:37:11 d2.utils.events]: \u001b[0m eta: 2:15:01  iter: 7619  total_loss: 0.1242  loss_cls: 0.05481  loss_box_reg: 0.04417  loss_rpn_cls: 0.001489  loss_rpn_loc: 0.01423  time: 2.6166  data_time: 0.0321  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:38:02 d2.utils.events]: \u001b[0m eta: 2:14:11  iter: 7639  total_loss: 0.1629  loss_cls: 0.06873  loss_box_reg: 0.06342  loss_rpn_cls: 0.00416  loss_rpn_loc: 0.0221  time: 2.6164  data_time: 0.0241  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:38:54 d2.utils.events]: \u001b[0m eta: 2:13:16  iter: 7659  total_loss: 0.1209  loss_cls: 0.05228  loss_box_reg: 0.05051  loss_rpn_cls: 0.002964  loss_rpn_loc: 0.0127  time: 2.6163  data_time: 0.0292  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:39:45 d2.utils.events]: \u001b[0m eta: 2:12:22  iter: 7679  total_loss: 0.2165  loss_cls: 0.09214  loss_box_reg: 0.07641  loss_rpn_cls: 0.006359  loss_rpn_loc: 0.03193  time: 2.6161  data_time: 0.0238  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:40:36 d2.utils.events]: \u001b[0m eta: 2:11:31  iter: 7699  total_loss: 0.1497  loss_cls: 0.07128  loss_box_reg: 0.06508  loss_rpn_cls: 0.002733  loss_rpn_loc: 0.01352  time: 2.6159  data_time: 0.0293  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:41:31 d2.utils.events]: \u001b[0m eta: 2:10:44  iter: 7719  total_loss: 0.1048  loss_cls: 0.04813  loss_box_reg: 0.04521  loss_rpn_cls: 0.003086  loss_rpn_loc: 0.01202  time: 2.6163  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:42:21 d2.utils.events]: \u001b[0m eta: 2:09:44  iter: 7739  total_loss: 0.1158  loss_cls: 0.05871  loss_box_reg: 0.05188  loss_rpn_cls: 0.002634  loss_rpn_loc: 0.01213  time: 2.6161  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:43:14 d2.utils.events]: \u001b[0m eta: 2:08:59  iter: 7759  total_loss: 0.1526  loss_cls: 0.06475  loss_box_reg: 0.06224  loss_rpn_cls: 0.003453  loss_rpn_loc: 0.01529  time: 2.6161  data_time: 0.0297  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:44:06 d2.utils.events]: \u001b[0m eta: 2:08:10  iter: 7779  total_loss: 0.151  loss_cls: 0.05984  loss_box_reg: 0.05685  loss_rpn_cls: 0.002958  loss_rpn_loc: 0.01616  time: 2.6160  data_time: 0.0281  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:44:58 d2.utils.events]: \u001b[0m eta: 2:07:19  iter: 7799  total_loss: 0.1564  loss_cls: 0.05999  loss_box_reg: 0.06292  loss_rpn_cls: 0.003512  loss_rpn_loc: 0.01945  time: 2.6160  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:45:51 d2.utils.events]: \u001b[0m eta: 2:06:28  iter: 7819  total_loss: 0.127  loss_cls: 0.05607  loss_box_reg: 0.05207  loss_rpn_cls: 0.003659  loss_rpn_loc: 0.01739  time: 2.6161  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:46:43 d2.utils.events]: \u001b[0m eta: 2:05:39  iter: 7839  total_loss: 0.1458  loss_cls: 0.05648  loss_box_reg: 0.05502  loss_rpn_cls: 0.004112  loss_rpn_loc: 0.0168  time: 2.6160  data_time: 0.0326  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:47:35 d2.utils.events]: \u001b[0m eta: 2:04:53  iter: 7859  total_loss: 0.1524  loss_cls: 0.06696  loss_box_reg: 0.05733  loss_rpn_cls: 0.003592  loss_rpn_loc: 0.01594  time: 2.6160  data_time: 0.0258  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:48:28 d2.utils.events]: \u001b[0m eta: 2:04:01  iter: 7879  total_loss: 0.1434  loss_cls: 0.06774  loss_box_reg: 0.04746  loss_rpn_cls: 0.003944  loss_rpn_loc: 0.01114  time: 2.6161  data_time: 0.0272  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:49:22 d2.utils.events]: \u001b[0m eta: 2:03:16  iter: 7899  total_loss: 0.1344  loss_cls: 0.05609  loss_box_reg: 0.04846  loss_rpn_cls: 0.002306  loss_rpn_loc: 0.009639  time: 2.6162  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:50:19 d2.utils.events]: \u001b[0m eta: 2:02:19  iter: 7919  total_loss: 0.1782  loss_cls: 0.06124  loss_box_reg: 0.06265  loss_rpn_cls: 0.003548  loss_rpn_loc: 0.02208  time: 2.6169  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:51:09 d2.utils.events]: \u001b[0m eta: 2:01:24  iter: 7939  total_loss: 0.1533  loss_cls: 0.06813  loss_box_reg: 0.05406  loss_rpn_cls: 0.002169  loss_rpn_loc: 0.01609  time: 2.6166  data_time: 0.0267  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:52:01 d2.utils.events]: \u001b[0m eta: 2:00:31  iter: 7959  total_loss: 0.1241  loss_cls: 0.05067  loss_box_reg: 0.04846  loss_rpn_cls: 0.002472  loss_rpn_loc: 0.01045  time: 2.6165  data_time: 0.0302  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:52:52 d2.utils.events]: \u001b[0m eta: 1:59:36  iter: 7979  total_loss: 0.1778  loss_cls: 0.07178  loss_box_reg: 0.05413  loss_rpn_cls: 0.003898  loss_rpn_loc: 0.01705  time: 2.6164  data_time: 0.0263  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:53:46 d2.utils.events]: \u001b[0m eta: 1:58:46  iter: 7999  total_loss: 0.1924  loss_cls: 0.08713  loss_box_reg: 0.08055  loss_rpn_cls: 0.00365  loss_rpn_loc: 0.01817  time: 2.6166  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:54:40 d2.utils.events]: \u001b[0m eta: 1:57:46  iter: 8019  total_loss: 0.1861  loss_cls: 0.07055  loss_box_reg: 0.07089  loss_rpn_cls: 0.002974  loss_rpn_loc: 0.01881  time: 2.6167  data_time: 0.0273  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:55:33 d2.utils.events]: \u001b[0m eta: 1:56:56  iter: 8039  total_loss: 0.1387  loss_cls: 0.06739  loss_box_reg: 0.05449  loss_rpn_cls: 0.002302  loss_rpn_loc: 0.0183  time: 2.6168  data_time: 0.0300  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:56:25 d2.utils.events]: \u001b[0m eta: 1:56:02  iter: 8059  total_loss: 0.1256  loss_cls: 0.06095  loss_box_reg: 0.05723  loss_rpn_cls: 0.001723  loss_rpn_loc: 0.01163  time: 2.6168  data_time: 0.0304  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:57:22 d2.utils.events]: \u001b[0m eta: 1:55:19  iter: 8079  total_loss: 0.1721  loss_cls: 0.06704  loss_box_reg: 0.06237  loss_rpn_cls: 0.003523  loss_rpn_loc: 0.0298  time: 2.6174  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:58:12 d2.utils.events]: \u001b[0m eta: 1:54:19  iter: 8099  total_loss: 0.1722  loss_cls: 0.07241  loss_box_reg: 0.0568  loss_rpn_cls: 0.005127  loss_rpn_loc: 0.01978  time: 2.6171  data_time: 0.0292  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:59:04 d2.utils.events]: \u001b[0m eta: 1:53:28  iter: 8119  total_loss: 0.1362  loss_cls: 0.0658  loss_box_reg: 0.05993  loss_rpn_cls: 0.003332  loss_rpn_loc: 0.01329  time: 2.6170  data_time: 0.0272  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 06:59:56 d2.utils.events]: \u001b[0m eta: 1:52:38  iter: 8139  total_loss: 0.1282  loss_cls: 0.05813  loss_box_reg: 0.04877  loss_rpn_cls: 0.002856  loss_rpn_loc: 0.01579  time: 2.6170  data_time: 0.0270  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:00:49 d2.utils.events]: \u001b[0m eta: 1:51:46  iter: 8159  total_loss: 0.09333  loss_cls: 0.04485  loss_box_reg: 0.03652  loss_rpn_cls: 0.001244  loss_rpn_loc: 0.007811  time: 2.6170  data_time: 0.0268  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:01:39 d2.utils.events]: \u001b[0m eta: 1:50:53  iter: 8179  total_loss: 0.1617  loss_cls: 0.07094  loss_box_reg: 0.06734  loss_rpn_cls: 0.001848  loss_rpn_loc: 0.02363  time: 2.6168  data_time: 0.0289  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:02:31 d2.utils.events]: \u001b[0m eta: 1:50:00  iter: 8199  total_loss: 0.1417  loss_cls: 0.06012  loss_box_reg: 0.04826  loss_rpn_cls: 0.002401  loss_rpn_loc: 0.01578  time: 2.6167  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:03:23 d2.utils.events]: \u001b[0m eta: 1:49:15  iter: 8219  total_loss: 0.1549  loss_cls: 0.06875  loss_box_reg: 0.05184  loss_rpn_cls: 0.003126  loss_rpn_loc: 0.01378  time: 2.6167  data_time: 0.0303  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:04:14 d2.utils.events]: \u001b[0m eta: 1:48:22  iter: 8239  total_loss: 0.1377  loss_cls: 0.06238  loss_box_reg: 0.05661  loss_rpn_cls: 0.00364  loss_rpn_loc: 0.0134  time: 2.6166  data_time: 0.0261  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:05:04 d2.utils.events]: \u001b[0m eta: 1:47:24  iter: 8259  total_loss: 0.1571  loss_cls: 0.07671  loss_box_reg: 0.067  loss_rpn_cls: 0.003458  loss_rpn_loc: 0.01247  time: 2.6162  data_time: 0.0311  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:05:58 d2.utils.events]: \u001b[0m eta: 1:46:35  iter: 8279  total_loss: 0.1382  loss_cls: 0.06822  loss_box_reg: 0.055  loss_rpn_cls: 0.002592  loss_rpn_loc: 0.01781  time: 2.6165  data_time: 0.0318  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:06:50 d2.utils.events]: \u001b[0m eta: 1:45:44  iter: 8299  total_loss: 0.1342  loss_cls: 0.06448  loss_box_reg: 0.05871  loss_rpn_cls: 0.002406  loss_rpn_loc: 0.01404  time: 2.6164  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:07:45 d2.utils.events]: \u001b[0m eta: 1:44:56  iter: 8319  total_loss: 0.1754  loss_cls: 0.08661  loss_box_reg: 0.06643  loss_rpn_cls: 0.005625  loss_rpn_loc: 0.01762  time: 2.6168  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:08:37 d2.utils.events]: \u001b[0m eta: 1:44:07  iter: 8339  total_loss: 0.125  loss_cls: 0.05101  loss_box_reg: 0.05089  loss_rpn_cls: 0.00257  loss_rpn_loc: 0.01506  time: 2.6167  data_time: 0.0265  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:09:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 07:09:26 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 07:09:26 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 07:09:26 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 07:09:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 07:09:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 07:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1741 s / img. ETA=0:00:54\n",
      "\u001b[32m[04/30 07:09:35 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2239 s / img. ETA=0:01:04\n",
      "\u001b[32m[04/30 07:09:40 d2.evaluation.evaluator]: \u001b[0mInference done 48/310. 0.2252 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 07:09:45 d2.evaluation.evaluator]: \u001b[0mInference done 65/310. 0.2150 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/30 07:09:50 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2133 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 07:09:55 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2066 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/30 07:10:01 d2.evaluation.evaluator]: \u001b[0mInference done 115/310. 0.2022 s / img. ETA=0:00:57\n",
      "\u001b[32m[04/30 07:10:06 d2.evaluation.evaluator]: \u001b[0mInference done 136/310. 0.1978 s / img. ETA=0:00:49\n",
      "\u001b[32m[04/30 07:10:11 d2.evaluation.evaluator]: \u001b[0mInference done 161/310. 0.1954 s / img. ETA=0:00:40\n",
      "\u001b[32m[04/30 07:10:16 d2.evaluation.evaluator]: \u001b[0mInference done 186/310. 0.1934 s / img. ETA=0:00:32\n",
      "\u001b[32m[04/30 07:10:21 d2.evaluation.evaluator]: \u001b[0mInference done 207/310. 0.1932 s / img. ETA=0:00:26\n",
      "\u001b[32m[04/30 07:10:26 d2.evaluation.evaluator]: \u001b[0mInference done 233/310. 0.1917 s / img. ETA=0:00:19\n",
      "\u001b[32m[04/30 07:10:31 d2.evaluation.evaluator]: \u001b[0mInference done 254/310. 0.1910 s / img. ETA=0:00:14\n",
      "\u001b[32m[04/30 07:10:36 d2.evaluation.evaluator]: \u001b[0mInference done 276/310. 0.1901 s / img. ETA=0:00:08\n",
      "\u001b[32m[04/30 07:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 302/310. 0.1897 s / img. ETA=0:00:01\n",
      "\u001b[32m[04/30 07:10:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.867330 (0.245467 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 07:10:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.191043 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 07:10:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 07:10:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 07:10:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 07:10:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[04/30 07:10:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 07:10:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
      "\u001b[32m[04/30 07:10:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.581 | 27.257 | 22.522 | 3.032 | 15.358 | 22.742 |\n",
      "\u001b[32m[04/30 07:10:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.569 | Carton          | 36.673 | Bottle cap     | 33.254 |\n",
      "| Can                   | 37.835 | Pop tab         | 12.350 | Cup            | 33.914 |\n",
      "| Plastic bag & wrapper | 30.129 | Styrofoam piece | 16.801 | Other plastic  | 6.030  |\n",
      "| Plastic container     | 27.756 | Paper           | 12.039 | Lid            | 15.031 |\n",
      "| Straw                 | 21.291 | Paper bag       | 19.188 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 56.642 | Glass jar       | 35.347 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 11.782 | Aluminium foil | 23.267 |\n",
      "| Unlabeled litter      | 1.993  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 7.855  | Cigarette       | 17.179 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 23.333 |                 |        |                |        |\n",
      "\u001b[32m[04/30 07:10:44 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 07:10:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 07:10:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 07:10:44 d2.evaluation.testing]: \u001b[0mcopypaste: 18.5806,27.2574,22.5225,3.0317,15.3580,22.7418\n",
      "\u001b[32m[04/30 07:10:50 d2.utils.events]: \u001b[0m eta: 1:43:25  iter: 8359  total_loss: 0.1551  loss_cls: 0.05685  loss_box_reg: 0.05995  loss_rpn_cls: 0.003601  loss_rpn_loc: 0.01742  time: 2.6169  data_time: 0.0244  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:11:44 d2.utils.events]: \u001b[0m eta: 1:42:36  iter: 8379  total_loss: 0.1496  loss_cls: 0.06749  loss_box_reg: 0.06235  loss_rpn_cls: 0.00196  loss_rpn_loc: 0.01653  time: 2.6171  data_time: 0.0272  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:12:35 d2.utils.events]: \u001b[0m eta: 1:41:46  iter: 8399  total_loss: 0.1171  loss_cls: 0.05148  loss_box_reg: 0.05565  loss_rpn_cls: 0.002391  loss_rpn_loc: 0.01047  time: 2.6169  data_time: 0.0315  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:13:25 d2.utils.events]: \u001b[0m eta: 1:40:54  iter: 8419  total_loss: 0.1494  loss_cls: 0.05859  loss_box_reg: 0.05481  loss_rpn_cls: 0.002842  loss_rpn_loc: 0.02362  time: 2.6166  data_time: 0.0474  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:14:17 d2.utils.events]: \u001b[0m eta: 1:40:04  iter: 8439  total_loss: 0.1417  loss_cls: 0.06846  loss_box_reg: 0.05448  loss_rpn_cls: 0.003345  loss_rpn_loc: 0.01891  time: 2.6166  data_time: 0.0261  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:15:08 d2.utils.events]: \u001b[0m eta: 1:39:12  iter: 8459  total_loss: 0.1589  loss_cls: 0.07295  loss_box_reg: 0.05955  loss_rpn_cls: 0.003444  loss_rpn_loc: 0.01196  time: 2.6165  data_time: 0.0263  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:15:59 d2.utils.events]: \u001b[0m eta: 1:38:22  iter: 8479  total_loss: 0.1238  loss_cls: 0.05274  loss_box_reg: 0.04777  loss_rpn_cls: 0.003283  loss_rpn_loc: 0.01129  time: 2.6164  data_time: 0.0288  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:16:54 d2.utils.events]: \u001b[0m eta: 1:37:30  iter: 8499  total_loss: 0.1707  loss_cls: 0.07432  loss_box_reg: 0.07361  loss_rpn_cls: 0.002922  loss_rpn_loc: 0.02117  time: 2.6167  data_time: 0.0231  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:17:48 d2.utils.events]: \u001b[0m eta: 1:36:37  iter: 8519  total_loss: 0.1339  loss_cls: 0.05787  loss_box_reg: 0.0575  loss_rpn_cls: 0.003366  loss_rpn_loc: 0.01116  time: 2.6168  data_time: 0.0274  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:18:39 d2.utils.events]: \u001b[0m eta: 1:35:41  iter: 8539  total_loss: 0.1636  loss_cls: 0.06861  loss_box_reg: 0.06016  loss_rpn_cls: 0.003686  loss_rpn_loc: 0.0289  time: 2.6167  data_time: 0.0276  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:19:32 d2.utils.events]: \u001b[0m eta: 1:34:52  iter: 8559  total_loss: 0.1616  loss_cls: 0.07998  loss_box_reg: 0.06864  loss_rpn_cls: 0.003908  loss_rpn_loc: 0.01846  time: 2.6168  data_time: 0.0293  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:20:23 d2.utils.events]: \u001b[0m eta: 1:33:57  iter: 8579  total_loss: 0.1742  loss_cls: 0.07283  loss_box_reg: 0.06487  loss_rpn_cls: 0.002973  loss_rpn_loc: 0.02042  time: 2.6166  data_time: 0.0272  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:21:15 d2.utils.events]: \u001b[0m eta: 1:33:06  iter: 8599  total_loss: 0.1642  loss_cls: 0.07062  loss_box_reg: 0.05308  loss_rpn_cls: 0.003672  loss_rpn_loc: 0.02358  time: 2.6165  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:22:10 d2.utils.events]: \u001b[0m eta: 1:32:16  iter: 8619  total_loss: 0.1169  loss_cls: 0.04875  loss_box_reg: 0.05007  loss_rpn_cls: 0.002028  loss_rpn_loc: 0.01298  time: 2.6168  data_time: 0.0287  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:23:04 d2.utils.events]: \u001b[0m eta: 1:31:24  iter: 8639  total_loss: 0.1463  loss_cls: 0.07193  loss_box_reg: 0.05777  loss_rpn_cls: 0.001483  loss_rpn_loc: 0.01062  time: 2.6170  data_time: 0.0286  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:23:57 d2.utils.events]: \u001b[0m eta: 1:30:32  iter: 8659  total_loss: 0.138  loss_cls: 0.06234  loss_box_reg: 0.05351  loss_rpn_cls: 0.00174  loss_rpn_loc: 0.01112  time: 2.6170  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:24:48 d2.utils.events]: \u001b[0m eta: 1:29:41  iter: 8679  total_loss: 0.182  loss_cls: 0.07721  loss_box_reg: 0.07036  loss_rpn_cls: 0.005726  loss_rpn_loc: 0.02265  time: 2.6170  data_time: 0.0257  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:25:41 d2.utils.events]: \u001b[0m eta: 1:28:49  iter: 8699  total_loss: 0.1391  loss_cls: 0.05021  loss_box_reg: 0.05253  loss_rpn_cls: 0.003772  loss_rpn_loc: 0.01709  time: 2.6170  data_time: 0.0398  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:26:33 d2.utils.events]: \u001b[0m eta: 1:27:55  iter: 8719  total_loss: 0.125  loss_cls: 0.05833  loss_box_reg: 0.04844  loss_rpn_cls: 0.002233  loss_rpn_loc: 0.01277  time: 2.6169  data_time: 0.0289  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:27:25 d2.utils.events]: \u001b[0m eta: 1:27:05  iter: 8739  total_loss: 0.1441  loss_cls: 0.0595  loss_box_reg: 0.05716  loss_rpn_cls: 0.003222  loss_rpn_loc: 0.01488  time: 2.6169  data_time: 0.0307  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:28:17 d2.utils.events]: \u001b[0m eta: 1:26:11  iter: 8759  total_loss: 0.1443  loss_cls: 0.06003  loss_box_reg: 0.05395  loss_rpn_cls: 0.00169  loss_rpn_loc: 0.01274  time: 2.6169  data_time: 0.0323  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:29:10 d2.utils.events]: \u001b[0m eta: 1:25:17  iter: 8779  total_loss: 0.1346  loss_cls: 0.06175  loss_box_reg: 0.04707  loss_rpn_cls: 0.003729  loss_rpn_loc: 0.01488  time: 2.6169  data_time: 0.0252  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:30:03 d2.utils.events]: \u001b[0m eta: 1:24:19  iter: 8799  total_loss: 0.2126  loss_cls: 0.08206  loss_box_reg: 0.07014  loss_rpn_cls: 0.003539  loss_rpn_loc: 0.02005  time: 2.6170  data_time: 0.0288  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:30:55 d2.utils.events]: \u001b[0m eta: 1:23:30  iter: 8819  total_loss: 0.1554  loss_cls: 0.06157  loss_box_reg: 0.05638  loss_rpn_cls: 0.001211  loss_rpn_loc: 0.01274  time: 2.6170  data_time: 0.0317  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:31:49 d2.utils.events]: \u001b[0m eta: 1:22:41  iter: 8839  total_loss: 0.2022  loss_cls: 0.09867  loss_box_reg: 0.07991  loss_rpn_cls: 0.00388  loss_rpn_loc: 0.0191  time: 2.6172  data_time: 0.0329  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:32:39 d2.utils.events]: \u001b[0m eta: 1:21:39  iter: 8859  total_loss: 0.1226  loss_cls: 0.05893  loss_box_reg: 0.05313  loss_rpn_cls: 0.002568  loss_rpn_loc: 0.009231  time: 2.6169  data_time: 0.0332  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:33:30 d2.utils.events]: \u001b[0m eta: 1:20:46  iter: 8879  total_loss: 0.1438  loss_cls: 0.06047  loss_box_reg: 0.05709  loss_rpn_cls: 0.001698  loss_rpn_loc: 0.01058  time: 2.6167  data_time: 0.0274  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:34:23 d2.utils.events]: \u001b[0m eta: 1:19:53  iter: 8899  total_loss: 0.1897  loss_cls: 0.08577  loss_box_reg: 0.07229  loss_rpn_cls: 0.00262  loss_rpn_loc: 0.0201  time: 2.6168  data_time: 0.0315  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:35:13 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 8919  total_loss: 0.1596  loss_cls: 0.06635  loss_box_reg: 0.06631  loss_rpn_cls: 0.003071  loss_rpn_loc: 0.01599  time: 2.6165  data_time: 0.0296  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:36:06 d2.utils.events]: \u001b[0m eta: 1:18:09  iter: 8939  total_loss: 0.1544  loss_cls: 0.07644  loss_box_reg: 0.0607  loss_rpn_cls: 0.002649  loss_rpn_loc: 0.01513  time: 2.6166  data_time: 0.0305  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:37:00 d2.utils.events]: \u001b[0m eta: 1:17:19  iter: 8959  total_loss: 0.1595  loss_cls: 0.06817  loss_box_reg: 0.06435  loss_rpn_cls: 0.004205  loss_rpn_loc: 0.01384  time: 2.6168  data_time: 0.0315  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:37:51 d2.utils.events]: \u001b[0m eta: 1:16:29  iter: 8979  total_loss: 0.1407  loss_cls: 0.06063  loss_box_reg: 0.05267  loss_rpn_cls: 0.003117  loss_rpn_loc: 0.02121  time: 2.6166  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:38:44 d2.utils.events]: \u001b[0m eta: 1:15:34  iter: 8999  total_loss: 0.1564  loss_cls: 0.05975  loss_box_reg: 0.06488  loss_rpn_cls: 0.003269  loss_rpn_loc: 0.01387  time: 2.6167  data_time: 0.0256  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:39:37 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 9019  total_loss: 0.1763  loss_cls: 0.07766  loss_box_reg: 0.06207  loss_rpn_cls: 0.003443  loss_rpn_loc: 0.02646  time: 2.6169  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:40:30 d2.utils.events]: \u001b[0m eta: 1:13:48  iter: 9039  total_loss: 0.1308  loss_cls: 0.06351  loss_box_reg: 0.05121  loss_rpn_cls: 0.002654  loss_rpn_loc: 0.01349  time: 2.6169  data_time: 0.0301  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:41:25 d2.utils.events]: \u001b[0m eta: 1:12:56  iter: 9059  total_loss: 0.1554  loss_cls: 0.06847  loss_box_reg: 0.05929  loss_rpn_cls: 0.001918  loss_rpn_loc: 0.02037  time: 2.6171  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:42:18 d2.utils.events]: \u001b[0m eta: 1:12:02  iter: 9079  total_loss: 0.1432  loss_cls: 0.06004  loss_box_reg: 0.04852  loss_rpn_cls: 0.003529  loss_rpn_loc: 0.01464  time: 2.6172  data_time: 0.0243  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:43:12 d2.utils.events]: \u001b[0m eta: 1:11:13  iter: 9099  total_loss: 0.138  loss_cls: 0.0645  loss_box_reg: 0.06362  loss_rpn_cls: 0.001956  loss_rpn_loc: 0.01318  time: 2.6175  data_time: 0.0255  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:44:03 d2.utils.events]: \u001b[0m eta: 1:10:22  iter: 9119  total_loss: 0.226  loss_cls: 0.08844  loss_box_reg: 0.08057  loss_rpn_cls: 0.004036  loss_rpn_loc: 0.02991  time: 2.6173  data_time: 0.0324  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:44:54 d2.utils.events]: \u001b[0m eta: 1:09:28  iter: 9139  total_loss: 0.1829  loss_cls: 0.08657  loss_box_reg: 0.06354  loss_rpn_cls: 0.002752  loss_rpn_loc: 0.01834  time: 2.6172  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:45:45 d2.utils.events]: \u001b[0m eta: 1:08:36  iter: 9159  total_loss: 0.1773  loss_cls: 0.07557  loss_box_reg: 0.06674  loss_rpn_cls: 0.003167  loss_rpn_loc: 0.01477  time: 2.6170  data_time: 0.0286  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:46:40 d2.utils.events]: \u001b[0m eta: 1:07:50  iter: 9179  total_loss: 0.1101  loss_cls: 0.05078  loss_box_reg: 0.04036  loss_rpn_cls: 0.001325  loss_rpn_loc: 0.01237  time: 2.6173  data_time: 0.0262  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:47:33 d2.utils.events]: \u001b[0m eta: 1:06:58  iter: 9199  total_loss: 0.1561  loss_cls: 0.0666  loss_box_reg: 0.05797  loss_rpn_cls: 0.002848  loss_rpn_loc: 0.01556  time: 2.6174  data_time: 0.0326  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:48:24 d2.utils.events]: \u001b[0m eta: 1:06:02  iter: 9219  total_loss: 0.1444  loss_cls: 0.0591  loss_box_reg: 0.05436  loss_rpn_cls: 0.0009061  loss_rpn_loc: 0.01147  time: 2.6172  data_time: 0.0309  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:49:16 d2.utils.events]: \u001b[0m eta: 1:05:12  iter: 9239  total_loss: 0.135  loss_cls: 0.05965  loss_box_reg: 0.04832  loss_rpn_cls: 0.002301  loss_rpn_loc: 0.02057  time: 2.6172  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:50:08 d2.utils.events]: \u001b[0m eta: 1:04:20  iter: 9259  total_loss: 0.1546  loss_cls: 0.06053  loss_box_reg: 0.05617  loss_rpn_cls: 0.001955  loss_rpn_loc: 0.01492  time: 2.6171  data_time: 0.0250  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:51:00 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 9279  total_loss: 0.1394  loss_cls: 0.06627  loss_box_reg: 0.05214  loss_rpn_cls: 0.003071  loss_rpn_loc: 0.01628  time: 2.6170  data_time: 0.0304  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:51:54 d2.utils.events]: \u001b[0m eta: 1:02:36  iter: 9299  total_loss: 0.1372  loss_cls: 0.04652  loss_box_reg: 0.04809  loss_rpn_cls: 0.003115  loss_rpn_loc: 0.01486  time: 2.6172  data_time: 0.0286  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:52:46 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 9319  total_loss: 0.158  loss_cls: 0.06848  loss_box_reg: 0.06121  loss_rpn_cls: 0.003732  loss_rpn_loc: 0.01251  time: 2.6172  data_time: 0.0337  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:53:38 d2.utils.events]: \u001b[0m eta: 1:00:51  iter: 9339  total_loss: 0.1599  loss_cls: 0.07648  loss_box_reg: 0.05608  loss_rpn_cls: 0.002762  loss_rpn_loc: 0.0219  time: 2.6172  data_time: 0.0290  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:54:33 d2.utils.events]: \u001b[0m eta: 0:59:59  iter: 9359  total_loss: 0.1591  loss_cls: 0.0626  loss_box_reg: 0.06415  loss_rpn_cls: 0.002001  loss_rpn_loc: 0.01116  time: 2.6174  data_time: 0.0313  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:55:25 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 9379  total_loss: 0.1589  loss_cls: 0.06449  loss_box_reg: 0.06875  loss_rpn_cls: 0.002389  loss_rpn_loc: 0.01803  time: 2.6174  data_time: 0.0293  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:56:24 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 9399  total_loss: 0.1247  loss_cls: 0.05608  loss_box_reg: 0.05223  loss_rpn_cls: 0.001693  loss_rpn_loc: 0.01309  time: 2.6181  data_time: 0.0301  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:57:18 d2.utils.events]: \u001b[0m eta: 0:57:28  iter: 9419  total_loss: 0.1784  loss_cls: 0.07606  loss_box_reg: 0.07401  loss_rpn_cls: 0.003267  loss_rpn_loc: 0.01914  time: 2.6182  data_time: 0.0285  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:58:12 d2.utils.events]: \u001b[0m eta: 0:56:36  iter: 9439  total_loss: 0.149  loss_cls: 0.06266  loss_box_reg: 0.062  loss_rpn_cls: 0.0021  loss_rpn_loc: 0.01679  time: 2.6184  data_time: 0.0283  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:59:05 d2.utils.events]: \u001b[0m eta: 0:55:45  iter: 9459  total_loss: 0.1682  loss_cls: 0.0729  loss_box_reg: 0.06971  loss_rpn_cls: 0.003091  loss_rpn_loc: 0.01838  time: 2.6185  data_time: 0.0291  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 07:59:57 d2.utils.events]: \u001b[0m eta: 0:54:51  iter: 9479  total_loss: 0.1734  loss_cls: 0.06979  loss_box_reg: 0.0592  loss_rpn_cls: 0.002907  loss_rpn_loc: 0.02083  time: 2.6184  data_time: 0.0253  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:00:51 d2.utils.events]: \u001b[0m eta: 0:53:59  iter: 9499  total_loss: 0.1634  loss_cls: 0.06908  loss_box_reg: 0.06176  loss_rpn_cls: 0.004726  loss_rpn_loc: 0.02061  time: 2.6187  data_time: 0.0330  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:01:43 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 9519  total_loss: 0.1402  loss_cls: 0.05956  loss_box_reg: 0.04541  loss_rpn_cls: 0.003143  loss_rpn_loc: 0.02053  time: 2.6186  data_time: 0.0295  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:02:37 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 9539  total_loss: 0.124  loss_cls: 0.04748  loss_box_reg: 0.04532  loss_rpn_cls: 0.001381  loss_rpn_loc: 0.01911  time: 2.6187  data_time: 0.0261  lr: 0.0004  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:03:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 08:03:08 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 08:03:08 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 08:03:08 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 08:03:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 08:03:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 08:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1680 s / img. ETA=0:00:52\n",
      "\u001b[32m[04/30 08:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 31/310. 0.2232 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/30 08:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 48/310. 0.2260 s / img. ETA=0:01:10\n",
      "\u001b[32m[04/30 08:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 66/310. 0.2151 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 08:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 81/310. 0.2094 s / img. ETA=0:01:07\n",
      "\u001b[32m[04/30 08:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 99/310. 0.2028 s / img. ETA=0:01:01\n",
      "\u001b[32m[04/30 08:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 118/310. 0.1994 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 08:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 141/310. 0.1957 s / img. ETA=0:00:47\n",
      "\u001b[32m[04/30 08:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 166/310. 0.1935 s / img. ETA=0:00:38\n",
      "\u001b[32m[04/30 08:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 193/310. 0.1915 s / img. ETA=0:00:30\n",
      "\u001b[32m[04/30 08:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 216/310. 0.1913 s / img. ETA=0:00:23\n",
      "\u001b[32m[04/30 08:04:10 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1896 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/30 08:04:15 d2.evaluation.evaluator]: \u001b[0mInference done 265/310. 0.1887 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/30 08:04:20 d2.evaluation.evaluator]: \u001b[0mInference done 287/310. 0.1882 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.384396 (0.243883 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.188659 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.485 | 26.079 | 19.783 | 2.586 | 16.655 | 18.957 |\n",
      "\u001b[32m[04/30 08:04:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 37.682 | Carton          | 30.511 | Bottle cap     | 30.403 |\n",
      "| Can                   | 29.134 | Pop tab         | 7.624  | Cup            | 27.661 |\n",
      "| Plastic bag & wrapper | 29.054 | Styrofoam piece | 15.750 | Other plastic  | 5.473  |\n",
      "| Plastic container     | 24.345 | Paper           | 9.289  | Lid            | 17.060 |\n",
      "| Straw                 | 23.758 | Paper bag       | 21.881 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 52.952 | Glass jar       | 30.297 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 0.000  | Aluminium foil | 21.584 |\n",
      "| Unlabeled litter      | 1.522  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 7.534  | Cigarette       | 14.724 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 23.333 |                 |        |                |        |\n",
      "\u001b[32m[04/30 08:04:26 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 08:04:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 08:04:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 08:04:26 d2.evaluation.testing]: \u001b[0mcopypaste: 16.4847,26.0787,19.7830,2.5861,16.6551,18.9568\n",
      "\u001b[32m[04/30 08:04:45 d2.utils.events]: \u001b[0m eta: 0:51:24  iter: 9559  total_loss: 0.1357  loss_cls: 0.05473  loss_box_reg: 0.05163  loss_rpn_cls: 0.003276  loss_rpn_loc: 0.01649  time: 2.6186  data_time: 0.0293  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:05:36 d2.utils.events]: \u001b[0m eta: 0:50:33  iter: 9579  total_loss: 0.1424  loss_cls: 0.05392  loss_box_reg: 0.04492  loss_rpn_cls: 0.001878  loss_rpn_loc: 0.02024  time: 2.6184  data_time: 0.0268  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:06:30 d2.utils.events]: \u001b[0m eta: 0:49:43  iter: 9599  total_loss: 0.1899  loss_cls: 0.08451  loss_box_reg: 0.08146  loss_rpn_cls: 0.00265  loss_rpn_loc: 0.01512  time: 2.6185  data_time: 0.0313  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:07:23 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 9619  total_loss: 0.1999  loss_cls: 0.09388  loss_box_reg: 0.07577  loss_rpn_cls: 0.003724  loss_rpn_loc: 0.01907  time: 2.6186  data_time: 0.0325  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:08:15 d2.utils.events]: \u001b[0m eta: 0:47:57  iter: 9639  total_loss: 0.1303  loss_cls: 0.06587  loss_box_reg: 0.0481  loss_rpn_cls: 0.002997  loss_rpn_loc: 0.01399  time: 2.6186  data_time: 0.0315  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:09:06 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 9659  total_loss: 0.1323  loss_cls: 0.06361  loss_box_reg: 0.05637  loss_rpn_cls: 0.005066  loss_rpn_loc: 0.01402  time: 2.6184  data_time: 0.0321  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:09:58 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 9679  total_loss: 0.1554  loss_cls: 0.06868  loss_box_reg: 0.06369  loss_rpn_cls: 0.002397  loss_rpn_loc: 0.01474  time: 2.6184  data_time: 0.0276  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:10:50 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 9699  total_loss: 0.1377  loss_cls: 0.05984  loss_box_reg: 0.05535  loss_rpn_cls: 0.002841  loss_rpn_loc: 0.01126  time: 2.6184  data_time: 0.0320  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:11:43 d2.utils.events]: \u001b[0m eta: 0:44:30  iter: 9719  total_loss: 0.1477  loss_cls: 0.06376  loss_box_reg: 0.05864  loss_rpn_cls: 0.001433  loss_rpn_loc: 0.01782  time: 2.6184  data_time: 0.0333  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:12:36 d2.utils.events]: \u001b[0m eta: 0:43:39  iter: 9739  total_loss: 0.1311  loss_cls: 0.05705  loss_box_reg: 0.05233  loss_rpn_cls: 0.003741  loss_rpn_loc: 0.0164  time: 2.6185  data_time: 0.0310  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:13:28 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 9759  total_loss: 0.1537  loss_cls: 0.05686  loss_box_reg: 0.05146  loss_rpn_cls: 0.003034  loss_rpn_loc: 0.03618  time: 2.6185  data_time: 0.0281  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:14:22 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 9779  total_loss: 0.1251  loss_cls: 0.06018  loss_box_reg: 0.05035  loss_rpn_cls: 0.002547  loss_rpn_loc: 0.01214  time: 2.6186  data_time: 0.0279  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:15:17 d2.utils.events]: \u001b[0m eta: 0:41:03  iter: 9799  total_loss: 0.2159  loss_cls: 0.1003  loss_box_reg: 0.08379  loss_rpn_cls: 0.00501  loss_rpn_loc: 0.0262  time: 2.6188  data_time: 0.0294  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:16:08 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 9819  total_loss: 0.1608  loss_cls: 0.07485  loss_box_reg: 0.06629  loss_rpn_cls: 0.005803  loss_rpn_loc: 0.01323  time: 2.6187  data_time: 0.0306  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:17:02 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 9839  total_loss: 0.2165  loss_cls: 0.1041  loss_box_reg: 0.09277  loss_rpn_cls: 0.004264  loss_rpn_loc: 0.02074  time: 2.6189  data_time: 0.0329  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:17:55 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 9859  total_loss: 0.1427  loss_cls: 0.06478  loss_box_reg: 0.04942  loss_rpn_cls: 0.003825  loss_rpn_loc: 0.01085  time: 2.6189  data_time: 0.0254  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:18:47 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 9879  total_loss: 0.1285  loss_cls: 0.05494  loss_box_reg: 0.04751  loss_rpn_cls: 0.002789  loss_rpn_loc: 0.01688  time: 2.6190  data_time: 0.0272  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:19:41 d2.utils.events]: \u001b[0m eta: 0:36:43  iter: 9899  total_loss: 0.1913  loss_cls: 0.07455  loss_box_reg: 0.06798  loss_rpn_cls: 0.004831  loss_rpn_loc: 0.02827  time: 2.6191  data_time: 0.0308  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:20:34 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 9919  total_loss: 0.1961  loss_cls: 0.1024  loss_box_reg: 0.07152  loss_rpn_cls: 0.002611  loss_rpn_loc: 0.01677  time: 2.6191  data_time: 0.0272  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:21:27 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 9939  total_loss: 0.1393  loss_cls: 0.05742  loss_box_reg: 0.05248  loss_rpn_cls: 0.002952  loss_rpn_loc: 0.01188  time: 2.6192  data_time: 0.0320  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:22:23 d2.utils.events]: \u001b[0m eta: 0:34:07  iter: 9959  total_loss: 0.1935  loss_cls: 0.07231  loss_box_reg: 0.06858  loss_rpn_cls: 0.004652  loss_rpn_loc: 0.0216  time: 2.6196  data_time: 0.0325  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:23:15 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 9979  total_loss: 0.1188  loss_cls: 0.05859  loss_box_reg: 0.04561  loss_rpn_cls: 0.004584  loss_rpn_loc: 0.0123  time: 2.6195  data_time: 0.0326  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:24:07 d2.utils.events]: \u001b[0m eta: 0:32:22  iter: 9999  total_loss: 0.146  loss_cls: 0.07  loss_box_reg: 0.05082  loss_rpn_cls: 0.00278  loss_rpn_loc: 0.02213  time: 2.6194  data_time: 0.0278  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:24:59 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 10019  total_loss: 0.1239  loss_cls: 0.0552  loss_box_reg: 0.05034  loss_rpn_cls: 0.002949  loss_rpn_loc: 0.01095  time: 2.6194  data_time: 0.0293  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:25:52 d2.utils.events]: \u001b[0m eta: 0:30:39  iter: 10039  total_loss: 0.1855  loss_cls: 0.07978  loss_box_reg: 0.07207  loss_rpn_cls: 0.005091  loss_rpn_loc: 0.02299  time: 2.6194  data_time: 0.0455  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:26:44 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 10059  total_loss: 0.1242  loss_cls: 0.05723  loss_box_reg: 0.05005  loss_rpn_cls: 0.002838  loss_rpn_loc: 0.01258  time: 2.6194  data_time: 0.0272  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:27:34 d2.utils.events]: \u001b[0m eta: 0:28:54  iter: 10079  total_loss: 0.1836  loss_cls: 0.07416  loss_box_reg: 0.0691  loss_rpn_cls: 0.006092  loss_rpn_loc: 0.0226  time: 2.6191  data_time: 0.0244  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:28:29 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 10099  total_loss: 0.1297  loss_cls: 0.0579  loss_box_reg: 0.05001  loss_rpn_cls: 0.003318  loss_rpn_loc: 0.0113  time: 2.6194  data_time: 0.0309  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:29:20 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 10119  total_loss: 0.1389  loss_cls: 0.07006  loss_box_reg: 0.05708  loss_rpn_cls: 0.003443  loss_rpn_loc: 0.01804  time: 2.6193  data_time: 0.0278  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:30:11 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 10139  total_loss: 0.1409  loss_cls: 0.05485  loss_box_reg: 0.04762  loss_rpn_cls: 0.003827  loss_rpn_loc: 0.01724  time: 2.6191  data_time: 0.0239  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:31:02 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 10159  total_loss: 0.1161  loss_cls: 0.04231  loss_box_reg: 0.05326  loss_rpn_cls: 0.003331  loss_rpn_loc: 0.01241  time: 2.6189  data_time: 0.0344  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:31:52 d2.utils.events]: \u001b[0m eta: 0:24:33  iter: 10179  total_loss: 0.1866  loss_cls: 0.07797  loss_box_reg: 0.06563  loss_rpn_cls: 0.004606  loss_rpn_loc: 0.02036  time: 2.6187  data_time: 0.0313  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:32:43 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 10199  total_loss: 0.1194  loss_cls: 0.04728  loss_box_reg: 0.04129  loss_rpn_cls: 0.002783  loss_rpn_loc: 0.01207  time: 2.6186  data_time: 0.0303  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:33:36 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 10219  total_loss: 0.1853  loss_cls: 0.07658  loss_box_reg: 0.07672  loss_rpn_cls: 0.003532  loss_rpn_loc: 0.04493  time: 2.6186  data_time: 0.0247  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:34:26 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 10239  total_loss: 0.1405  loss_cls: 0.06052  loss_box_reg: 0.05146  loss_rpn_cls: 0.002542  loss_rpn_loc: 0.01111  time: 2.6185  data_time: 0.0298  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:35:21 d2.utils.events]: \u001b[0m eta: 0:21:06  iter: 10259  total_loss: 0.1417  loss_cls: 0.05743  loss_box_reg: 0.05685  loss_rpn_cls: 0.002841  loss_rpn_loc: 0.01658  time: 2.6186  data_time: 0.0307  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:36:13 d2.utils.events]: \u001b[0m eta: 0:20:14  iter: 10279  total_loss: 0.1481  loss_cls: 0.06355  loss_box_reg: 0.06308  loss_rpn_cls: 0.002969  loss_rpn_loc: 0.01572  time: 2.6187  data_time: 0.0277  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:37:07 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 10299  total_loss: 0.1607  loss_cls: 0.0661  loss_box_reg: 0.05641  loss_rpn_cls: 0.003537  loss_rpn_loc: 0.01735  time: 2.6188  data_time: 0.0301  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:38:00 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 10319  total_loss: 0.1338  loss_cls: 0.05914  loss_box_reg: 0.05006  loss_rpn_cls: 0.003623  loss_rpn_loc: 0.01692  time: 2.6188  data_time: 0.0302  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:38:54 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 10339  total_loss: 0.1357  loss_cls: 0.06351  loss_box_reg: 0.05582  loss_rpn_cls: 0.003557  loss_rpn_loc: 0.01173  time: 2.6190  data_time: 0.0272  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:39:46 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 10359  total_loss: 0.1606  loss_cls: 0.06392  loss_box_reg: 0.05541  loss_rpn_cls: 0.005875  loss_rpn_loc: 0.0241  time: 2.6190  data_time: 0.0298  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:40:38 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 10379  total_loss: 0.1586  loss_cls: 0.06631  loss_box_reg: 0.06537  loss_rpn_cls: 0.005388  loss_rpn_loc: 0.01637  time: 2.6189  data_time: 0.0300  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:41:28 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 10399  total_loss: 0.232  loss_cls: 0.09971  loss_box_reg: 0.0654  loss_rpn_cls: 0.006007  loss_rpn_loc: 0.02598  time: 2.6187  data_time: 0.0357  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:42:20 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 10419  total_loss: 0.1482  loss_cls: 0.06274  loss_box_reg: 0.05307  loss_rpn_cls: 0.002627  loss_rpn_loc: 0.01327  time: 2.6186  data_time: 0.0248  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:43:10 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 10439  total_loss: 0.1721  loss_cls: 0.07778  loss_box_reg: 0.07088  loss_rpn_cls: 0.004968  loss_rpn_loc: 0.02173  time: 2.6184  data_time: 0.0308  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:44:03 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 10459  total_loss: 0.1312  loss_cls: 0.06391  loss_box_reg: 0.0525  loss_rpn_cls: 0.003254  loss_rpn_loc: 0.01106  time: 2.6185  data_time: 0.0283  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:44:54 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 10479  total_loss: 0.1566  loss_cls: 0.06271  loss_box_reg: 0.04992  loss_rpn_cls: 0.003599  loss_rpn_loc: 0.01451  time: 2.6184  data_time: 0.0286  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:45:46 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 10499  total_loss: 0.1662  loss_cls: 0.07121  loss_box_reg: 0.06964  loss_rpn_cls: 0.004142  loss_rpn_loc: 0.016  time: 2.6183  data_time: 0.0251  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:46:40 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 10519  total_loss: 0.1533  loss_cls: 0.05987  loss_box_reg: 0.06116  loss_rpn_cls: 0.001309  loss_rpn_loc: 0.01669  time: 2.6185  data_time: 0.0275  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:47:31 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 10539  total_loss: 0.1314  loss_cls: 0.05132  loss_box_reg: 0.05385  loss_rpn_cls: 0.00502  loss_rpn_loc: 0.01538  time: 2.6183  data_time: 0.0720  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:48:24 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 10559  total_loss: 0.1544  loss_cls: 0.05606  loss_box_reg: 0.06553  loss_rpn_cls: 0.00404  loss_rpn_loc: 0.01538  time: 2.6184  data_time: 0.0264  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:49:13 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 10579  total_loss: 0.1464  loss_cls: 0.0581  loss_box_reg: 0.0565  loss_rpn_cls: 0.003726  loss_rpn_loc: 0.01563  time: 2.6181  data_time: 0.0269  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:50:04 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 10599  total_loss: 0.1607  loss_cls: 0.0775  loss_box_reg: 0.06779  loss_rpn_cls: 0.003115  loss_rpn_loc: 0.01606  time: 2.6179  data_time: 0.0250  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:50:58 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 10619  total_loss: 0.1203  loss_cls: 0.05371  loss_box_reg: 0.04916  loss_rpn_cls: 0.003157  loss_rpn_loc: 0.009884  time: 2.6181  data_time: 0.0279  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:51:50 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 10639  total_loss: 0.1548  loss_cls: 0.06553  loss_box_reg: 0.06083  loss_rpn_cls: 0.002798  loss_rpn_loc: 0.02428  time: 2.6180  data_time: 0.0345  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:52:43 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 10659  total_loss: 0.1318  loss_cls: 0.04885  loss_box_reg: 0.04991  loss_rpn_cls: 0.002445  loss_rpn_loc: 0.02122  time: 2.6181  data_time: 0.0265  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:53:37 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 10679  total_loss: 0.1471  loss_cls: 0.06286  loss_box_reg: 0.05535  loss_rpn_cls: 0.002871  loss_rpn_loc: 0.01657  time: 2.6183  data_time: 0.0393  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:54:30 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 10699  total_loss: 0.1375  loss_cls: 0.05652  loss_box_reg: 0.05018  loss_rpn_cls: 0.003044  loss_rpn_loc: 0.01617  time: 2.6183  data_time: 0.0311  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:55:22 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 10719  total_loss: 0.1528  loss_cls: 0.07083  loss_box_reg: 0.0627  loss_rpn_cls: 0.003604  loss_rpn_loc: 0.01374  time: 2.6183  data_time: 0.0319  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:56:14 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 10739  total_loss: 0.1637  loss_cls: 0.07385  loss_box_reg: 0.06274  loss_rpn_cls: 0.006134  loss_rpn_loc: 0.02161  time: 2.6182  data_time: 0.0276  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:56:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 08:56:32 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 08:56:32 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 08:56:32 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 08:56:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 08:56:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 08:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1820 s / img. ETA=0:00:57\n",
      "\u001b[32m[04/30 08:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2266 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 08:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 49/310. 0.2262 s / img. ETA=0:01:08\n",
      "\u001b[32m[04/30 08:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 64/310. 0.2161 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 08:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2125 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 08:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2067 s / img. ETA=0:01:02\n",
      "\u001b[32m[04/30 08:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 116/310. 0.2030 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/30 08:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 138/310. 0.1986 s / img. ETA=0:00:48\n",
      "\u001b[32m[04/30 08:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 164/310. 0.1963 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/30 08:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 189/310. 0.1934 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/30 08:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 211/310. 0.1925 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 08:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 234/310. 0.1918 s / img. ETA=0:00:19\n",
      "\u001b[32m[04/30 08:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 255/310. 0.1909 s / img. ETA=0:00:13\n",
      "\u001b[32m[04/30 08:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 279/310. 0.1899 s / img. ETA=0:00:07\n",
      "\u001b[32m[04/30 08:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 304/310. 0.1901 s / img. ETA=0:00:01\n",
      "\u001b[32m[04/30 08:57:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.520321 (0.244329 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 08:57:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.190862 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 08:57:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 08:57:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 08:57:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.42 seconds.\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.271 | 26.961 | 20.764 | 3.346 | 16.206 | 20.600 |\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.178 | Carton          | 30.550 | Bottle cap     | 30.145 |\n",
      "| Can                   | 31.516 | Pop tab         | 11.316 | Cup            | 28.544 |\n",
      "| Plastic bag & wrapper | 31.697 | Styrofoam piece | 13.811 | Other plastic  | 6.777  |\n",
      "| Plastic container     | 24.002 | Paper           | 10.586 | Lid            | 15.722 |\n",
      "| Straw                 | 23.671 | Paper bag       | 20.619 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 56.630 | Glass jar       | 30.297 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 11.782 | Aluminium foil | 17.525 |\n",
      "| Unlabeled litter      | 1.910  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 7.534  | Cigarette       | 15.443 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 23.333 |                 |        |                |        |\n",
      "\u001b[32m[04/30 08:57:49 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.testing]: \u001b[0mcopypaste: 17.2710,26.9610,20.7642,3.3462,16.2059,20.6005\n",
      "\u001b[32m[04/30 08:57:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 10745  total_loss: 0.177  loss_cls: 0.07625  loss_box_reg: 0.06369  loss_rpn_cls: 0.006045  loss_rpn_loc: 0.02826  time: 2.6183  data_time: 0.0291  lr: 4e-05  max_mem: 9676M\n",
      "\u001b[32m[04/30 08:57:49 d2.engine.hooks]: \u001b[0mOverall training speed: 10744 iterations in 7:48:51 (2.6184 s / it)\n",
      "\u001b[32m[04/30 08:57:49 d2.engine.hooks]: \u001b[0mTotal training time: 8:00:47 (0:11:56 on hooks)\n",
      "\u001b[32m[04/30 08:57:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 08:57:49 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 08:57:49 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 08:57:49 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 08:57:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 08:57:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 08:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1798 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 08:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2261 s / img. ETA=0:01:04\n",
      "\u001b[32m[04/30 08:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 46/310. 0.2307 s / img. ETA=0:01:13\n",
      "\u001b[32m[04/30 08:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 62/310. 0.2173 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/30 08:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 78/310. 0.2127 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 08:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 98/310. 0.2067 s / img. ETA=0:01:02\n",
      "\u001b[32m[04/30 08:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 118/310. 0.2019 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 08:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 142/310. 0.1983 s / img. ETA=0:00:46\n",
      "\u001b[32m[04/30 08:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 163/310. 0.1989 s / img. ETA=0:00:39\n",
      "\u001b[32m[04/30 08:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 189/310. 0.1958 s / img. ETA=0:00:31\n",
      "\u001b[32m[04/30 08:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 214/310. 0.1940 s / img. ETA=0:00:24\n",
      "\u001b[32m[04/30 08:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1921 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/30 08:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 265/310. 0.1910 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/30 08:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 288/310. 0.1903 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/30 08:59:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.237687 (0.243402 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 08:59:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.191371 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 08:59:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 08:59:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 08:59:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.17 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.271 | 26.961 | 20.764 | 3.346 | 16.206 | 20.600 |\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.178 | Carton          | 30.550 | Bottle cap     | 30.145 |\n",
      "| Can                   | 31.516 | Pop tab         | 11.316 | Cup            | 28.544 |\n",
      "| Plastic bag & wrapper | 31.697 | Styrofoam piece | 13.811 | Other plastic  | 6.777  |\n",
      "| Plastic container     | 24.002 | Paper           | 10.586 | Lid            | 15.722 |\n",
      "| Straw                 | 23.671 | Paper bag       | 20.619 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 56.630 | Glass jar       | 30.297 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 11.782 | Aluminium foil | 17.525 |\n",
      "| Unlabeled litter      | 1.910  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 7.534  | Cigarette       | 15.443 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 23.333 |                 |        |                |        |\n",
      "\u001b[32m[04/30 08:59:06 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.testing]: \u001b[0mcopypaste: 17.2710,26.9610,20.7642,3.3462,16.2059,20.6005\n",
      "\u001b[32m[04/30 08:59:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: []\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 08:59:06 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 08:59:06 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 08:59:06 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 08:59:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 08:59:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 08:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1829 s / img. ETA=0:00:56\n",
      "\u001b[32m[04/30 08:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 32/310. 0.2261 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 08:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 50/310. 0.2230 s / img. ETA=0:01:05\n",
      "\u001b[32m[04/30 08:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 66/310. 0.2146 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/30 08:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 83/310. 0.2087 s / img. ETA=0:01:03\n",
      "\u001b[32m[04/30 08:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 102/310. 0.2037 s / img. ETA=0:00:58\n",
      "\u001b[32m[04/30 08:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 118/310. 0.2017 s / img. ETA=0:00:55\n",
      "\u001b[32m[04/30 08:59:46 d2.evaluation.evaluator]: \u001b[0mInference done 141/310. 0.1981 s / img. ETA=0:00:46\n",
      "\u001b[32m[04/30 08:59:51 d2.evaluation.evaluator]: \u001b[0mInference done 165/310. 0.1953 s / img. ETA=0:00:38\n",
      "\u001b[32m[04/30 08:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 192/310. 0.1928 s / img. ETA=0:00:30\n",
      "\u001b[32m[04/30 09:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 216/310. 0.1913 s / img. ETA=0:00:23\n",
      "\u001b[32m[04/30 09:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1897 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/30 09:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 262/310. 0.1895 s / img. ETA=0:00:11\n",
      "\u001b[32m[04/30 09:00:17 d2.evaluation.evaluator]: \u001b[0mInference done 286/310. 0.1889 s / img. ETA=0:00:05\n",
      "\u001b[32m[04/30 09:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 310/310. 0.1899 s / img. ETA=0:00:00\n",
      "\u001b[32m[04/30 09:00:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.045402 (0.242772 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 09:00:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.189896 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 09:00:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 09:00:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 09:00:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.271 | 26.961 | 20.764 | 3.346 | 16.206 | 20.600 |\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 40.178 | Carton          | 30.550 | Bottle cap     | 30.145 |\n",
      "| Can                   | 31.516 | Pop tab         | 11.316 | Cup            | 28.544 |\n",
      "| Plastic bag & wrapper | 31.697 | Styrofoam piece | 13.811 | Other plastic  | 6.777  |\n",
      "| Plastic container     | 24.002 | Paper           | 10.586 | Lid            | 15.722 |\n",
      "| Straw                 | 23.671 | Paper bag       | 20.619 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 56.630 | Glass jar       | 30.297 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 11.782 | Aluminium foil | 17.525 |\n",
      "| Unlabeled litter      | 1.910  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 7.534  | Cigarette       | 15.443 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 23.333 |                 |        |                |        |\n",
      "\u001b[32m[04/30 09:00:23 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_test_0 in csv format:\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/30 09:00:23 d2.evaluation.testing]: \u001b[0mcopypaste: 17.2710,26.9610,20.7642,3.3462,16.2059,20.6005\n"
     ]
    }
   ],
   "source": [
    "train(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goIHpnTXED-y",
    "papermill": {
     "duration": 0.315989,
     "end_time": "2021-04-30T09:00:23.965164",
     "exception": false,
     "start_time": "2021-04-30T09:00:23.649175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:00:24.609512Z",
     "iopub.status.busy": "2021-04-30T09:00:24.608736Z",
     "iopub.status.idle": "2021-04-30T09:00:24.646799Z",
     "shell.execute_reply": "2021-04-30T09:00:24.646320Z"
    },
    "id": "9sWii-FSED-z",
    "papermill": {
     "duration": 0.359361,
     "end_time": "2021-04-30T09:00:24.646897",
     "exception": false,
     "start_time": "2021-04-30T09:00:24.287536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(CONFIG_PATH,\"detectron_config.yaml\"),\"w\") as f:\n",
    "    f.write(get_config().dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:00:25.291644Z",
     "iopub.status.busy": "2021-04-30T09:00:25.290892Z",
     "iopub.status.idle": "2021-04-30T09:00:25.962306Z",
     "shell.execute_reply": "2021-04-30T09:00:25.963104Z"
    },
    "id": "uhOMK3cOED-z",
    "outputId": "d59b43a2-356f-4c5f-fcaa-4868e516b450",
    "papermill": {
     "duration": 0.992733,
     "end_time": "2021-04-30T09:00:25.963246",
     "exception": false,
     "start_time": "2021-04-30T09:00:24.970513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1619744205.30bd733c75bc.22.0  experiment.yaml  metrics.json\r\n"
     ]
    }
   ],
   "source": [
    "%ls logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:00:26.604106Z",
     "iopub.status.busy": "2021-04-30T09:00:26.603333Z",
     "iopub.status.idle": "2021-04-30T09:00:27.262656Z",
     "shell.execute_reply": "2021-04-30T09:00:27.262193Z"
    },
    "id": "yjShC_zvED-z",
    "outputId": "6bc3e6d9-f081-46ad-955a-4ab47c79c8a4",
    "papermill": {
     "duration": 0.983037,
     "end_time": "2021-04-30T09:00:27.262767",
     "exception": false,
     "start_time": "2021-04-30T09:00:26.279730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.pth   model_0004999.pth  model_final.pth\r\n",
      "last_checkpoint  model_0009999.pth\r\n"
     ]
    }
   ],
   "source": [
    "%ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:00:27.924325Z",
     "iopub.status.busy": "2021-04-30T09:00:27.905042Z",
     "iopub.status.idle": "2021-04-30T09:00:28.566878Z",
     "shell.execute_reply": "2021-04-30T09:00:28.567277Z"
    },
    "id": "OK_zwp-2ED-0",
    "outputId": "4254b986-bc1e-4194-e172-bfe1d5ec7020",
    "papermill": {
     "duration": 0.987336,
     "end_time": "2021-04-30T09:00:28.567406",
     "exception": false,
     "start_time": "2021-04-30T09:00:27.580070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detectron_config.yaml\r\n"
     ]
    }
   ],
   "source": [
    "%ls configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F5_h9ZLED-1",
    "papermill": {
     "duration": 0.315394,
     "end_time": "2021-04-30T09:00:29.201415",
     "exception": false,
     "start_time": "2021-04-30T09:00:28.886021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Dataset (without validation augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:00:29.845938Z",
     "iopub.status.busy": "2021-04-30T09:00:29.844947Z",
     "iopub.status.idle": "2021-04-30T09:00:29.847839Z",
     "shell.execute_reply": "2021-04-30T09:00:29.847322Z"
    },
    "id": "QJggkCNbED-1",
    "papermill": {
     "duration": 0.328923,
     "end_time": "2021-04-30T09:00:29.847936",
     "exception": false,
     "start_time": "2021-04-30T09:00:29.519013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:00:30.506938Z",
     "iopub.status.busy": "2021-04-30T09:00:30.498815Z",
     "iopub.status.idle": "2021-04-30T09:00:32.121262Z",
     "shell.execute_reply": "2021-04-30T09:00:32.121717Z"
    },
    "id": "mOyVMdxYED-1",
    "papermill": {
     "duration": 1.953811,
     "end_time": "2021-04-30T09:00:32.121869",
     "exception": false,
     "start_time": "2021-04-30T09:00:30.168058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg=get_config()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(MODELS_PATH, \"best_model.pth\")  # path to the model we just trained\n",
    "model = build_model(cfg)\n",
    "m=DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:00:32.764932Z",
     "iopub.status.busy": "2021-04-30T09:00:32.764127Z",
     "iopub.status.idle": "2021-04-30T09:02:21.090860Z",
     "shell.execute_reply": "2021-04-30T09:02:21.091967Z"
    },
    "id": "QhmN1En7ED-2",
    "outputId": "8b3f4e84-62f0-4354-fc39-1e9c8b3a22bd",
    "papermill": {
     "duration": 108.651855,
     "end_time": "2021-04-30T09:02:21.092162",
     "exception": false,
     "start_time": "2021-04-30T09:00:32.440307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 09:00:32 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 09:00:32 d2.data.datasets.coco]: \u001b[0mLoaded 310 images in COCO format from my_dataset_test_0.json\n",
      "\u001b[32m[04/30 09:00:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/30 09:00:32 d2.data.common]: \u001b[0mSerializing 310 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 09:00:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[32m[04/30 09:00:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 310 images\n",
      "\u001b[32m[04/30 09:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/310. 0.1252 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/30 09:00:40 d2.evaluation.evaluator]: \u001b[0mInference done 29/310. 0.1235 s / img. ETA=0:01:17\n",
      "\u001b[32m[04/30 09:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 42/310. 0.1279 s / img. ETA=0:01:30\n",
      "\u001b[32m[04/30 09:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 54/310. 0.1294 s / img. ETA=0:01:31\n",
      "\u001b[32m[04/30 09:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 63/310. 0.1319 s / img. ETA=0:01:36\n",
      "\u001b[32m[04/30 09:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 74/310. 0.1344 s / img. ETA=0:01:36\n",
      "\u001b[32m[04/30 09:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 87/310. 0.1337 s / img. ETA=0:01:33\n",
      "\u001b[32m[04/30 09:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 99/310. 0.1337 s / img. ETA=0:01:29\n",
      "\u001b[32m[04/30 09:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 110/310. 0.1350 s / img. ETA=0:01:25\n",
      "\u001b[32m[04/30 09:01:24 d2.evaluation.evaluator]: \u001b[0mInference done 123/310. 0.1346 s / img. ETA=0:01:19\n",
      "\u001b[32m[04/30 09:01:29 d2.evaluation.evaluator]: \u001b[0mInference done 141/310. 0.1331 s / img. ETA=0:01:09\n",
      "\u001b[32m[04/30 09:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 159/310. 0.1321 s / img. ETA=0:00:59\n",
      "\u001b[32m[04/30 09:01:40 d2.evaluation.evaluator]: \u001b[0mInference done 175/310. 0.1313 s / img. ETA=0:00:52\n",
      "\u001b[32m[04/30 09:01:45 d2.evaluation.evaluator]: \u001b[0mInference done 193/310. 0.1307 s / img. ETA=0:00:44\n",
      "\u001b[32m[04/30 09:01:50 d2.evaluation.evaluator]: \u001b[0mInference done 210/310. 0.1306 s / img. ETA=0:00:37\n",
      "\u001b[32m[04/30 09:01:55 d2.evaluation.evaluator]: \u001b[0mInference done 227/310. 0.1302 s / img. ETA=0:00:30\n",
      "\u001b[32m[04/30 09:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 241/310. 0.1301 s / img. ETA=0:00:25\n",
      "\u001b[32m[04/30 09:02:06 d2.evaluation.evaluator]: \u001b[0mInference done 259/310. 0.1298 s / img. ETA=0:00:18\n",
      "\u001b[32m[04/30 09:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 276/310. 0.1295 s / img. ETA=0:00:12\n",
      "\u001b[32m[04/30 09:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 296/310. 0.1299 s / img. ETA=0:00:04\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:46.057269 (0.347729 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.129312 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to logs/coco_instances_results.json\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[04/30 09:02:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 09:02:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.18 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n",
      "\u001b[32m[04/30 09:02:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.269 | 23.984 | 19.256 | 1.856 | 15.105 | 20.596 |\n",
      "\u001b[32m[04/30 09:02:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 37.226 | Carton          | 35.245 | Bottle cap     | 30.990 |\n",
      "| Can                   | 36.127 | Pop tab         | 15.806 | Cup            | 29.852 |\n",
      "| Plastic bag & wrapper | 28.728 | Styrofoam piece | 14.669 | Other plastic  | 4.058  |\n",
      "| Plastic container     | 26.099 | Paper           | 9.653  | Lid            | 17.988 |\n",
      "| Straw                 | 13.940 | Paper bag       | 14.644 | Broken glass   | 0.000  |\n",
      "| Plastic utensils      | 59.817 | Glass jar       | 15.149 | Food waste     | 0.000  |\n",
      "| Squeezable tube       | 0.000  | Shoe            | 5.050  | Aluminium foil | 23.465 |\n",
      "| Unlabeled litter      | 0.767  | Blister pack    | 0.000  | Battery        | 0.000  |\n",
      "| Rope & strings        | 23.003 | Cigarette       | 13.263 | Scrap metal    | 0.000  |\n",
      "| Plastic glooves       | 0.000  |                 |        |                |        |\n"
     ]
    }
   ],
   "source": [
    "evaluator = COCOEvaluator(\"my_dataset_test_0\", (\"bbox\",), False, output_dir=LOGS_PATH)\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test_0\")\n",
    "train_metric=inference_on_dataset(model, val_loader, evaluator)\n",
    "metrics[\"train_metric\"]=train_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:02:21.863712Z",
     "iopub.status.busy": "2021-04-30T09:02:21.862639Z",
     "iopub.status.idle": "2021-04-30T09:09:02.293921Z",
     "shell.execute_reply": "2021-04-30T09:09:02.293028Z"
    },
    "id": "6ec3dABzED-2",
    "outputId": "002c844b-5e8c-457a-b4fe-7f66c9c85732",
    "papermill": {
     "duration": 400.765846,
     "end_time": "2021-04-30T09:09:02.294046",
     "exception": false,
     "start_time": "2021-04-30T09:02:21.528200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/30 09:02:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/30 09:02:21 d2.data.datasets.coco]: \u001b[0mLoaded 1190 images in COCO format from my_dataset_train_0.json\n",
      "\u001b[32m[04/30 09:02:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/30 09:02:22 d2.data.common]: \u001b[0mSerializing 1190 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/30 09:02:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.80 MiB\n",
      "\u001b[32m[04/30 09:02:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 1190 images\n",
      "\u001b[32m[04/30 09:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/1190. 0.1211 s / img. ETA=0:02:37\n",
      "\u001b[32m[04/30 09:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 40/1190. 0.1242 s / img. ETA=0:03:14\n",
      "\u001b[32m[04/30 09:02:35 d2.evaluation.evaluator]: \u001b[0mInference done 57/1190. 0.1254 s / img. ETA=0:04:00\n",
      "\u001b[32m[04/30 09:02:40 d2.evaluation.evaluator]: \u001b[0mInference done 76/1190. 0.1246 s / img. ETA=0:04:17\n",
      "\u001b[32m[04/30 09:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 99/1190. 0.1258 s / img. ETA=0:04:10\n",
      "\u001b[32m[04/30 09:02:50 d2.evaluation.evaluator]: \u001b[0mInference done 119/1190. 0.1250 s / img. ETA=0:04:10\n",
      "\u001b[32m[04/30 09:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 137/1190. 0.1258 s / img. ETA=0:04:21\n",
      "\u001b[32m[04/30 09:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 157/1190. 0.1260 s / img. ETA=0:04:19\n",
      "\u001b[32m[04/30 09:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 176/1190. 0.1261 s / img. ETA=0:04:16\n",
      "\u001b[32m[04/30 09:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 185/1190. 0.1270 s / img. ETA=0:04:32\n",
      "\u001b[32m[04/30 09:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 197/1190. 0.1278 s / img. ETA=0:04:44\n",
      "\u001b[32m[04/30 09:03:24 d2.evaluation.evaluator]: \u001b[0mInference done 211/1190. 0.1275 s / img. ETA=0:04:45\n",
      "\u001b[32m[04/30 09:03:29 d2.evaluation.evaluator]: \u001b[0mInference done 221/1190. 0.1279 s / img. ETA=0:04:55\n",
      "\u001b[32m[04/30 09:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 233/1190. 0.1277 s / img. ETA=0:04:57\n",
      "\u001b[32m[04/30 09:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 245/1190. 0.1287 s / img. ETA=0:05:03\n",
      "\u001b[32m[04/30 09:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 257/1190. 0.1297 s / img. ETA=0:05:11\n",
      "\u001b[32m[04/30 09:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 266/1190. 0.1305 s / img. ETA=0:05:15\n",
      "\u001b[32m[04/30 09:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 277/1190. 0.1310 s / img. ETA=0:05:16\n",
      "\u001b[32m[04/30 09:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 289/1190. 0.1315 s / img. ETA=0:05:18\n",
      "\u001b[32m[04/30 09:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 304/1190. 0.1320 s / img. ETA=0:05:12\n",
      "\u001b[32m[04/30 09:04:15 d2.evaluation.evaluator]: \u001b[0mInference done 313/1190. 0.1322 s / img. ETA=0:05:15\n",
      "\u001b[32m[04/30 09:04:20 d2.evaluation.evaluator]: \u001b[0mInference done 327/1190. 0.1321 s / img. ETA=0:05:10\n",
      "\u001b[32m[04/30 09:04:25 d2.evaluation.evaluator]: \u001b[0mInference done 337/1190. 0.1322 s / img. ETA=0:05:10\n",
      "\u001b[32m[04/30 09:04:30 d2.evaluation.evaluator]: \u001b[0mInference done 351/1190. 0.1320 s / img. ETA=0:05:05\n",
      "\u001b[32m[04/30 09:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 361/1190. 0.1322 s / img. ETA=0:05:07\n",
      "\u001b[32m[04/30 09:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 373/1190. 0.1320 s / img. ETA=0:05:04\n",
      "\u001b[32m[04/30 09:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 385/1190. 0.1319 s / img. ETA=0:05:02\n",
      "\u001b[32m[04/30 09:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 397/1190. 0.1319 s / img. ETA=0:04:59\n",
      "\u001b[32m[04/30 09:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 409/1190. 0.1317 s / img. ETA=0:04:57\n",
      "\u001b[32m[04/30 09:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 421/1190. 0.1315 s / img. ETA=0:04:53\n",
      "\u001b[32m[04/30 09:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 433/1190. 0.1314 s / img. ETA=0:04:52\n",
      "\u001b[32m[04/30 09:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 447/1190. 0.1313 s / img. ETA=0:04:46\n",
      "\u001b[32m[04/30 09:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 457/1190. 0.1314 s / img. ETA=0:04:45\n",
      "\u001b[32m[04/30 09:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 469/1190. 0.1312 s / img. ETA=0:04:41\n",
      "\u001b[32m[04/30 09:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 481/1190. 0.1311 s / img. ETA=0:04:38\n",
      "\u001b[32m[04/30 09:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 503/1190. 0.1306 s / img. ETA=0:04:24\n",
      "\u001b[32m[04/30 09:05:41 d2.evaluation.evaluator]: \u001b[0mInference done 514/1190. 0.1307 s / img. ETA=0:04:22\n",
      "\u001b[32m[04/30 09:05:46 d2.evaluation.evaluator]: \u001b[0mInference done 530/1190. 0.1304 s / img. ETA=0:04:14\n",
      "\u001b[32m[04/30 09:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 553/1190. 0.1305 s / img. ETA=0:04:01\n",
      "\u001b[32m[04/30 09:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 573/1190. 0.1304 s / img. ETA=0:03:51\n",
      "\u001b[32m[04/30 09:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 591/1190. 0.1304 s / img. ETA=0:03:43\n",
      "\u001b[32m[04/30 09:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 609/1190. 0.1304 s / img. ETA=0:03:35\n",
      "\u001b[32m[04/30 09:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 629/1190. 0.1302 s / img. ETA=0:03:26\n",
      "\u001b[32m[04/30 09:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 647/1190. 0.1303 s / img. ETA=0:03:18\n",
      "\u001b[32m[04/30 09:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 665/1190. 0.1303 s / img. ETA=0:03:11\n",
      "\u001b[32m[04/30 09:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 684/1190. 0.1303 s / img. ETA=0:03:02\n",
      "\u001b[32m[04/30 09:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 701/1190. 0.1302 s / img. ETA=0:02:56\n",
      "\u001b[32m[04/30 09:06:39 d2.evaluation.evaluator]: \u001b[0mInference done 718/1190. 0.1301 s / img. ETA=0:02:49\n",
      "\u001b[32m[04/30 09:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 737/1190. 0.1300 s / img. ETA=0:02:41\n",
      "\u001b[32m[04/30 09:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 753/1190. 0.1301 s / img. ETA=0:02:35\n",
      "\u001b[32m[04/30 09:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 770/1190. 0.1301 s / img. ETA=0:02:29\n",
      "\u001b[32m[04/30 09:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 789/1190. 0.1299 s / img. ETA=0:02:21\n",
      "\u001b[32m[04/30 09:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 808/1190. 0.1299 s / img. ETA=0:02:14\n",
      "\u001b[32m[04/30 09:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 825/1190. 0.1299 s / img. ETA=0:02:07\n",
      "\u001b[32m[04/30 09:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 843/1190. 0.1298 s / img. ETA=0:02:01\n",
      "\u001b[32m[04/30 09:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 859/1190. 0.1298 s / img. ETA=0:01:55\n",
      "\u001b[32m[04/30 09:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 879/1190. 0.1296 s / img. ETA=0:01:47\n",
      "\u001b[32m[04/30 09:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 897/1190. 0.1297 s / img. ETA=0:01:41\n",
      "\u001b[32m[04/30 09:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 915/1190. 0.1296 s / img. ETA=0:01:34\n",
      "\u001b[32m[04/30 09:07:44 d2.evaluation.evaluator]: \u001b[0mInference done 934/1190. 0.1296 s / img. ETA=0:01:28\n",
      "\u001b[32m[04/30 09:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 946/1190. 0.1297 s / img. ETA=0:01:24\n",
      "\u001b[32m[04/30 09:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 962/1190. 0.1299 s / img. ETA=0:01:18\n",
      "\u001b[32m[04/30 09:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 980/1190. 0.1298 s / img. ETA=0:01:12\n",
      "\u001b[32m[04/30 09:08:05 d2.evaluation.evaluator]: \u001b[0mInference done 997/1190. 0.1299 s / img. ETA=0:01:06\n",
      "\u001b[32m[04/30 09:08:10 d2.evaluation.evaluator]: \u001b[0mInference done 1015/1190. 0.1298 s / img. ETA=0:01:00\n",
      "\u001b[32m[04/30 09:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 1032/1190. 0.1298 s / img. ETA=0:00:54\n",
      "\u001b[32m[04/30 09:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 1052/1190. 0.1298 s / img. ETA=0:00:47\n",
      "\u001b[32m[04/30 09:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 1068/1190. 0.1300 s / img. ETA=0:00:41\n",
      "\u001b[32m[04/30 09:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 1089/1190. 0.1298 s / img. ETA=0:00:34\n",
      "\u001b[32m[04/30 09:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 1105/1190. 0.1302 s / img. ETA=0:00:28\n",
      "\u001b[32m[04/30 09:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 1122/1190. 0.1303 s / img. ETA=0:00:23\n",
      "\u001b[32m[04/30 09:08:47 d2.evaluation.evaluator]: \u001b[0mInference done 1139/1190. 0.1304 s / img. ETA=0:00:17\n",
      "\u001b[32m[04/30 09:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 1158/1190. 0.1302 s / img. ETA=0:00:10\n",
      "\u001b[32m[04/30 09:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 1178/1190. 0.1302 s / img. ETA=0:00:04\n",
      "\u001b[32m[04/30 09:09:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:36.672073 (0.334744 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 09:09:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:34 (0.130067 s / img per device, on 1 devices)\n",
      "\u001b[32m[04/30 09:09:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/30 09:09:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to logs/coco_instances_results.json\n",
      "\u001b[32m[04/30 09:09:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/30 09:09:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/30 09:09:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.06 seconds.\n",
      "\u001b[32m[04/30 09:09:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/30 09:09:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.17 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.375\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.430\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
      "\u001b[32m[04/30 09:09:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 33.217 | 52.577 | 37.518 | 5.226 | 20.912 | 40.353 |\n",
      "\u001b[32m[04/30 09:09:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category              | AP     | category        | AP     | category       | AP     |\n",
      "|:----------------------|:-------|:----------------|:-------|:---------------|:-------|\n",
      "| Bottle                | 55.009 | Carton          | 53.621 | Bottle cap     | 47.798 |\n",
      "| Can                   | 66.423 | Pop tab         | 23.930 | Cup            | 53.572 |\n",
      "| Plastic bag & wrapper | 40.765 | Styrofoam piece | 40.567 | Other plastic  | 23.135 |\n",
      "| Plastic container     | 39.632 | Paper           | 31.223 | Lid            | 41.919 |\n",
      "| Straw                 | 30.481 | Paper bag       | 35.666 | Broken glass   | 9.108  |\n",
      "| Plastic utensils      | 29.607 | Glass jar       | 36.997 | Food waste     | 20.198 |\n",
      "| Squeezable tube       | 11.518 | Shoe            | 42.816 | Aluminium foil | 54.604 |\n",
      "| Unlabeled litter      | 15.636 | Blister pack    | 28.485 | Battery        | 0.000  |\n",
      "| Rope & strings        | 27.561 | Cigarette       | 19.396 | Scrap metal    | 3.888  |\n",
      "| Plastic glooves       | 46.535 |                 |        |                |        |\n"
     ]
    }
   ],
   "source": [
    "evaluator = COCOEvaluator(\"my_dataset_train_0\", (\"bbox\",), False, output_dir=LOGS_PATH)\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_train_0\")\n",
    "valid_metric=inference_on_dataset(model, val_loader, evaluator)\n",
    "metrics[\"valid_metric\"]=valid_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-30T09:09:03.011394Z",
     "iopub.status.busy": "2021-04-30T09:09:03.010830Z",
     "iopub.status.idle": "2021-04-30T09:09:03.013977Z",
     "shell.execute_reply": "2021-04-30T09:09:03.013413Z"
    },
    "id": "iE3NWP7uED-2",
    "papermill": {
     "duration": 0.366773,
     "end_time": "2021-04-30T09:09:03.014073",
     "exception": false,
     "start_time": "2021-04-30T09:09:02.647300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dump_dict(metrics,os.path.join(LOGS_PATH,\"metrics.yaml\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 29608.025218,
   "end_time": "2021-04-30T09:09:05.212304",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-30T00:55:37.187086",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
